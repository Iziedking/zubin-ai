{"version":3,"file":"static/js/7885.943c3e0c.chunk.js","mappings":"+UAEA,MAAMA,EAAmCC,EAAAA,cAAoB,CAC3DC,SAAWC,GAAsBA,IAGtBC,EAA4BA,EACvCC,WACAC,eAMEC,EAAAA,EAAAA,GAACP,EAAiCQ,SAAQ,CAACC,MAAO,CAAEP,SAAUI,GAAWD,SACtEA,IAKMK,EAAuBA,IAAMT,EAAAA,WAAiBD,E,+NCpBpD,MAAMW,EAAgC,sBAChCC,EAAuC,6BACvCC,EAAyB,c,iHCe/B,SAASC,GAAiB,YAC/BC,EAAW,YACXC,EAAW,SACXC,EAAQ,YACRC,EAAW,mBACXC,GAAqB,EAAK,OAC1BC,EAAM,aACNC,IAEA,MAAM,WAAEC,EAAU,KAAEC,EAAI,wBAAEC,EAAuB,YAAEC,EAAW,eAAEC,IAAmBC,EAAAA,EAAAA,GACjFV,EACAC,EACAE,GAGIQ,GACJrB,EAAAA,EAAAA,GAACsB,EAAAA,EAAM,CACL,aAAYH,EACZV,YAAwB,OAAXA,QAAW,IAAXA,EAAAA,EAAe,sDAC5Bc,KAAMR,EACNS,QAASR,EACTS,KAAK,WACDjB,IAIFkB,GACJ1B,EAAAA,EAAAA,GAACsB,EAAAA,EAAM,CACL,aAAYH,EACZV,YAAwB,OAAXA,QAAW,IAAXA,EAAAA,EAAe,sDAC5Be,QAASR,KACLR,EAAWV,SAEdiB,IAIL,OACEf,EAAAA,EAAAA,GAAC2B,EAAAA,EAAO,CACNlB,YACEA,EAAc,GAAGA,YAAwB,8DAE3CmB,QAAST,EACTU,aAAcZ,EACda,KAAMZ,KACFJ,EAAYhB,SAEfc,EAAqBc,EAAmBL,GAG/C,C,mMC9DO,MAAMU,EAA+BA,EAC1CC,UACAC,eACAC,eAMA,MAAMC,GAAOC,EAAAA,EAAAA,OACNC,EAAaC,IAAkBC,EAAAA,EAAAA,UAAS,KACxCC,EAAkBC,IAAuBF,EAAAA,EAAAA,UAAS,KACnD,gCAAEG,EAA+B,UAAEC,GCHOC,GAChDC,YACAC,cAKA,MAAMC,GAAcC,EAAAA,EAAAA,OAEZC,OAAQP,EAA+B,UAAEC,IAAcO,EAAAA,EAAAA,GAAY,CACzEC,WAAYC,OAASf,cAAagB,oBAChC,MAAMC,EAAc,CAClBC,KAAMlB,EACNmB,eAAgBH,GASlB,aANwBI,EAAAA,EAAAA,KACtBC,EAAAA,EAAAA,IAAW,uCACX,OACAJ,IAGcK,OAAO,EAEzBd,UAAWA,KACTE,EAAYa,kBAAkB,CAAEC,SAAU,CAACxD,EAAAA,MAClC,OAATwC,QAAS,IAATA,GAAAA,GAAa,EAEfC,QAAUgB,IACD,OAAPhB,QAAO,IAAPA,GAAAA,EAAUgB,EAAM,IAIpB,MAAO,CACLpB,kCACAC,YACD,EDjCsDC,CAAmC,CACxFC,UAAWA,KAETX,GAAU,IAIR6B,GAAgCC,EAAAA,EAAAA,cAAY,KAC3C3B,EASLK,EAAgC,CAAEL,cAAagB,cAAe,CAACpB,KAR7DQ,EACEN,EAAK8B,cAAc,CAAAC,GAAA,SACjBC,eAAe,6BAM0D,GAC9E,CAACzB,EAAiCT,EAAcI,EAAaF,IAEhE,OACEiC,EAAAA,EAAAA,IAACC,EAAAA,EAAK,CACJ5D,YAAY,yCACZuB,QAASA,EACTE,SAAUA,EACVoC,OAAQnC,EAAK8B,cAAc,CAAAC,GAAA,SAAEC,eAAe,WAC5CI,WAAYpC,EAAK8B,cAAc,CAAAC,GAAA,SAC7BC,eAAe,WAGjBK,KAAMT,EACNU,cAAe,CAAEC,QAAS/B,EAAWgC,UAAWtC,GAChDuC,OACE5E,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SACfC,eAAe,8BAGlBrE,SAAA,EAEDE,EAAAA,EAAAA,GAAC8E,EAAAA,OAAOC,MAAK,CAACC,QAAQ,qBAAoBlF,UACxCE,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SAACC,eAAe,oBAEnCnE,EAAAA,EAAAA,GAACiF,EAAAA,EAAK,CACJxE,YAAY,sDACZyD,GAAG,qBACHX,KAAK,OACL2B,KAAK,OACLC,YAAahD,EAAK8B,cAAc,CAAAC,GAAA,SAC9BC,eAAe,uBAGjBjE,MAAOmC,EACP+C,SAAWC,IACT/C,EAAe+C,EAAEC,OAAOpF,OACxBuC,EAAoB,GAAG,IAG1BD,IAAoBxC,EAAAA,EAAAA,GAAC8E,EAAAA,OAAOS,QAAO,CAACL,KAAK,QAAQM,QAAShD,MACrD,EExEkE,IAAAiD,EAAA,CAAAlC,KAAA,SAAAmC,OAAA,qBAEvE,MAAMC,EAAgCA,EAAG1D,mBAC9C,MAAO2D,EAAwBC,IAA6BtD,EAAAA,EAAAA,WAAS,GACrE,OACE6B,EAAAA,EAAAA,IAAA0B,EAAAA,GAAA,CAAAhG,SAAA,EACEE,EAAAA,EAAAA,GAACsB,EAAAA,EAAM,CACLb,YAAY,6CACZsF,IAAGN,EACHlE,MAAMvB,EAAAA,EAAAA,GAACgG,EAAAA,aAAY,IACnBxE,QAASA,IAAMqE,GAA0B,GAAM/F,UAE/CE,EAAAA,EAAAA,GAAC6E,EAAAA,EAAgB,CAAAX,GAAA,SAACC,eAAe,sBAEnCnE,EAAAA,EAAAA,GAAC+B,EAA4B,CAC3BE,aAAcA,EACdD,QAAS4D,EACT1D,SAAUA,IAAM2D,GAA0B,OAE3C,C,wGChBP,MAOaI,EAA8BA,EACzChE,eACAiE,WAAU,EACVC,aAAa,OAMb,MAAM,KAAEC,EAAI,cAAEC,EAAa,YAAEC,EAAW,UAAE3D,EAAS,WAAE4D,EAAU,QAAEC,EAAO,MAAE1C,IAAU2C,EAAAA,EAAAA,GAGlF,CACA5C,SAAU,CAACxD,EAAAA,GAAsC4B,EAAckE,GAC/DO,QAAStD,OAASS,UAAW,CAAE5B,EAAckE,GAAaQ,gBACxD,MACMrD,EAAc,CAClBE,eAAgB,CAACvB,GACjB2E,cAHmBT,EAAa,gBAAgBA,WAAiBU,EAIjEC,SAAU,CAAC,qBACXC,YA3BqC,GA4BrCC,WAAYL,GAGd,aAAclD,EAAAA,EAAAA,KACZC,EAAAA,EAAAA,IAAW,uCACX,OACAJ,EACD,EAEH2D,UAAW,EACXC,sBAAsB,EACtBC,OAAO,EACPjB,UACAkB,iBAAmBC,GAAaA,EAASC,kBAK3C,MAAO,CACLlB,MAHemB,EAAAA,EAAAA,UAAQ,SAAAC,EAAA,OAAwD,QAAxDA,EAAU,OAAJpB,QAAI,IAAJA,OAAI,EAAJA,EAAMqB,MAAMC,SAASC,IAAI,IAAAC,EAAA,OAAkB,QAAlBA,EAAKD,EAAKE,gBAAQ,IAAAD,EAAAA,EAAI,EAAE,WAAC,IAAAJ,EAAAA,EAAI,EAAE,GAAE,CAACpB,IAIxFC,gBACAC,cACA3D,YACA4D,aACAC,UACA1C,QACD,C,+NCjBI,MAAMgE,EAAsBA,CACjCC,EACAC,KAEA,KAAKC,EAAAA,EAAAA,OAAMD,GACT,GAA6B,cAAzBD,EAAeG,MAAuB,CACxC,GAAIF,IAAoBG,EAAAA,GAA2CC,IACjE,OAAO,EACF,GAAIJ,IAAoBG,EAAAA,GAA2CE,GACxE,OAAO,CAEX,MAAO,GAA6B,YAAzBN,EAAeG,MACxB,OAA2B,IAApBF,CAGK,EAChB,IAAAvC,EAAA,CAAAlC,KAAA,UAAAmC,OAAA,qBAAA4C,EAAA,CAAA/E,KAAA,UAAAmC,OAAA,qBAsKD,IAAA6C,EAAA,CAAAhF,KAAA,UAAAmC,OAAA,iEAAA8C,EAAA,CAAAjF,KAAA,UAAAmC,OAAA,mBAAA+C,EAAA,CAAAlF,KAAA,SAAAmC,OAAA,eAAAgD,EAAA,CAAAnF,KAAA,SAAAmC,OAAA,0CAEM,MAAMiD,EAAiCA,EAC5CC,aACAC,SACAC,UAAS,EACTC,uBACAC,0BAAyB,EACzBC,oBAAmB,EACnBC,sBAAqB,EACrBC,YAAW,EACXC,kBAAiB,EACjBC,wBACAtB,iBACA7C,OACAoE,YAeK,IAADC,EAAAC,EACJ,MAAM,MAAEC,IAAUC,EAAAA,EAAAA,KACZvH,GAAOC,EAAAA,EAAAA,MAEPlC,EAAQ0I,GAAae,EAAAA,EAAAA,IAAmCf,QAAc/B,EACtE+C,GAAYrC,EAAAA,EAAAA,UAAQ,IAAMO,EAAoBC,EAAgB7H,IAAQ,CAACA,EAAO6H,IAE9E8B,GAAYC,EAAAA,EAAAA,IAA6BL,EAAO1B,EAAgBa,GAChEmB,GAAYC,EAAAA,EAAAA,IAA6BP,EAAO1B,EAAgBa,GAEtE,IAAIqB,GAEQ,OAAVrB,QAAU,IAAVA,GAAAA,EAAYqB,mBACGpD,IAAd+C,GAA2BhB,GAAcsB,EAAAA,GAAmDtB,EAAWrF,SAExG0G,EACErB,EAAWqB,cACX9H,EAAK8B,cAAciG,EAAAA,GAAmDtB,EAAWrF,QAGrF,MAAM4G,EAAkBvB,EAAawB,EAAAA,GAA0CxB,EAAWrF,WAAQsD,EAC5FwD,GAAkB9C,EAAAA,EAAAA,UACtB,IAAO4C,EAAkBhI,EAAK8B,cAAckG,GAA6B,OAAVvB,QAAU,IAAVA,OAAU,EAAVA,EAAYrF,MAC3E,CAACqF,EAAYuB,EAAiBhI,IAE1BmI,GAAgB/C,EAAAA,EAAAA,UACpB,IAAOqB,GAAa2B,EAAAA,EAAAA,IAAoBC,EAAAA,GAAsB5B,EAAWrF,YAASsD,GAClF,CAAC+B,KAGG,SAAEjJ,IAAaQ,EAAAA,EAAAA,KAEfsK,GAAgBlD,EAAAA,EAAAA,UAAQ,KAC5B,MAAMmD,EAAsB,OAAV9B,QAAU,IAAVA,OAAU,EAAVA,EAAY8B,UAC9B,OAAOC,EAAAA,EAAAA,UAASD,GAAa/K,EAAS+K,QAAa7D,CAAS,GAC3D,CAAC+B,EAAYjJ,IAEViL,GAAgBrD,EAAAA,EAAAA,UAAQ,MAAOU,EAAAA,EAAAA,OAAMW,KAAeiC,EAAAA,EAAAA,IAAqBjC,IAAa,CAACA,KAEvF,QAAEkC,EAAO,KAAEvJ,EAAI,YAAEwJ,IAAgBxD,EAAAA,EAAAA,UACrC,IA1OJ,SACEkC,EACAtH,EACA+C,EACA6C,EACA6C,EACAhC,EACAS,GAEA,IACI0B,EADAD,EAAgC,GAEhCvJ,GAAoBvB,EAAAA,EAAAA,GAAA8F,EAAAA,GAAA,IAExB,MAAMkF,EAAoB,CACxBF,SACE9K,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SAACC,eAAe,UAEnC5C,MAAMvB,EAAAA,EAAAA,GAACiL,EAAAA,EAAU,CAAClF,KAAGmF,EAAAA,EAAAA,IAAE,CAAEC,MAAO1B,EAAM2B,OAAOC,uBAAuB,OAGhEC,EAAmB,CACvBR,SACE9K,EAAAA,EAAAA,GAAA,QAAM+F,IAAGN,EAA0B3F,UACjCE,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SAACC,eAAe,WAGrC5C,MAAMvB,EAAAA,EAAAA,GAACuL,EAAAA,EAAW,CAACxF,KAAGmF,EAAAA,EAAAA,IAAE,CAAEC,MAAO1B,EAAM2B,OAAOI,SAAS,OAGnDtL,EAAQ0I,GAAae,EAAAA,EAAAA,IAAmCf,QAAc/B,EAG5E,GAFgB4E,QAAkB,OAAV7C,QAAU,IAAVA,OAAU,EAAVA,EAAYqB,cAGlC,OAAOe,EAGT,GAA6B,cAAzBjD,EAAeG,OAAkD,YAAzBH,EAAeG,MAAqB,CAC9E,MAAM0B,EAAY9B,EAAoBC,EAAgB7H,GACtD,IAAIwL,EAAmB,GACvB,GAA6B,cAAzB3D,EAAeG,MAEjB,IAAkB,IAAd0B,EACF8B,EAAmBvJ,EAAK8B,cAAc,CAAAC,GAAA,SACpCC,eAAe,aAGZ,KAAkB,IAAdyF,EAMT,OAAO0B,EALPI,EAAmBvJ,EAAK8B,cAAc,CAAAC,GAAA,SACpCC,eAAe,QAKnB,MACK,IAAkB,IAAdyF,EACT8B,EAAmBvJ,EAAK8B,cAAc,CAAAC,GAAA,SACpCC,eAAe,aAGZ,KAAkB,IAAdyF,EAMT,OAAO0B,EALPI,EAAmBvJ,EAAK8B,cAAc,CAAAC,GAAA,SACpCC,eAAe,SAKnB,CAEA,MAAM0F,GAAYC,EAAAA,EAAAA,IAA6BL,EAAO1B,EAAgBa,GA8BtE,GA7BArH,GACgB,IAAdqI,GACE5J,EAAAA,EAAAA,GAAC2L,EAAAA,gBAAe,CACd5F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAOtB,GACR,OAEa,IAAdD,EACFP,GACErJ,EAAAA,EAAAA,GAAC4L,EAAAA,EAAe,CACd7F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAOtB,GACR,OAGH7J,EAAAA,EAAAA,GAAC6L,EAAAA,YAAW,CACV9F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAOtB,GACR,OAIL7J,EAAAA,EAAAA,GAACuL,EAAAA,EAAW,CACVxF,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAOtB,GACR,MAIM,qBAAT3E,EAA6B,CAC/B,MAAM4G,EAAeC,EAAAA,GAA4ChE,EAAexE,MAEhF,GAAIuI,EAAc,CAAC,IAADE,EAChB,MAAMC,EAAoB/L,GACQ,QADH8L,EAC3BF,EAAa5L,EAAMgM,mBAAW,IAAAF,EAAAA,EAC9BF,EAAa3D,EAAAA,GAA2CC,KACxD6D,IACFnB,GAAU9K,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,IAAKoH,EAAmBE,OAAQ,CAAEjM,WAEjE,MACE4K,GACE1G,EAAAA,EAAAA,IAAA0B,EAAAA,GAAA,CAAAhG,SAAA,CACGiI,EAAeqE,YAAY,KAAGlM,IAIvC,KAAoB,UAATgF,IAEP4F,GADE7C,EAAAA,EAAAA,OAAM2B,IACE5J,EAAAA,EAAAA,GAAA,QAAM+F,IAAGuC,EAA0BxI,SAAE4L,IAErCA,EAGhB,MAAO,GAA6B,YAAzB3D,EAAeG,MAAqB,CAC7C,MAAMmE,GAAgBpE,EAAAA,EAAAA,OAAM/H,GAA4DA,GAAnDoM,EAAAA,EAAAA,IAAapM,GAElD,GAAa,qBAATgF,EACF4F,GACE1G,EAAAA,EAAAA,IAAA0B,EAAAA,GAAA,CAAAhG,SAAA,CACGiI,EAAeqE,YAAY,KAAGC,KAGnCtB,GACE3G,EAAAA,EAAAA,IAAA0B,EAAAA,GAAA,CAAAhG,SAAA,CACGiI,EAAeqE,YAAY,KAAGlM,SAG9B,CACL,IAAI+H,EAAAA,EAAAA,OAAMoE,GACR,OAAOf,EAETR,EAAU,GAAGuB,IACbtB,EAAc,GAAG7K,GACnB,CACF,KAAO,CAEL,IAAI+H,EAAAA,EAAAA,OAAM/H,GACR,OAAOoL,EAET,MAAMiB,GAAevM,EAAAA,EAAAA,GAAA8F,EAAAA,GAAA,CAAAhG,SAAG0M,OAAOtM,KAG3B4K,EAFS,qBAAT5F,GACE+C,EAAAA,EAAAA,OAAM/H,IACEF,EAAAA,EAAAA,GAAA8F,EAAAA,GAAA,CAAAhG,SAAGiI,EAAeqE,eAG1BhI,EAAAA,EAAAA,IAAA0B,EAAAA,GAAA,CAAAhG,SAAA,CACGiI,EAAeqE,YAAY,KAAGG,KAK3BA,CAEd,CACA,MAAO,CAAEzB,UAASvJ,OAAMwJ,cAC1B,CAuEM0B,CAA6BhD,EAAOtH,EAAM+C,EAAM6C,EAAgB6C,EAAehC,EAAYS,IAC7F,CAACI,EAAOtH,EAAM+C,EAAM6C,EAAgBa,EAAYS,EAAuBuB,IAGnE8B,GACJtI,EAAAA,EAAAA,IAAA0B,EAAAA,GAAA,CAAAhG,SAAA,CACGgL,EACAxB,GAASA,EAAQ,EAAI,KAAKA,KAAW,MAM1C,GADsD,WAAjB,QAArBC,EAAAxB,EAAe4E,cAAM,IAAApD,OAAA,EAArBA,EAAuBqD,eAAqC,OAAVhE,QAAU,IAAVA,GAAkB,QAARY,EAAVZ,EAAY+D,cAAM,IAAAnD,GAAlBA,EAAoBqD,UAEpF,OAAO7M,EAAAA,EAAAA,GAAA8F,EAAAA,GAAA,IAGT,MAAMgH,GACJ9M,EAAAA,EAAAA,GAAA,OAAAF,UACEE,EAAAA,EAAAA,GAAC+M,EAAoB,CACnB5D,SAAUA,EACVD,mBAAoBA,EACpBwD,WAAYA,EACZ5D,OAAQA,EACRvH,KAAMA,EACNsI,UAAWA,EACXE,UAAWA,EACXiD,WACEjF,EAAekF,gBACbjN,EAAAA,EAAAA,GAACkN,EAAAA,cAAa,IACZtE,GAAcgC,GAChB5K,EAAAA,EAAAA,GAACmN,EAAAA,SAAQ,KAETnN,EAAAA,EAAAA,GAACoN,EAAAA,kBAAiB,IAGtBC,iBAAiBC,EAAAA,EAAAA,IAA6C7D,EAAO1B,EAAgBa,GACrF2E,sBAAuBxE,IAAyB6B,EAChDC,qBAAsBD,EACtB/B,OAAQA,MAKd,OACE7I,EAAAA,EAAAA,GAAA8F,EAAAA,GAAA,CAAAhG,SACGsJ,EACC0D,GAEA9M,EAAAA,EAAAA,GAACwN,EAAAA,UAAS,CACRC,KAAK,SACL7L,SACEwC,EAAAA,EAAAA,IAAA,OACE2B,KAAGmF,EAAAA,EAAAA,IAAE,CACHwC,SAAU,QACVC,QAAS,OACTC,cAAe,SACfC,aAAc,aACdC,UAAW,aACXC,IAAKtE,EAAMuE,QAAQC,IACpB,IAACnO,SAAA,EAEFsE,EAAAA,EAAAA,IAAA,OACE2B,KAAGmF,EAAAA,EAAAA,IAAE,CACHyC,QAAS,OACTC,cAAe,SACfG,IAAKtE,EAAMuE,QAAQE,IACpB,IAACpO,SAAA,EAEFsE,EAAAA,EAAAA,IAAA,OACE2B,IAAGwC,EAIDzI,SAAA,EAEFsE,EAAAA,EAAAA,IAAA,OACE2B,KAAGmF,EAAAA,EAAAA,IAAE,CACHyC,QAAS,OACTI,IAAKtE,EAAMuE,QAAQC,GACnBE,WAAY,UACb,IAACrO,SAAA,EAEFE,EAAAA,EAAAA,GAACoO,EAAAA,EAAWC,MAAK,CACftI,IAAGyC,EAED1I,SAEDuK,KAEHrK,EAAAA,EAAAA,GAAC+M,EAAoB,CACnB5D,SAAUA,EACVD,mBAAoBA,EACpBwD,WAAY3B,GAA4B2B,EACxC5D,OAAQA,EACRvH,KAAMA,EACNsI,UAAWA,EACXE,UAAWA,EACXiD,WACEjF,EAAekF,gBACbjN,EAAAA,EAAAA,GAACkN,EAAAA,cAAa,IACZtE,IAAciC,EAAAA,EAAAA,IAAqBjC,IACrC5I,EAAAA,EAAAA,GAACmN,EAAAA,SAAQ,KAETnN,EAAAA,EAAAA,GAACoN,EAAAA,kBAAiB,IAGtBC,iBAAiBC,EAAAA,EAAAA,IAA6C7D,EAAO1B,EAAgBa,GACrF2E,sBAAuBxE,EACvB8B,qBAAsBD,OAGzBN,IACCtK,EAAAA,EAAAA,GAAA,KACEsO,KAAMhE,EACNhF,OAAO,SACPiJ,IAAI,aACJxI,IAAG0C,EAED3I,UAEFE,EAAAA,EAAAA,GAACwO,EAAAA,EAAa,SAInBnF,IACCrJ,EAAAA,EAAAA,GAACoO,EAAAA,EAAWK,KAAI,CAAA3O,SACbqC,EAAK8B,cAAc,CAAAC,GAAA,SAClBC,eAAe,8EAOtB6E,GAA0BJ,GAAc6B,IACvCzK,EAAAA,EAAAA,GAAA,OAAAF,UACEE,EAAAA,EAAAA,GAAA8F,EAAAA,GAAA,CAAAhG,UACEE,EAAAA,EAAAA,GAAA,QACE+F,IAAG2C,EAOHgG,wBAAyB,CAAEC,OAAQlE,SAK1CR,IACCjK,EAAAA,EAAAA,GAAA,OACE+F,KAAGmF,EAAAA,EAAAA,IAAE,CACHyC,QAAS,OACTC,cAAe,SACfG,IAAKtE,EAAMuE,QAAQE,IACpB,IAACpO,UAEFE,EAAAA,EAAAA,GAAA,QACE+F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAO1B,EAAM2B,OAAOC,sBACpBuD,UAAW,UACZ,IAAC9O,SAEDmK,SAMX4E,QAAS/B,KAGZ,EAIDC,EAAuBA,EAC3B5D,WACAD,qBACAwD,aACA5D,SACAkE,aACAzL,OACAsI,YACAE,YACAsD,kBACAE,wBACA1C,uBACAhC,aAeA,MAAM,MAAEY,IAAUC,EAAAA,EAAAA,KAEZoF,EAAU3F,EAAW,GAAK,GAEhC,OACE/E,EAAAA,EAAAA,IAAA,OACE2B,KAAGmF,EAAAA,EAAAA,IAAE,CAEHyC,QAAS,cACToB,OAAQ5F,EAAW2F,EAAU,GAC7BE,MAAO7F,EAAW2F,EAAU5F,EAAqB,cAAgB,GACjE+F,eAAgB,gBAChBd,WAAY,SACZe,QAAS/F,EAAW,IAAMN,EAAS,YAAc,QACjDkF,IAAKtE,EAAMuE,QAAQC,GACnBkB,aAAchG,EAAW,MAAQM,EAAM2F,cAAcC,eACrDhC,gBAAiBA,EACjBiC,UAAW,qBAAqBxG,EAASW,EAAM2B,OAAOmE,iBAAmB,gBAEzEC,SAAU/F,EAAMgG,WAAWC,WAC3BC,IAAK,CAAEX,MAAOF,EAASC,OAAQD,GAC/Bc,WAAY,UACb,IAAC9P,SAAA,CAEDyB,EACAmL,IACC1M,EAAAA,EAAAA,GAAA,QACE+F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAOpB,GACR,IAACjK,SAED4M,KAGsB,IAA1Ba,GACCvN,EAAAA,EAAAA,GAAA,QACE+F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAOtB,GACR,IAAC/J,SAEDkN,KAGHhN,EAAAA,EAAAA,GAAA8F,EAAAA,GAAA,IAED+C,IACC7I,EAAAA,EAAAA,GAACsB,EAAAA,EAAM,CACLb,YAAY,mDACZe,QAASqH,EACTpH,KAAK,QACLF,MACEvB,EAAAA,EAAAA,GAAC6P,EAAAA,WAAU,CACT9J,KAAGmF,EAAAA,EAAAA,IAAE,CACH,SAAU,CACRC,MAAO1B,EAAM2B,OAAO0E,yBAEvB,UAKL,C,0PC1iBH,MAAMC,EAA2C,CAEtDC,GAAI,YAEJC,KAAM,aAIKC,EAAoC,UAGpCC,EAAoB,UACpBC,EAAuB,UAE9BC,EAA0B,UAC1BC,EAA0B,UAG1BC,EAAiB,YAEVzG,EAA+BA,CAC1CL,EACA1B,EACAa,KAEA,GAA6B,cAAzBb,EAAeG,MAAuB,CAExC,IAAc,OAAVU,QAAU,IAAVA,OAAU,EAAVA,EAAY4H,eAAgBrI,EAAAA,GAA2CC,IACzE,OAAOqB,EAAMgH,WAAahH,EAAM2B,OAAOsF,SAAWjH,EAAM2B,OAAOuF,SAEjE,IAAc,OAAV/H,QAAU,IAAVA,OAAU,EAAVA,EAAY4H,eAAgBrI,EAAAA,GAA2CE,GACzE,OAAOoB,EAAMgH,WAAahH,EAAM2B,OAAOwF,OAASnH,EAAM2B,OAAOyF,MAEjE,CACA,OAAc,OAAVjI,QAAU,IAAVA,GAAAA,EAAYqB,aACPR,EAAM2B,OAAOC,sBAEf5B,EAAM2B,OAAOI,OAAO,EAGhB8B,EAA+CA,CAC1D7D,EACA1B,EACAa,EACAO,GAAW,KAEX,GAA6B,cAAzBpB,EAAeG,MAAuB,CAExC,IAAc,OAAVU,QAAU,IAAVA,OAAU,EAAVA,EAAY4H,eAAgBrI,EAAAA,GAA2CC,IACzE,OAAOmI,EAET,IAAc,OAAV3H,QAAU,IAAVA,OAAU,EAAVA,EAAY4H,eAAgBrI,EAAAA,GAA2CE,GACzE,OAAOoB,EAAMgH,YAAaK,EAAAA,EAAAA,IAAUrH,EAAM2B,OAAO2F,OAAQ,IAAOtH,EAAM2B,OAAO4F,OAE/E,IAAK7H,GAAsB,OAAVP,QAAU,IAAVA,GAAAA,EAAYqB,aAC3B,MAAO,EAEX,MAAO,GAA6B,YAAzBlC,EAAeG,MACxB,OAAID,EAAAA,EAAAA,OAAgB,OAAVW,QAAU,IAAVA,OAAU,EAAVA,EAAYqI,cACb,GAEFrI,EAAWqI,aAAeV,EAAiB9G,EAAMgH,WAAahH,EAAM2B,OAAO2F,OAAStH,EAAM2B,OAAO4F,OAE1G,MAAO,EAAE,EAGEhH,EAA+BA,CAC1CP,EACA1B,EACAa,IAEc,OAAVA,QAAU,IAAVA,GAAAA,EAAYqB,aACPR,EAAM2B,OAAOC,sBAGO,cAAzBtD,EAAeG,OAEH,OAAVU,QAAU,IAAVA,OAAU,EAAVA,EAAY4H,eAAgBrI,EAAAA,GAA2CC,IAClEqB,EAAMgH,WAAahH,EAAM2B,OAAOsF,SAAWjH,EAAM2B,OAAOuF,UAC5C,OAAV/H,QAAU,IAAVA,OAAU,EAAVA,EAAY4H,eAAgBrI,EAAAA,GAA2CE,GACzEoB,EAAMgH,WAAahH,EAAM2B,OAAOwF,OAASnH,EAAM2B,OAAOyF,OAEtDpH,EAAM2B,OAAO8F,cAEY,YAAzBnJ,EAAeG,OACpBD,EAAAA,EAAAA,OAAgB,OAAVW,QAAU,IAAVA,OAAU,EAAVA,EAAYqI,cACbxH,EAAM2B,OAAO8F,cAEfzH,EAAM2B,OAAO+F,YACc,YAAzBpJ,EAAeG,MACjBuB,EAAM2B,OAAO8F,cAEfzH,EAAM2B,OAAO+F,YAGTC,EAAuCA,CAClD3H,EACA1B,EACAC,EACAqJ,IAEIA,EArF2B,UAwFF,cAAzBtJ,EAAeG,MAEbF,IAAoBG,EAAAA,GAA2CC,IAC1DiI,EAELrI,IAAoBG,EAAAA,GAA2CE,GAC1DiI,EAEF7G,EAAMgH,WAAahH,EAAM2B,OAAOkG,QAAU7H,EAAM2B,OAAOmG,QAC5B,YAAzBxJ,EAAeG,OACpBD,EAAAA,EAAAA,OAAMD,GACDyB,EAAMgH,WAAahH,EAAM2B,OAAOkG,QAAU7H,EAAM2B,OAAOmG,QAEzDvJ,EAAkBqI,EAA0BC,EAE9C7G,EAAMgH,WAAahH,EAAM2B,OAAOkG,QAAU7H,EAAM2B,OAAOmG,O,uEC7HhE,MAKaC,EAAyBA,EACpCjL,aACAD,cACAD,oBAMOrC,EAAAA,EAAAA,cACJyN,IACC,GAAIA,EAAqB,CACvB,MAAM,aAAEC,EAAY,UAAEC,EAAS,aAAEC,GAAiBH,EAC9CC,EAAeC,EAAYC,EAlBD,MAkBkDrL,GAAcD,GAC5FD,GAEJ,IAEF,CAACA,EAAeE,EAAYD,G,26BCRzB,MACDuL,EAAqB,WAEpB,IAAKC,EAAmC,SAAnCA,GAAmC,OAAnCA,EAAmC,wCAAnCA,EAAmC,gBAAnCA,EAAmC,4BAAnCA,EAAmC,gDAAnCA,EAAmC,0BAAnCA,EAAmC,wCAAnCA,EAAmC,kCAAnCA,EAAmC,0CAAnCA,EAAmC,0CAAnCA,EAAmC,8CAAnCA,EAAmC,0CAAnCA,EAAmC,wBAAnCA,EAAmC,wDAAnCA,CAAmC,MAgBxC,MAAMC,EAA2C,CACtDD,EAAoCE,mBAEpCF,EAAoCG,YACpCH,EAAoCI,2BACpCJ,EAAoCK,oBACpCL,EAAoCM,WACpCN,EAAoCO,mBACpCP,EAAoCQ,oBACpCR,EAAoCS,sBACpCT,EAAoCU,gBACpCV,EAAoCW,oBACpCX,EAAoCY,aACpCZ,EAAoCa,uBACpCb,EAAoCc,QAGzBrI,EAAuBsI,GAE3B,uEAaIrI,EAAiE,CAC5E,CAACsH,EAAoCE,oBAAqB,CAExDc,SAAU,oDACVC,KAAM,yCAER,CAACjB,EAAoCG,aAAc,CACjDa,SAAU,sDACVC,KAAM,eAER,CAACjB,EAAoCY,cAAe,CAClDI,SAAU,sDACVC,KAAM,gBAER,CAACjB,EAAoCa,wBAAyB,CAC5DG,SAAU,sDACVC,KAAM,gBAER,CAACjB,EAAoCO,oBAAqB,CACxDS,SAAU,sDACVC,KAAM,oBAER,CAACjB,EAAoCc,QAAS,CAC5CE,SAAU,sDACVC,KAAM,UAER,CAACjB,EAAoCU,iBAAkB,CACrDM,SAAU,sDACVC,KAAM,6BAER,CAACjB,EAAoCW,qBAAsB,CACzDK,SAAU,sDACVC,KAAM,6BAER,CAACjB,EAAoCQ,qBAAsB,CACzDQ,SAAU,sDACVC,KAAM,uBAER,CAACjB,EAAoCS,uBAAwB,CAC3DO,SAAU,sDACVC,KAAM,uBAER,CAACjB,EAAoCK,qBAAsB,CACzDW,SAAU,sDACVC,KAAM,uBAER,CAACjB,EAAoCM,YAAa,CAChDU,SAAU,sDACVC,KAAM,wBAIH,IAAK5K,EAA0C,SAA1CA,GAA0C,OAA1CA,EAA0C,UAA1CA,EAA0C,QAA1CA,EAA0C,kBAA1CA,CAA0C,MAM/C,SAAS6K,EACd7Q,EACAsH,EACA1B,EACA7H,GAEA,MAA6B,cAAzB6H,EAAeG,MACbhI,IAAUiI,EAA2CC,IAChD,CACLxG,QAASO,EAAK8B,cAAc,CAAAC,GAAA,SAC1BC,eAAe,SAGjB5C,MACEvB,EAAAA,EAAAA,GAAA,QACE+F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAO,IAAGrB,EAAAA,EAAAA,IAA6BL,EAAO1B,EAAgB,CAC5DyI,YAAarI,EAA2CC,mBAE1DuH,IAAK,CACHX,MAAO,OACPD,OAAQ,SAEX,IAACjP,UAEFE,EAAAA,EAAAA,GAAC2L,EAAAA,gBAAe,CACd5F,KAAGmF,EAAAA,EAAAA,IAAE,CACHmC,iBAAiBC,EAAAA,EAAAA,IAA6C7D,EAAO1B,EAAgB,CACnFyI,YAAarI,EAA2CC,MAE1D+G,aAAc,OACf,SAKAjP,IAAUiI,EAA2CE,GACvD,CACLzG,QAASO,EAAK8B,cAAc,CAAAC,GAAA,SAC1BC,eAAe,SAGjB5C,MACEvB,EAAAA,EAAAA,GAAA,QACE+F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAO,IAAGrB,EAAAA,EAAAA,IAA6BL,EAAO1B,EAAgB,CAC5DyI,YAAarI,EAA2CE,kBAE1DsH,IAAK,CACHX,MAAO,OACPD,OAAQ,SAEX,IAACjP,UAEFE,EAAAA,EAAAA,GAAC6L,EAAAA,YAAW,CACV9F,KAAGmF,EAAAA,EAAAA,IAAE,CACHmC,iBAAiBC,EAAAA,EAAAA,IAA6C7D,EAAO1B,EAAgB,CACnFyI,YAAarI,EAA2CE,KAE1D8G,aAAc,OACf,SAMF,CACLvN,QAASO,EAAK8B,cAAc,CAAAC,GAAA,SAC1BC,eAAe,YAGjB5C,MACEvB,EAAAA,EAAAA,GAAA,QACE+F,KAAGmF,EAAAA,EAAAA,IAAE,CACHC,MAAO,IAAGrB,EAAAA,EAAAA,IAA6BL,EAAO1B,EAAgB,CAC5DyI,YAAarI,EAA2C8K,uBAE1DtD,IAAK,CACHX,MAAO,OACPD,OAAQ,SAEX,IAACjP,UAEFE,EAAAA,EAAAA,GAACuL,EAAAA,EAAW,CACVxF,KAAGmF,EAAAA,EAAAA,IAAE,CACHmC,iBAAiBC,EAAAA,EAAAA,IAA6C7D,EAAO1B,EAAgB,CACnFyI,YAAarI,EAA2C8K,UAE1D9D,aAAc,OACf,SAMuB,YAAzBpH,EAAeG,OACV,IAAVhI,EACK,CACL0B,QAASO,EAAK8B,cAAc,CAAAC,GAAA,SAC1BC,eAAe,WAIA,IAAVjE,EACF,CACL0B,QAASO,EAAK8B,cAAc,CAAAC,GAAA,SAC1BC,eAAe,WAKZ,CACLvC,QAASO,EAAK8B,cAAc,CAAAC,GAAA,SAC1BC,eAAe,UAMhB,CACLvC,QAAS,GAAG1B,IAEhB,CAEO,IAAKgT,EAA6C,SAA7CA,GAA6C,OAA7CA,EAA6C,8CAA7CA,EAA6C,0BAA7CA,EAA6C,sCAA7CA,CAA6C,MAMlD,MAAMC,EAAgF,CAC3FC,UAAUC,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACtBC,eAAe,kBAKNmP,EAA4B,iBAE5BC,EAAgF,CAC3FC,mBAAmBH,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC/BC,eAAe,oBAGjB,CAACmP,IAA4BD,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACzCC,eAAe,oBAKNiG,EAA+E,CAC1F,CAAC0H,EAAoCE,qBAAqBqB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACtEC,eAAe,YAGjB,CAAC2N,EAAoCG,cAAcoB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC/DC,eAAe,gBAIjB,CAAC2N,EAAoCY,eAAeW,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAChEC,eAAe,iBAIjB,CAAC2N,EAAoCa,yBAAyBU,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC1EC,eAAe,2BAIjB,CAAC2N,EAAoCQ,sBAAsBe,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACvEC,eAAe,wBAIjB,CAAC2N,EAAoCS,wBAAwBc,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACzEC,eAAe,0BAIjB,CAAC2N,EAAoCO,qBAAqBgB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACtEC,eAAe,cAIjB,CAAC2N,EAAoCc,SAASS,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC1DC,eAAe,WAIjB,CAAC2N,EAAoCU,kBAAkBa,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACnEC,eAAe,oBAIjB,CAAC2N,EAAoCW,sBAAsBY,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACvEC,eAAe,wBAIjB,CAAC2N,EAAoCK,sBAAsBkB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACvEC,eAAe,wBAIjB,CAAC2N,EAAoCM,aAAaiB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,eAIjB,CAAC2N,EAAoCI,6BAA6BmB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9EC,eAAe,gCAMN+F,EAAwF,CACnG,CAAC4H,EAAoCG,cAAcoB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC/DC,eAAe,0IAKjB,CAAC2N,EAAoCY,eAAeW,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAChEC,eAAe,8GAKjB,CAAC2N,EAAoCa,yBAAyBU,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC1EC,eAAe,wHAKjB,CAAC2N,EAAoCQ,sBAAsBe,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACvEC,eAAe,qHAKjB,CAAC2N,EAAoCS,wBAAwBc,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACzEC,eAAe,wHAONsP,EAAqF,CAChG,CAAC3B,EAAoCE,qBAAqBqB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACtEC,eAAe,+DAIjB,CAAC2N,EAAoCG,cAAcoB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC/DC,eAAe,+NAKjB,CAAC2N,EAAoCY,eAAeW,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAChEC,eAAe,+KAIjB,CAAC2N,EAAoCa,yBAAyBU,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC1EC,eAAe,yLAKjB,CAAC2N,EAAoCO,qBAAqBgB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACtEC,eAAe,uGAIjB,CAAC2N,EAAoCc,SAASS,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC1DC,eAAe,yIAIjB,CAAC2N,EAAoCU,kBAAkBa,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACnEC,eAAe,mcAIjB,CAAC2N,EAAoCW,sBAAsBY,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACvEC,eAAe,6bAIjB,CAAC2N,EAAoCQ,sBAAsBe,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACvEC,eAAe,gIAIjB,CAAC2N,EAAoCS,wBAAwBc,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACzEC,eAAe,kIAIjB,CAAC2N,EAAoCK,sBAAsBkB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SACvEC,eAAe,0GAIjB,CAAC2N,EAAoCM,aAAaiB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,0IAIjB,CAAC2N,EAAoCI,6BAA6BmB,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9EC,eAAe,yKAMN4H,EAAiG,CAC5G,CAAC+F,EAAoCE,oBAAqB,CACxD,CAAC7J,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,SAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,UAKnB,CAAC2N,EAAoCU,iBAAkB,CACrD,CAACrK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,aAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,gBAKnB,CAAC2N,EAAoCW,qBAAsB,CACzD,CAACtK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,aAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,gBAKnB,CAAC2N,EAAoCQ,qBAAsB,CACzD,CAACnK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,uBAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,0BAKnB,CAAC2N,EAAoCS,uBAAwB,CAC3D,CAACpK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,eAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,kBAKnB,CAAC2N,EAAoCO,oBAAqB,CACxD,CAAClK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,aAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,gBAKnB,CAAC2N,EAAoCY,cAAe,CAClD,CAACvK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,aAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,kBAKnB,CAAC2N,EAAoCa,wBAAyB,CAC5D,CAACxK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,aAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,kBAKnB,CAAC2N,EAAoCG,aAAc,CACjD,CAAC9J,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,YAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,eAKnB,CAAC2N,EAAoCc,QAAS,CAC5C,CAACzK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,SAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,YAKnB,CAAC2N,EAAoCK,qBAAsB,CACzD,CAAChK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,0BAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,yBAKnB,CAAC2N,EAAoCM,YAAa,CAChD,CAACjK,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,0BAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,yBAKnB,CAAC2N,EAAoCI,4BAA6B,CAChE,CAAC/J,EAA2CC,MAAMiL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC9DC,eAAe,iCAIjB,CAACgE,EAA2CE,KAAKgL,EAAAA,EAAAA,IAAc,CAAAnP,GAAA,SAC7DC,eAAe,iCAOfuP,EAA2B9K,IAA+C,IAADY,EAC7E,MAA0C,cAAzB,OAAVZ,QAAU,IAAVA,GAAkB,QAARY,EAAVZ,EAAY+D,cAAM,IAAAnD,OAAR,EAAVA,EAAoBoD,WAAyB,EAQzC+G,EAA4BC,IAEvC,IAAIhP,EAAQiP,EAA8BD,EAvlBX,WAsmB/B,OAbI3L,EAAAA,EAAAA,OAAMrD,KACRA,EAAQiP,EAA8BD,EAAY/B,KAIhD5J,EAAAA,EAAAA,OAAMrD,MAAWqD,EAAAA,EAAAA,OAAM2L,EAAWE,SAAWC,OAAOC,KAAKJ,EAAWE,QAAQG,OAAS,IACvFrP,EAAQsP,EAAeN,EAAWE,WAGhC7L,EAAAA,EAAAA,OAAMrD,IAAoB,KAAVA,KAClBA,EAAQgP,EAAWO,cAGdvP,CAAK,EAQDiP,EAAgCA,CAC3CD,EACAQ,KACwB,IAADC,EAAAC,EACvB,KAAKrM,EAAAA,EAAAA,OAAM2L,EAAWW,aACpB,MAAyC,kBAA3BX,EAAWW,YAA2BX,EAAWW,YAAcC,KAAKC,UAAUb,EAAWW,aAGzG,IAAI3P,EAEJ,MAAM8P,EAAQd,EAAWE,OAAOM,GAM7B,IAADO,EALF,IACEC,EAAAA,EAAAA,eAAcF,MACbzM,EAAAA,EAAAA,OAAMyM,EAAM7C,KACbgD,MAAMC,QAAQJ,EAAM7C,OACnB5J,EAAAA,EAAAA,OAAkC,QAA7BoM,EAACK,EAAM7C,GAAoB,UAAE,IAAAwC,OAAA,EAA5BA,EAA8BzS,SAErCgD,EAAuE,QAAlE+P,EAAGD,EAAM7C,GAAoB6C,EAAM7C,GAAoBoC,OAAS,UAAE,IAAAU,OAAA,EAA/DA,EAAiE/S,aACpE,IAAKqG,EAAAA,EAAAA,OAAMyM,KAAUG,MAAMC,QAAQJ,KAAWzM,EAAAA,EAAAA,OAAc,QAATqM,EAACI,EAAM,UAAE,IAAAJ,OAAA,EAARA,EAAU1S,SAInEgD,EAAQ8P,EAAQR,EAAeQ,QAAS7N,MAJqC,CAAC,IAADkO,EAE7EnQ,EAA+B,QAA1BmQ,EAAGL,EAAMA,EAAMT,OAAS,UAAE,IAAAc,OAAA,EAAvBA,EAAyBnT,OACnC,CAIA,OAAOgD,CAAK,EAGDoQ,EAAuCC,IAA8C,IAAAC,EAAA,OACI,KAA5E,QAAxBA,EAAAD,EAAgBE,gBAAQ,IAAAD,OAAA,EAAxBA,EAA2BhC,EAA8CkC,uBAA+B,EAE7FC,EAAiDJ,IAA8C,IAAAK,EAAA,OAC1GC,EAAAA,EAAAA,UAAiC,QAAzBD,EAACL,EAAgBE,gBAAQ,IAAAG,OAAA,EAAxBA,EAA2BpC,EAA8CsC,aAAa,EAEpF7L,EACXf,IACqC,IAADnD,EAAAgQ,EACpC,MAAMvV,EAAyD,QAApDuF,EAAyB,QAAzBgQ,EAAG7M,EAAW4H,mBAAW,IAAAiF,EAAAA,EAAI7M,EAAW8M,oBAAY,IAAAjQ,EAAAA,EAAImD,EAAWqI,aAC9E,KAAIhJ,EAAAA,EAAAA,OAAM/H,GAGV,OAAOA,CAAK,EAMP,SAAS4Q,EAAU6E,EAAkBC,GAC1C,IAAIzK,EAAQwK,EACZ,MAAME,EAAiB1K,EAAM2K,WAAW,KACpCD,IACF1K,EAAQwK,EAASI,MAAM,IAIzB,MAAO,GAAGF,EAAiB,IAAM,KAAK1K,IAFxB6K,KAAKC,MAA0C,IAApCD,KAAKE,IAAIF,KAAKG,IAAIP,EAAS,GAAI,IACjC1J,SAAS,IAAIkK,eAEtC,CAKO,MAAMC,EAAyC,CACpDvE,EAAoCK,oBACpCL,EAAoCM,WACpCN,EAAoCI,2BACpCJ,EAAoCO,mBACpCP,EAAoCQ,oBACpCR,EAAoCS,sBACpCT,EAAoCG,YACpCH,EAAoCY,aACpCZ,EAAoCa,uBACpCb,EAAoCc,QAMzB0D,EAA0C,CAACxE,EAAoCU,iBAK/E+D,EAA8CA,EACzDhT,OACAiT,sBACAtW,QACAwK,YACAyK,WAAW,CAAC,MAO6B,IAADsB,EAExC,MAAM5J,EAAoB,QAAZ4J,GAAGC,EAAAA,EAAAA,YAAS,IAAAD,EAAAA,EAAI,GAS9B,MAAO,CACLxF,aAJoC,mBAAV/Q,EAAsBA,EAAQ,KAKxDwV,aAAc,KACdlF,YALmC,mBAAVtQ,EAAsBA,EAAQ,KAMvDqD,OACA4R,SAZqBqB,EACnB,IAAKrB,EAAU,CAACjC,EAA8CkC,wBAAwB,GACtFD,EAWFzK,UAAoB,OAATA,QAAS,IAATA,EAAAA,EAAa,KACxBiC,OAAQ,CACNE,WACAD,WAAY,QACZuI,SAAU,CAAC,GAEbwB,UAAWC,KAAKC,MAChBC,SAAS,EACV,EAGUC,EAAkDA,CAC7DC,EACAC,IAEAD,EAAuBE,mBAAmBjD,OAAS,GACnD+C,EAAuBE,mBAAmBC,MAAMzD,KAC/CuD,EAAyBG,KAAKpC,GAEpBqC,EACXL,IAC+C,IAADM,EAC9C,MAAMC,EAA2BP,EAAuBE,mBAAmBM,KAAK9D,GAEhF,IAAK6D,EACH,OAAO,KAGT,MAAM1K,EAAoB,QAAZyK,GAAGZ,EAAAA,EAAAA,YAAS,IAAAY,EAAAA,EAAI,GAE9B,MAAO,IACFC,EACHZ,UAAWC,KAAKC,MAChBC,SAAS,EACTnK,OAAQ,CACNC,WAAY,QACZC,WACAsI,SAAU,CAAC,GAEbA,SAAU,IACLoC,EAAyBpC,SAE5B,CAACjC,EAA8CuE,oBAAoB,GAEtE,EAGUC,EACX9O,GACqD,YAAaA,GAAcA,EAAWkO,QAShFa,EAAyBC,IACpCC,EAAAA,EAAAA,SAAQ9D,OAAO+D,QAAQF,IAAoB,EAAEG,EAAKC,GAAcC,KAG9D,MAAMC,EAAoBnG,EAA+BoG,QAAQJ,GAEjE,OAA2B,IAAvBG,EAEKA,EAG8C,QAArDE,EAA0C,QAA1CC,EAAOL,EAAYA,EAAY/D,OAAS,UAAE,IAAAoE,OAAA,EAAnCA,EAAqC1B,iBAAS,IAAAyB,EAAAA,EAAIH,EAFnD,IAADG,EAAAC,CAGP,IAGSC,EAAqCC,IAA8C,IAAAC,EAAAC,EAAA,OAGjC,QAHiCD,EAC3D,QAD2DC,EAC9FF,EAAiBrB,0BAAkB,IAAAuB,OAAA,EAAnCA,EACIC,QAAQ9P,IAAgB8O,EAAkB9O,KAC3CwO,MAAMxO,IAAgB8K,EAAwB9K,YAAY,IAAA4P,GAAAA,CAAS,EAE3D3N,EAAwBjC,IAAyC,IAAA+P,EAAAC,EAAA,MAE1C,WAAjB,QAAjBD,EAAA/P,EAAW+D,cAAM,IAAAgM,OAAA,EAAjBA,EAAmB/L,eACC,QAApBgM,EAAChQ,EAAWuM,gBAAQ,IAAAyD,GAAnBA,EAAsB1F,EAA8CuE,mBAAkB,EAE5EoB,EAA2CjQ,IAAyC,IAAAkQ,EAAA,OAC5E,QAD4EA,EAC/FlQ,EAAWuM,gBAAQ,IAAA2D,OAAA,EAAnBA,EAAsB5F,EAA8CsC,YAAY,EAoBrEtB,EAAkBhU,IACtB0U,EAAAA,EAAAA,eAAc1U,IAAU2U,MAAMC,QAAQ5U,GAASsU,KAAKC,UAAUvU,OAAO2G,EAAW,GAAK3G,EAMjF6Y,EAAgCA,CAC3C5W,EACA6W,EACAC,EACAC,KAGA,GAAIF,EAAoB,CACtB,MAAMG,EAAUpN,EAA4CiN,EAAmBzV,MAC/E,OAAK4V,EAIEpF,OAAO+D,QAAQqB,GAASC,KAAI,EAAErB,EAAK7X,MACjC,CAAE6X,MAAKsB,MAAOlX,EAAK8B,cAAc/D,GAAQoZ,mBAAoBN,EAAmBzV,SAJhF,EAMX,CAGA,OAAQ2V,GAAmB,IACxBR,QAAQ3Q,GAA4C,YAAzBA,EAAeG,QAC1CkR,KAAKrR,IAAc,CAClBgQ,IAAKhQ,EAAexE,KACpB8V,MAAOtR,EAAexE,KACtB+V,mBAAoBvR,EAAexE,KAEnCoB,SAA2B,OAAjBsU,QAAiB,IAAjBA,OAAiB,EAAjBA,EAAmB7B,MAAMxO,GAAeA,EAAWrF,OAASwE,EAAexE,UACpF,EAOMgW,EAAuB3Q,IAClC,GAAKA,EAEE,CACL,MAAM4Q,EAAe/N,QAAQ7C,EAAW8B,WAClC+O,IAAYxR,EAAAA,EAAAA,OAAM0B,EAAmCf,IACrD8Q,EAAkBjO,QAAQ7C,EAAWqB,cAC3C,QAASuP,GAAgBC,GAAYC,EACvC,CANE,OAAO,CAMT,EAOWC,EAAsBzZ,GAC1B2U,MAAMC,QAAQ5U,IAAUA,EAAMiX,OAAOyC,IAAMhF,EAAAA,EAAAA,eAAcgF,IAAM,YAAaA,GAAK,YAAaA,G,uPCh2BhG,MAAMC,EAAY,QAElB,SAASC,EAA4BlR,GAC1C,OAAO6C,SAAkB,OAAV7C,QAAU,IAAVA,OAAU,EAAVA,EAAYmR,aAAuB,OAAVnR,QAAU,IAAVA,OAAU,EAAVA,EAAYqB,cACtD,CAEA,SAAS+P,EAAiCC,GAGxC,MAAMC,EAASD,EAAeE,MAAM,KACpC,OAAsB,IAAlBD,EAAOjG,OACF,CAAEmG,WAAYH,EAAgBI,eAAgBJ,GAC1B,IAAlBC,EAAOjG,OACT,CAAEmG,WAAYF,EAAO,GAAIG,eAAgBH,EAAO,IAEhD,CAAEE,WAAYF,EAAO,GAAIG,eAAgBH,EAAOnE,MAAM,GAAGuE,KAAK,KAEzE,CAEA,MAAMC,EAA6B,CACjCpS,EAAAA,GAA2CC,IAC3CD,EAAAA,GAA2CE,IAKtC,SAASmS,EACdrY,EACAsY,EACAC,GACmB,IAADC,EAClB,MAAMzB,EAAkD,CAAC,EAEnD0B,EAAgE,CACpE,CAAC9I,EAAAA,GAAoCE,oBAAqB,aAGtD6I,EAAkB,IAAIC,IAE5B,IAAIL,KAA8BC,GAA0B,IAAKK,SAASC,IAAY,IAADC,EACnF,MAAMC,EAAyEnH,OAAO+D,QACpFkD,EAAOE,2BAA6B,CAAC,GAGjCC,EAAwEH,EAAO9D,mBAAmBkC,KACrGxQ,GAAe,CAACkJ,EAAAA,GAAoCE,mBAA8B,CAACpJ,MAEhFwS,EAA0E,GAC1D,QAAtBH,EAAAD,EAAOK,uBAAe,IAAAJ,GAAtBA,EAAwBF,SAASO,IAE/B,IAAK,MAAOjB,EAAgBrC,KAAgBjE,OAAO+D,QAAQwD,EAAMF,4BAA8B,CAAC,GAC9FA,EAA2BG,KAAK,CAAClB,EAAgBrC,GACnD,IAGF,IAAK,MAAOqC,EAAgBrC,IAAgB,IACvCkD,KACAC,KACAC,GACF,CACDP,EAAgBW,IAAInB,GACpB,MAAMzR,EAAaoP,EAAY,GAG/B,IAAI9P,GAAsCD,EAAAA,EAAAA,OAAMW,EAAW4H,cAEtDvI,EAAAA,EAAAA,OAAMW,EAAW8M,eAEjBzN,EAAAA,EAAAA,OAAMW,EAAWqI,mBAElBpK,EADA,UAFA,UAFA,YAOAiT,EAA4BlR,KAC9BV,OAAQrB,GAGL+T,EAAiBP,KAChBA,KAAkBjQ,EAAAA,KACpBlC,EAAQ,aAEV0S,EAAiBP,GAAkBnS,GAKzB,cAAVA,IACCD,EAAAA,EAAAA,OAAMW,EAAW4H,cACjB+J,EAAiBkB,SAAS7S,EAAW4H,eAEtCoK,EAAiBP,GAAkB,eAKvBxT,IAAVqB,GAAuBA,IAAU0S,EAAiBP,KACpDO,EAAiBP,GAAkB,SAEvC,KAIF,IAAK,MAAMA,KAAkBQ,EACtBD,EAAiBP,KACpBO,EAAiBP,GAAkB,WAIvC,IAAII,KAA8BC,GAA0B,IAAKK,SAASC,IAAY,IAADU,EACnF,MAAMR,EAAyEnH,OAAO+D,QACpFkD,EAAOE,2BAA6B,CAAC,GAGjCC,EAAwEH,EAAO9D,mBAAmBkC,KACrGxQ,GAAe,CAACkJ,EAAAA,GAAoCE,mBAA8B,CAACpJ,MAEhFwS,EAA0E,GAC1D,QAAtBM,EAAAV,EAAOK,uBAAe,IAAAK,GAAtBA,EAAwBX,SAASO,IAE/B,IAAK,MAAOjB,EAAgBrC,KAAgBjE,OAAO+D,QAAQwD,EAAMF,4BAA8B,CAAC,GAC9FA,EAA2BG,KAAK,CAAClB,EAAgBrC,GACnD,IAGF,MAAM6C,EAAkB9G,OAAOC,KAAK4G,GACpC,IAAK,MAAMP,KAAkBQ,EAAiB,CAC5C,MAOMjS,EAPoB,IACrBsS,EAA0BxC,QAAO,EAAEnV,KAAUA,IAAS8W,OACtDc,EAAyBzC,QAAO,EAAEnV,KAAUA,IAAS8W,OACrDe,EAA2B1C,QAAO,EAAEnV,KAAUA,IAAS8W,KAGtBjB,KAAI,EAAEuC,EAAG3D,KAAiBA,EAAY,KACF,GAEpE3G,EAAUyI,EAA4BlR,GAE5C,IAAIX,EAAAA,EAAAA,OAAMiR,EAAgBmB,IAAkB,CAAC,IAAD1B,EAAAiD,EAAAC,EAC1C,IAAIzP,EACAgO,EACAnN,GAAiB,EAErB,MAAM6O,OAAwEjV,IAA9DuD,EAAAA,GAA0CiQ,GAC1D,GAAIyB,EACF1P,EAAcjK,EAAK8B,cAAcmG,EAAAA,GAA0CiQ,IAC3ED,EAAaC,EACbpN,GAAiB,MACZ,CAAC,IAADzD,EACL,MAAQ4Q,WAAY2B,EAAkB1B,eAAgB2B,GACpDhC,EAAiCK,GACnCjO,EAAc4P,GAAwB,IACtC5B,EAAa2B,EAC0B,UAAzB,OAAVnT,QAAU,IAAVA,GAAkB,QAARY,EAAVZ,EAAY+D,cAAM,IAAAnD,OAAR,EAAVA,EAAoBoD,cACtBK,GAAiB,EAErB,CACA,MAAM/E,EAAQ0S,EAAiBP,IAAmB,SAE5C4B,GAAW1R,EAAAA,EAAAA,IAAoBC,EAAAA,GAAsB6P,IACrD6B,EACJ7B,KAAkBnQ,EAAAA,GACd/H,EAAK8B,cAAciG,EAAAA,GAAmDmQ,IACtE,GACA8B,EACJ9B,KAAkB5G,EAAAA,GACdtR,EAAK8B,cAAcwP,EAAAA,GAAgD4G,IAChC,WAAzB,OAAVzR,QAAU,IAAVA,GAAkB,QAAR+P,EAAV/P,EAAY+D,cAAM,IAAAgM,OAAR,EAAVA,EAAoB/L,YACpBzK,EAAK8B,cAAc,CAAAC,GAAA,SACjBC,eAAe,kDAGjBhC,EAAK8B,cAAc,CAAAC,GAAA,SACjBC,eAAe,oDAIvB,IAAI6D,EAAkBY,GAAae,EAAAA,EAAAA,IAAmCf,QAAc/B,EAC5D,OAApBmB,IAA0BA,OAAkBnB,GAEhD,MAAMuV,EAAe,IAAItB,IACpBzJ,GACH+K,EAAaZ,IAAIxT,GAGnBkR,EAAgBmB,GAAkB,CAChC9W,KAAM8W,EACNjO,YAAaA,EACb0P,UACA1B,aACAnN,iBACAN,OAAkB,OAAV/D,QAAU,IAAVA,OAAU,EAAVA,EAAY+D,OACpBzE,QACAkU,eACAC,UAAWhC,IAAmBvI,EAAAA,GAAoCE,mBAClEiK,WACAC,iBACAC,cACAG,WAA+C,cAAzB,OAAV1T,QAAU,IAAVA,GAAkB,QAARgT,EAAVhT,EAAY+D,cAAM,IAAAiP,OAAR,EAAVA,EAAoBhP,aAAgE,WAAzB,OAAVhE,QAAU,IAAVA,GAAkB,QAARiT,EAAVjT,EAAY+D,cAAM,IAAAkP,OAAR,EAAVA,EAAoBjP,YACjF2P,sBAAuBnB,EAA2BhE,MAAK,EAAE7T,KAAUA,IAAS8W,IAC5EmC,eAAgBnL,EAEpB,KAAO,CACL,MAAMtJ,EAAiBmR,EAAgBmB,GACvC,IAAIna,EAAQ0I,GAAae,EAAAA,EAAAA,IAAmCf,QAAc/B,EAOzC,IAAD4V,EAAAC,EAAhC,IANIzU,EAAAA,EAAAA,OAAM/H,KAAQA,OAAQ2G,GACrBwK,GACHtJ,EAAeqU,aAAaZ,IAAItb,IAI7B6H,EAAeuU,WAClBvU,EAAeuU,WACsB,cAAzB,OAAV1T,QAAU,IAAVA,GAAkB,QAAR6T,EAAV7T,EAAY+D,cAAM,IAAA8P,OAAR,EAAVA,EAAoB7P,aAAgE,WAAzB,OAAVhE,QAAU,IAAVA,GAAkB,QAAR8T,EAAV9T,EAAY+D,cAAM,IAAA+P,OAAR,EAAVA,EAAoB9P,YAIzE7E,EAAewU,sBACbxU,EAAewU,uBAAyBnB,EAA2BhE,MAAK,EAAE7T,KAAUA,IAAS8W,IAE/FtS,EAAeyU,eAAiBzU,EAAeyU,gBAAkBnL,CACnE,CACF,KAIF,MAAMsL,GACmE,QAAvEhC,EAAAzB,EAAgBpH,EAAAA,GAAoCE,2BAAmB,IAAA2I,OAAA,EAAvEA,EAAyEyB,eAAgB,IAAItB,IAQ/F,OANE6B,EAA4BC,IAAIzU,EAAAA,GAA2CC,MAC3EuU,EAA4BC,IAAIzU,EAAAA,GAA2CE,YAEpE6Q,EAAgBpH,EAAAA,GAAoCE,oBAGtD6K,EAAoB9I,OAAO5H,OAAO+M,GAC3C,CAEO,SAAS2D,EAAoB3D,GAElC,OAAOA,EAAgB4D,MAAK,CAACC,EAAGC,KAC9B,MAAMC,EAASlL,EAAAA,GAA+BoG,QAAQ4E,EAAExZ,MAClD2Z,EAASnL,EAAAA,GAA+BoG,QAAQ6E,EAAEzZ,MAGxD,OAAgB,IAAZ0Z,IAA6B,IAAZC,EACZD,EAASC,GAIF,IAAZD,GAAuB,GACX,IAAZC,EAAsB,EAGnBH,EAAExZ,KAAK4Z,cAAcH,EAAEzZ,KAAK,GAEvC,CAuCO,SAAS6Z,EACdrV,EACAsV,GAEA,GAA6B,YAAzBtV,EAAeG,MACjB,OAaF,OAvDK,SAA6BoV,GAClC,GAA6B,IAAzBA,EAAcrJ,OAChB,OAGF,MAAMsJ,EAAkD,GAClDrH,EAAMF,KAAKE,OAAOoH,GAClBnH,EAAMH,KAAKG,OAAOmH,GAIlBE,EAAaxH,KAAKG,IAAI,KAAOA,EAAMD,GAAO,IAChD,IAAIuH,EAAW,EAEf,GAAIvH,IAAQC,EACVoH,EAAuBhC,KAAK,CAAEmC,MAAOxH,EAAKyH,MAAOxH,EAAK7M,MAAOgU,EAAcrJ,cAE3E,IAAK,IAAI2J,EAAI1H,EAAK0H,EAAIzH,EAAKyH,GAAKJ,EAC9BD,EAAuBhC,KAAK,CAAEmC,MAAOE,EAAGD,MAAO3H,KAAKE,IAAI0H,EAAIJ,EAAYrH,GAAM7M,MAAO,IAIzFiU,EAAuBT,MAAK,CAACC,EAAGC,IAAMD,EAAEW,MAAQV,EAAEU,QAClD,IAAK,MAAMhI,KAAgB4H,EAAe,CACxC,MAAMO,EAASN,EAAuB/F,MACnCqG,GACCnI,GAAgBmI,EAAOH,QACtBhI,EAAemI,EAAOF,OAAUjI,IAAiBmI,EAAOF,OAASjI,IAAiBS,KAEnF0H,IACFA,EAAOvU,QACPmU,EAAWzH,KAAKG,IAAIsH,EAAUI,EAAOvU,OAEzC,CACA,MAAO,CAAE4M,MAAKC,MAAKsH,WAAUK,OAAQP,EACvC,CAoBSQ,CAXeV,EACnB3V,SAASsW,IACR,MAAMhG,EAAcjQ,EAAesU,UAC/B2B,EAAW9G,mBACX8G,EAAW9C,0BAA0BnT,EAAexE,MAIxD,OAH0B,OAAXyU,QAAW,IAAXA,OAAW,EAAXA,EACXoB,KAAKxQ,IAAee,EAAAA,EAAAA,IAAmCf,KACxD8P,QAAQxY,QAAoB2G,IAAV3G,GAAwC,kBAAVA,GACtC,IAEdwY,QAAQxY,KAAW+H,EAAAA,EAAAA,OAAM/H,KAE9B,CAEA,SAAS+d,EACPlW,EACAsV,GAEA,GAA6B,YAAzBtV,EAAeG,MACjB,OAEF,MAAMgW,EAAmC,IAAIC,IAkB7C,OAjBAd,EAAYtC,SAASiD,IACnB,MAAMhG,EAAcjQ,EAAesU,UAC/B2B,EAAW9G,mBACX8G,EAAW9C,0BAA0BnT,EAAexE,MAClD6a,EACJpG,GAAeA,EAAY/D,OAAS,EAChCoK,EAA+BtW,EAAgBiQ,GAC/C,CAAC,CAAE9X,WAAO2G,EAAWyC,MAAO,IAC5BgV,EAAcvW,EAAeyU,eAC/B,CAAC3C,KAAc9R,EAAeqU,cAC9BrU,EAAeqU,aACnB,IAAK,MAAMmC,KAAeD,EAAa,CACrC,MAAME,EAAuBJ,EAAsB5G,MAAMiH,GAAeA,EAAWve,QAAUqe,IACvFjV,EAAQkV,EAAuBA,EAAqBlV,MAAQ,EAClE4U,EAAYQ,IAAIH,GAAcL,EAAYS,IAAIJ,IAAgB,GAAKjV,EACrE,KAEK4U,CACT,CAEA,SAASU,EACP7W,EACAsV,GAEA,GAA6B,YAAzBtV,EAAeG,MACjB,OAEF,MAAMiE,EAAmB,GAazB,OAZAkR,EAAYtC,SAASiD,IACnB,MAAMpV,EAAab,EAAesU,WAC9BwC,EAAAA,EAAAA,OAAMb,EAAW9G,qBACjB2H,EAAAA,EAAAA,OAAMb,EAAW9C,0BAA0BnT,EAAexE,OAC9D,GAAIqF,EAAY,CACd,MAAM1I,GAAQyJ,EAAAA,EAAAA,IAAmCf,IAE5CX,EAAAA,EAAAA,OAAM/H,IACTiM,EAAOoP,KAAKuD,OAAO5e,GAEvB,KAEKiM,CACT,CAEA,SAAS4S,EACPhX,EACAsV,GAEA,IAAI2B,EAAe,EAQnB,OAPA3B,EAAYtC,SAASiD,IAAgB,IAADiB,EAClC,IAAIhX,EAAAA,EAAAA,OAAM+V,GAAa,OACvB,MAAMkB,GAAoBL,EAAAA,EAAAA,OAAMb,EAAW9G,qBACtB,OAAjBgI,QAAiB,IAAjBA,GAAsC,QAArBD,EAAjBC,EAAmBC,2BAAmB,IAAAF,OAArB,EAAjBA,EAAwC5E,kBAAmBtS,EAAexE,MAC5Eyb,GACF,IAEKA,CACT,CAEO,SAASI,EACdrX,EACAsV,EACAgC,GAEA,MAAMC,EAAqBjC,EAAYjE,KAAKmG,GAAUA,EAAMC,kBAAiB9G,QAAQ6G,KAAWtX,EAAAA,EAAAA,OAAMsX,KAChGE,EAAmBpC,EAAYjE,KAAKmG,GAAUA,EAAMG,gBAAehH,QAAQ6G,KAAWtX,EAAAA,EAAAA,OAAMsX,KAE5FI,EAA8B1B,EAA4BlW,EAAgBuX,GAC1EM,EAA4B3B,EAA4BlW,EAAgB0X,GAExEI,EAA2BzC,EAA+BrV,EAAgBuX,GAE1EQ,EAAoBT,EAAqB3G,QAAQA,GAAWA,EAAO2B,iBAAmBtS,EAAexE,OAE3G,MAAO,CACLwE,iBACAgY,cAAeJ,EACfK,YAAaJ,EACbK,qBAAsBrB,EAA8B7W,EAAgBuX,GACpEY,mBAAoBtB,EAA8B7W,EAAgB0X,GAClEU,wBAAyBN,EACzBO,oBAAqBrB,EAA4BhX,EAAgBuX,GACjEe,kBAAmBtB,EAA4BhX,EAAgB0X,GAC/DK,oBAEJ,CAQO,SAASQ,EACdvY,EACAwY,EAA2C,IAAIpC,KAE/C,GAA6B,cAAzBpW,EAAeG,OAAkD,YAAzBH,EAAeG,MAAqB,CAC9E,IAAIsY,EAAQ,EACRC,EAAY,EAChB,IAAK,MAAOvgB,EAAOoJ,KAAUiX,GACvBzY,EAAAA,EAAAA,GAAoBC,EAAgB7H,KACtCugB,GAAanX,IAGVrB,EAAAA,EAAAA,OAAM/H,IAAUA,IAAU2Z,IAC7B2G,GAASlX,GAGb,OAAOkX,EAAQ,EAAIC,EAAYD,EAAQ,CACzC,CACA,OAAO,CACT,CAEA,SAASE,EACPve,EACA4F,EACA+X,EACA5f,EACAge,EACAyC,EACAC,GAOA,IAAIC,EAAW,EACf,MAAMC,EAAgB5gB,IAAU2Z,QAAuBhT,IAAV3G,EAC7C,IAAK,MAAO6X,EAAKzO,KAAU4U,OACbrX,IAARkR,GAAqBA,IAAQ8B,IAC/BgH,GAAYvX,GAGhB,MAAMyX,EAAW7C,EAAYS,IAAIze,IAAU,EACrC8gB,GAAYF,GAAiBD,EAAW,EAAIE,EAAWF,EAAW,EAIxE,MAAO,CACL3gB,MAAOge,EAAYS,IAAIze,IAAU,EACjC8gB,WACAC,WAAYnB,EAAkB1I,MAC3BsB,GACCA,EAAOwI,cAAgBhhB,GAASwY,EAAO2B,iBAAmBtS,EAAexE,MAAQmV,EAAOyI,MAAQR,IAEpGS,aAAcA,IAAMR,EAAuB7Y,EAAexE,KAAMrD,EAAOygB,EATtB9Z,WAUjDwa,QAAUP,EAYN3e,EAAK8B,cACH,CAAAC,GAAA,SACEC,eAAe,kCAGjB,CACE4c,WACAJ,YAlBJxe,EAAK8B,cACH,CAAAC,GAAA,SACEC,eAAe,6CAGjB,CACE4c,SAAUA,EACVF,WACAF,YAcZ,CAEA,SAASW,EAAgBvZ,GACvB,MAAMiM,EA4ER,SAA+BjM,GAC7B,MAAMwZ,EAAoB1M,MAAM2M,KAAKzZ,EAAeqU,cACpD,GAA6B,cAAzBrU,EAAeG,MAAuB,CAEnCqZ,EAAkB9F,SAAStT,EAAAA,GAA2CC,MACzEmZ,EAAkBhG,KAAKpT,EAAAA,GAA2CC,KAE/DmZ,EAAkB9F,SAAStT,EAAAA,GAA2CE,KACzEkZ,EAAkBhG,KAAKpT,EAAAA,GAA2CE,IAEpE,MAAMoZ,EAAsB,CAC1BtZ,EAAAA,GAA2CC,IAC3CD,EAAAA,GAA2CE,IAI7C,OAAOkZ,EAAkBzE,MAAK,CAACC,EAAGC,IACjByE,EAAUtJ,QAAQ4E,GAClB0E,EAAUtJ,QAAQ6E,IAGrC,CAAO,GAA6B,YAAzBjV,EAAeG,MAExB,OAAOqZ,EAAkBzE,MAAK,CAACC,EAAGC,KACN,IAAlBD,GAA0B,EAAI,IAK1C,OAAOwE,EAAkBzE,MAC3B,CA1Ge4E,CAAsB3Z,GAKnC,OAJIA,EAAeyU,gBACjBxI,EAAKuH,KAAK1B,GAGL7F,CACT,CAEO,SAAS2N,EACdxf,EACAsH,EACA1B,EACA+X,EACAc,EAMAgB,EACAC,EACAC,GAEA,MAAMC,OAAoDlb,IAAlC+a,EAAkB5B,YAEpCgC,EAAkC,GAExC,IAAK,MAAM9hB,KAASohB,EAAgBvZ,GAAiB,CACnD,MAAMka,EAAiBL,EAAkB7B,cACrCW,EACEve,EACA4F,EACA+X,EACA5f,EACA0hB,EAAkB7B,cAElB8B,GAAyB,UACzBjB,QAEF/Z,EAEEqb,EACJH,GAAmBD,EACfpB,EACEve,EACA4F,EACA+X,EACA5f,EACA0hB,EAAkB5B,aAAe,IAAI7B,IACrC2D,EACAlB,QAEF/Z,EAEAia,EAAgB5gB,IAAU2Z,QAAuBhT,IAAV3G,EACvCiiB,EACJJ,GAAmBE,GAAkBC,EACjCpB,EACEmB,EAAe/hB,QAAqB,OAAZgiB,QAAY,IAAZA,OAAY,EAAZA,EAAchiB,QAAS,GAC/C+hB,EAAejB,WAAwB,OAAZkB,QAAY,IAAZA,OAAY,EAAZA,EAAclB,WAAY,QACvDna,EAEFob,KAAoBnB,GAA0C,IAAzBmB,EAAe/hB,OAAgBiiB,GAA+B,IAAhBA,IACrFH,EAASzG,KAAK,CACZhY,KAAM6e,EAA+BjgB,EAAMsH,EAAO1B,EAAgB7H,GAClEmiB,QAASJ,EACTK,MAAOJ,EACP7U,iBAAiB+D,EAAAA,EAAAA,IAAqC3H,EAAO1B,EAAgB7H,EAAOA,IAAU2Z,GAC9FsI,eAGN,CAEA,OAAOH,CACT,CAkCA,SAASI,EACPjgB,EACAsH,EACA1B,EACA7H,GAEA,MAA6B,cAAzB6H,EAAeG,MACbhI,IAAUiI,EAAAA,GAA2CC,IAChDjG,EAAK8B,cAAc,CAAAC,GAAA,SACxBC,eAAe,SAGRjE,IAAUiI,EAAAA,GAA2CE,GACvDlG,EAAK8B,cAAc,CAAAC,GAAA,SACxBC,eAAe,SAGRjE,IAAU2Z,EACZ1X,EAAK8B,cAAc,CAAAC,GAAA,SACxBC,eAAe,UAIVhC,EAAK8B,cAAc,CAAAC,GAAA,SACxBC,eAAe,SAIe,YAAzB4D,EAAeG,OACV,IAAVhI,EACKiC,EAAK8B,cAAc,CAAAC,GAAA,SACxBC,eAAe,UAGE,IAAVjE,EACFiC,EAAK8B,cAAc,CAAAC,GAAA,SACxBC,eAAe,UAIVhC,EAAK8B,cAAc,CAAAC,GAAA,SACxBC,eAAe,UAKd8D,EAAAA,EAAAA,OAAM/H,GAAS,OAAS,GAAGA,GACpC,CAKO,SAASme,EACdtW,EACAiQ,GAMA,MAAMuK,EAAsBvK,EAAYU,QAAQ9P,GAAeA,EAAWrF,OAASwE,EAAexE,OAElG,IAAI6Y,EAAe,IAAItB,IACvB,IAAK,MAAMlS,KAAc2Z,EAAqB,CAC5C,MAAMriB,GAAQyJ,EAAAA,EAAAA,IAAmCf,GACjDwT,EAAaZ,IAAItb,EACnB,CAGAqiB,EAAoBzF,MAAK,CAACC,EAAGC,KAAOA,EAAErG,WAAa,IAAMoG,EAAEpG,WAAa,KAGxE,MAAM6L,EAAmBD,EAAoB7J,QAAQ9P,GAAekR,EAA4BlR,KAC1F6Z,EAAmBF,EAAoB7J,QAAQ9P,IAAgBkR,EAA4BlR,KAGjGwT,EAAe,IAAItB,IACnB,IAAK,MAAMlS,KAAc6Z,EAAkB,CACzC,MAAMviB,GAAQyJ,EAAAA,EAAAA,IAAmCf,GACjDwT,EAAaZ,IAAItb,EACnB,CAGA,MAAMge,EAIA,GACN,IAAK,MAAMhe,KAASkc,EAAc,CAChC,MAAMsG,EAAuBH,EAAoB7J,QAC9C9P,IAAee,EAAAA,EAAAA,IAAmCf,KAAgB1I,IAE/DoJ,EAAQoZ,EAAqBzO,OACnCiK,EAAY3C,KAAK,CAAErb,QAAOoJ,QAAOqZ,iBAAkBD,EAAqB,IAC1E,CAWA,OARIF,EAAiBvO,OAAS,GAC5BiK,EAAY3C,KAAK,CACfrb,MAAO2Z,EACPvQ,MAAOkZ,EAAiBvO,OACxB0O,iBAAkBH,EAAiB,KAIhCtE,CACT,C,+QC7uBA,MAAM0E,EAAkC,EAGjC,SAASC,EAAkB7B,EAAkB8B,EAA+BF,GAEjF,OAAO9D,QAAmB,IAAXkC,GAAgB+B,QAAQD,IAA+B5W,UACxE,CAEO,SAASI,EAAapM,EAAkC8iB,EAAc,GAC3E,IAAI/a,EAAAA,EAAAA,OAAM/H,GACR,MAAO,OAET,MAAM+iB,EAAajN,KAAKkN,IAAI,GAAIF,GAEhC,OADehN,KAAKC,MAAM/V,EAAQ+iB,GAAcA,GAClC/W,UAChB,CAKO,SAASiX,EACdhhB,EACA4F,EACAqb,GAOA,GAA6B,YAAzBrb,EAAeG,MAAqB,CAEtC,MAAM+X,EAAuBmD,EAAsBnD,qBAC7CC,EAAqBkD,EAAsBlD,mBAEjD,IAAImD,EAAiBC,IACjBC,EAAeD,IACfrD,IACFoD,EAAiBpD,EAAqBuD,QAAO,CAACzG,EAAGC,IAAMD,EAAIC,GAAG,GAAKiD,EAAqBhM,QAEtFiM,IACFqD,EAAerD,EAAmBsD,QAAO,CAACzG,EAAGC,IAAMD,EAAIC,GAAG,GAAKkD,EAAmBjM,QAEpF,MACMkO,EAAcjC,EAAqBmD,EAAiBE,OAAe1c,EACnE4c,EAAkBtB,EAAeA,EAAc,EAAI,KAAO,OAAU,OAU1E,MAAO,CACLuB,aAbmBpX,EAAa+W,EAAgB,GAchDM,mBAVyBxB,EACH,OAApBsB,EACE,IAAInX,EAAa0J,KAAK4N,IAAIzB,GAAc,KACpB,SAApBsB,EACA,IAAInX,EAAa0J,KAAK4N,IAAIzB,GAAc,KACxC,UACFtb,EAKF4c,kBACAI,cAAe,UAEnB,CAAO,GAA6B,cAAzB9b,EAAeG,OAAkD,YAAzBH,EAAeG,MAAqB,CACrF,MAAM4a,EAA+B,EAC/BgB,GAAgBxD,EAAAA,EAAAA,IAAsCvY,EAAgBqb,EAAsBrD,eAC5F2D,EAAeb,EAAkBiB,EAAehB,GAAgC,IAChFX,EAAciB,EAAsBpD,YACtC8D,GAAgBxD,EAAAA,EAAAA,IAAsCvY,EAAgBqb,EAAsBpD,kBAC5FnZ,EACE4c,EAAkBtB,EAAeA,EAAc,EAAI,KAAO,OAAU,OAO1E,MAAO,CACLuB,eACAC,mBARyBxB,GACF,OAApBsB,GAAgD,SAApBA,EAA6B,IAAM,IAChEZ,EAAkBV,EAAaW,GAC/B,SACAjc,EAKF4c,kBACAI,cAAe,kBAEnB,CAAO,GAA6B,WAAzB9b,EAAeG,MAAoB,CAC5C,MAAM6b,EAAkBhc,EAAeqU,aAAa3a,KACpD,MAAO,CACLiiB,aACsB,IAApBK,EACI5hB,EAAK8B,cACH,CAAAC,GAAA,SACEC,eAAe,4BAGjB,CAAE4f,oBAEJ5hB,EAAK8B,cAAc,CAAAC,GAAA,SACjBC,eAAe,YAGvBwf,mBAAoB,GACpBF,gBAAiB,OACjBI,cAAe,cAEnB,CACE,MAAO,CACLH,aAAc,MACdC,mBAAoB,MACpBF,gBAAiB,OACjBI,cAAe,cAGrB,CAEO,SAASG,EAAgBjc,EAAgCiZ,GAC9D,OAAO6B,EAAkB7B,EAAU,GAAK,GAC1C,CAEO,SAASiD,EAAsBlc,EAAgCoa,EAAqB+B,GAAe,GACxG,GAA6B,YAAzBnc,EAAeG,MAAqB,CAEtC,MAA2B,QADHia,EAAc,EAAI,KAAO,QACf,IAAI7V,EAAa6V,EAAa,KAAO,IAAI7V,EAAa6V,EAAa,IACvG,CAAO,CACL,MAAMsB,EAAkBtB,GAAe,EAAI,KAAO,OAClD,OAAI+B,EACyB,OAApBT,EACH,IAAIZ,EAAkBV,EAAa,MACnC,IAAIU,GAAiC,EAAfV,EAAkB,MAEjB,OAApBsB,EAA2B,IAAItB,IAAgB,IAAIA,GAE9D,CACF,CAGO,SAASgC,EAAaC,EAAWC,EAAgB,IAAIzN,MAE1D,MAAM0N,EAAUtO,KAAKG,IAAI,EAAGH,KAAKuO,OAAOF,EAAgBD,GAAQ,MAChE,IAAII,EAAWxO,KAAKuO,MAAMD,EAAU,SAEpC,OAAIE,GAAY,GAEZxkB,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SACfC,eAAe,uDAEfgI,OAAQ,CAAEsY,UAAWD,MAI3BA,EAAWxO,KAAKuO,MAAMD,EAAU,QAC5BE,GAAY,GAEZxkB,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SACfC,eAAe,yDAEfgI,OAAQ,CAAEsY,UAAWD,MAI3BA,EAAWxO,KAAKuO,MAAMD,EAAU,OAC5BE,GAAY,GAEZxkB,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SACfC,eAAe,qDAEfgI,OAAQ,CAAEsY,UAAWD,MAI3BA,EAAWxO,KAAKuO,MAAMD,EAAU,MAC5BE,GAAY,GAEZxkB,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SACfC,eAAe,uDAEfgI,OAAQ,CAAEsY,UAAWD,MAI3BA,EAAWxO,KAAKuO,MAAMD,EAAU,IAC5BE,GAAY,GAEZxkB,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SACfC,eAAe,2DAEfgI,OAAQ,CAAEsY,UAAWD,MAKzBxkB,EAAAA,EAAAA,GAAC6E,EAAAA,GAAgB,CAAAX,GAAA,SACfC,eAAe,2DAEfgI,OAAQ,CAAEsY,UAAWH,QAG3B,CAGO,SAASI,EAA2BC,GAEzC,OAAOA,EAAIC,QAAQ,4CAA6C,OAClE,CAGO,SAASC,EAAmBC,EAAkCC,GACnE,OAGF,SACE7kB,EACA8kB,EACAC,EAAkB,GAClBF,GAEA,IAAIG,EAAMpG,OAAO5e,GAEjB,GAAIilB,MAAMD,KAASE,SAASF,GAC1B,MAAO,CACLhlB,MAAO,GACPwV,kBAAc7O,EACdwe,KAAM,GACNL,QAAS,GAIb,IAAIK,EAAO,EACPC,EAAkB,EAEtB,KAAOJ,GAAOF,GAAWK,EAAOJ,EAAMhR,OAAS,GAC7CiR,GAAOF,EACPM,GAAmBN,EACnBK,GAAQ,EAGV,MAAO,CACLnlB,MAAOqlB,EAAaL,EAAKH,GACzBrP,aAAcwP,EACdG,KAAMJ,EAAMI,GACZL,QAASM,EAEb,CAnCSE,CAAqBV,EAAO,KAAM,CAAC,QAAS,KAAM,KAAM,KAAM,KAAM,MAAOC,EACpF,CAoCA,SAASQ,EAAarlB,EAAe6kB,EAAiB,GACpD,OAAO/O,KAAKC,MAAM/V,KAAWA,EAAQA,EAAM6iB,QAAQgC,GAAkB7kB,EAAMgM,UAC7E,C,kQCpPkE,IAAAzG,EAAA,CAAAlC,KAAA,UAAAmC,OAAA,aAMnD,SAAS+f,GAAoB,eAAEtkB,KAAmBX,IAC/D,MAAMklB,EAAKjgB,EAGX,OACEzF,EAAAA,EAAAA,GAAC2lB,EAAAA,cAAa,CAAC/gB,MAAOzD,EAAerB,UACnCE,EAAAA,EAAAA,GAACsB,EAAAA,EAAM,CACLb,YAAY,uEACRD,EACJuF,IAAK2f,KAIb,CCTO,SAASE,GAAkB,SAAEllB,EAAQ,QAAEc,KAAYqkB,IACxD,MAAM,WAAE9kB,EAAU,eAAEI,EAAc,KAAEH,IAASI,EAAAA,EAAAA,IAAkBV,GAE/D,OACEV,EAAAA,EAAAA,GAACylB,EAAmB,CAClBtkB,eAAgBA,EAChBI,KAAMR,EACNS,QAAU6D,IACRrE,IACO,OAAPQ,QAAO,IAAPA,GAAAA,EAAU6D,EAAE,KAEVwgB,GAGV,CCpBAC,EAAAA,EAAkBC,iBAAiB,MAAOC,EAAAA,GAC1CF,EAAAA,EAAkBC,iBAAiB,OAAQE,EAAAA,GAC3CH,EAAAA,EAAkBC,iBAAiB,SAAUG,EAAAA,GAC7CJ,EAAAA,EAAkBC,iBAAiB,KAAMI,EAAAA,GACzCL,EAAAA,EAAkBC,iBAAiB,aAAcK,EAAAA,GACjDN,EAAAA,EAAkBC,iBAAiB,OAAQM,EAAAA,GAC3CP,EAAAA,EAAkBC,iBAAiB,OAAQO,EAAAA,GAOpC,MAKMC,EAAiB,OACxBC,EAA8C,CAClDC,MAAOC,EAAAA,EACPC,YAAaC,EAAAA,GAwDR,SAASC,GAAY,MAC1Bpd,EAAQ,QAAO,SACfqd,EAAQ,QACRC,EAAO,MACPrB,EAAK,SACL5lB,EAAQ,gBACRknB,EAAe,gBACfC,EAAe,cACfC,EAAa,UACbC,EAAS,OACTC,IAEA,MAAMC,EAAc,CAClBC,OAAQ,OACRnY,aAAc,EACdoY,OAAQ,EACRrY,QAASqX,KACNb,GAEL,OACE1lB,EAAAA,EAAAA,GAAC8lB,EAAAA,EAAiB,CAChBkB,gBAAiBA,EACjBC,gBAAiBA,EACjBH,SAAUA,EACVpB,MAAOc,EAAa/c,GACpB4d,YAAaA,EACbG,aAAc,CACZ9B,OAAO+B,EAAAA,EAAAA,MAAK/B,EAAO,oBAErBwB,cAAeA,EACfC,UAAWA,EACXC,OAAQA,EAAOtnB,SAEdA,GAGP,C","sources":["shared/web-shared/genai-traces-table/utils/MarkdownUtils.tsx","experiment-tracking/pages/experiment-evaluation-datasets/constants.ts","shared/web-shared/copy/CopyActionButton.tsx","experiment-tracking/pages/experiment-evaluation-datasets/components/CreateEvaluationDatasetModal.tsx","experiment-tracking/pages/experiment-evaluation-datasets/hooks/useCreateEvaluationDatasetMutation.tsx","experiment-tracking/pages/experiment-evaluation-datasets/components/CreateEvaluationDatasetButton.tsx","experiment-tracking/pages/experiment-evaluation-datasets/hooks/useSearchEvaluationDatasets.tsx","shared/web-shared/genai-traces-table/components/EvaluationsReviewAssessmentTag.tsx","shared/web-shared/genai-traces-table/utils/Colors.ts","experiment-tracking/pages/experiment-evaluation-datasets/hooks/useInfiniteScrollFetch.tsx","shared/web-shared/genai-traces-table/components/GenAiEvaluationTracesReview.utils.tsx","shared/web-shared/genai-traces-table/utils/AggregationUtils.ts","shared/web-shared/genai-traces-table/utils/DisplayUtils.tsx","shared/web-shared/snippet/actions/SnippetActionButton.tsx","shared/web-shared/snippet/actions/SnippetCopyAction.tsx","shared/web-shared/snippet/index.tsx"],"sourcesContent":["import React from 'react';\n\nconst MarkdownConverterProviderContext = React.createContext({\n  makeHTML: (markdown?: string) => markdown,\n});\n\nexport const MarkdownConverterProvider = ({\n  children,\n  makeHtml,\n}: {\n  children: React.ReactNode;\n  makeHtml: (markdown?: string) => string;\n}) => {\n  return (\n    <MarkdownConverterProviderContext.Provider value={{ makeHTML: makeHtml }}>\n      {children}\n    </MarkdownConverterProviderContext.Provider>\n  );\n};\n\nexport const useMarkdownConverter = () => React.useContext(MarkdownConverterProviderContext);\n","export const GET_DATASET_RECORDS_QUERY_KEY = 'GET_DATASET_RECORDS';\nexport const SEARCH_EVALUATION_DATASETS_QUERY_KEY = 'SEARCH_EVALUATION_DATASETS';\nexport const FETCH_TRACES_QUERY_KEY = 'FETCH_TRACES';\n","import React from 'react';\n\nimport type { ButtonProps, TooltipProps } from '@databricks/design-system';\nimport { Button, Tooltip } from '@databricks/design-system';\n\nimport { useCopyController } from './useCopyController';\n\nexport interface CopyActionButtonProps {\n  buttonProps?: Partial<ButtonProps>;\n  componentId?: string;\n  copyText: string;\n  copyTooltip?: string;\n  isInsideInputGroup?: boolean;\n  onCopy?: () => void;\n  tooltipProps?: Partial<TooltipProps>;\n}\n\nexport function CopyActionButton({\n  buttonProps,\n  componentId,\n  copyText,\n  copyTooltip,\n  isInsideInputGroup = false,\n  onCopy,\n  tooltipProps,\n}: CopyActionButtonProps) {\n  const { actionIcon, copy, handleTooltipOpenChange, tooltipOpen, tooltipMessage } = useCopyController(\n    copyText,\n    copyTooltip,\n    onCopy,\n  );\n\n  const button = (\n    <Button\n      aria-label={tooltipMessage}\n      componentId={componentId ?? 'codegen_web-shared_src_copy_copyactionbutton.tsx_17'}\n      icon={actionIcon}\n      onClick={copy}\n      size=\"small\"\n      {...buttonProps}\n    />\n  );\n\n  const inputGroupButton = (\n    <Button\n      aria-label={tooltipMessage}\n      componentId={componentId ?? 'codegen_web-shared_src_copy_copyactionbutton.tsx_17'}\n      onClick={copy}\n      {...buttonProps}\n    >\n      {actionIcon}\n    </Button>\n  );\n\n  return (\n    <Tooltip\n      componentId={\n        componentId ? `${componentId}-tooltip` : 'codegen_web-shared_src_copy_copyactionbutton.tsx_17-tooltip'\n      }\n      content={tooltipMessage}\n      onOpenChange={handleTooltipOpenChange}\n      open={tooltipOpen}\n      {...tooltipProps}\n    >\n      {isInsideInputGroup ? inputGroupButton : button}\n    </Tooltip>\n  );\n}\n","import { FormUI, Input, Modal } from '@databricks/design-system';\nimport { FormattedMessage, useIntl } from '@databricks/i18n';\nimport { useCreateEvaluationDatasetMutation } from '../hooks/useCreateEvaluationDatasetMutation';\nimport { useCallback, useState } from 'react';\n\nexport const CreateEvaluationDatasetModal = ({\n  visible,\n  experimentId,\n  onCancel,\n}: {\n  visible: boolean;\n  experimentId: string;\n  onCancel: () => void;\n}) => {\n  const intl = useIntl();\n  const [datasetName, setDatasetName] = useState('');\n  const [datasetNameError, setDatasetNameError] = useState('');\n  const { createEvaluationDatasetMutation, isLoading } = useCreateEvaluationDatasetMutation({\n    onSuccess: () => {\n      // close modal when dataset is created\n      onCancel();\n    },\n  });\n\n  const handleCreateEvaluationDataset = useCallback(() => {\n    if (!datasetName) {\n      setDatasetNameError(\n        intl.formatMessage({\n          defaultMessage: 'Dataset name is required',\n          description: 'Input field error when dataset name is empty',\n        }),\n      );\n      return;\n    }\n    createEvaluationDatasetMutation({ datasetName, experimentIds: [experimentId] });\n  }, [createEvaluationDatasetMutation, experimentId, datasetName, intl]);\n\n  return (\n    <Modal\n      componentId=\"mlflow.create-evaluation-dataset-modal\"\n      visible={visible}\n      onCancel={onCancel}\n      okText={intl.formatMessage({ defaultMessage: 'Create', description: 'Create evaluation dataset button text' })}\n      cancelText={intl.formatMessage({\n        defaultMessage: 'Cancel',\n        description: 'Cancel create evaluation dataset button text',\n      })}\n      onOk={handleCreateEvaluationDataset}\n      okButtonProps={{ loading: isLoading, disabled: !datasetName }}\n      title={\n        <FormattedMessage\n          defaultMessage=\"Create evaluation dataset\"\n          description=\"Create evaluation dataset modal title\"\n        />\n      }\n    >\n      <FormUI.Label htmlFor=\"dataset-name-input\">\n        <FormattedMessage defaultMessage=\"Dataset name\" description=\"Dataset name label\" />\n      </FormUI.Label>\n      <Input\n        componentId=\"mlflow.create-evaluation-dataset-modal.dataset-name\"\n        id=\"dataset-name-input\"\n        name=\"name\"\n        type=\"text\"\n        placeholder={intl.formatMessage({\n          defaultMessage: 'Enter dataset name',\n          description: 'Dataset name placeholder',\n        })}\n        value={datasetName}\n        onChange={(e) => {\n          setDatasetName(e.target.value);\n          setDatasetNameError('');\n        }}\n      />\n      {datasetNameError && <FormUI.Message type=\"error\" message={datasetNameError} />}\n    </Modal>\n  );\n};\n","import { fetchAPI, getAjaxUrl } from '@mlflow/mlflow/src/common/utils/FetchUtils';\nimport { useMutation, useQueryClient } from '@mlflow/mlflow/src/common/utils/reactQueryHooks';\nimport { EvaluationDataset } from '../types';\nimport { SEARCH_EVALUATION_DATASETS_QUERY_KEY } from '../constants';\n\ntype CreateDatasetResponse = {\n  dataset: EvaluationDataset;\n};\n\ntype CreateDatasetPayload = {\n  datasetName: string;\n  experimentIds?: string[];\n};\n\nexport const useCreateEvaluationDatasetMutation = ({\n  onSuccess,\n  onError,\n}: {\n  onSuccess?: () => void;\n  onError?: (error: any) => void;\n}) => {\n  const queryClient = useQueryClient();\n\n  const { mutate: createEvaluationDatasetMutation, isLoading } = useMutation({\n    mutationFn: async ({ datasetName, experimentIds }: CreateDatasetPayload) => {\n      const requestBody = {\n        name: datasetName,\n        experiment_ids: experimentIds,\n      };\n\n      const response = (await fetchAPI(\n        getAjaxUrl('ajax-api/3.0/mlflow/datasets/create'),\n        'POST',\n        requestBody,\n      )) as CreateDatasetResponse;\n\n      return response.dataset;\n    },\n    onSuccess: () => {\n      queryClient.invalidateQueries({ queryKey: [SEARCH_EVALUATION_DATASETS_QUERY_KEY] });\n      onSuccess?.();\n    },\n    onError: (error) => {\n      onError?.(error);\n    },\n  });\n\n  return {\n    createEvaluationDatasetMutation,\n    isLoading,\n  };\n};\n","import { Button, DatabaseIcon } from '@databricks/design-system';\nimport { useState } from 'react';\nimport { FormattedMessage } from 'react-intl';\nimport { CreateEvaluationDatasetModal } from './CreateEvaluationDatasetModal';\n\nexport const CreateEvaluationDatasetButton = ({ experimentId }: { experimentId: string }) => {\n  const [showCreateDatasetModal, setShowCreateDatasetModal] = useState(false);\n  return (\n    <>\n      <Button\n        componentId=\"mlflow.eval-datasets.create-dataset-button\"\n        css={{ width: 'min-content' }}\n        icon={<DatabaseIcon />}\n        onClick={() => setShowCreateDatasetModal(true)}\n      >\n        <FormattedMessage defaultMessage=\"Create dataset\" description=\"Create evaluation dataset button\" />\n      </Button>\n      <CreateEvaluationDatasetModal\n        experimentId={experimentId}\n        visible={showCreateDatasetModal}\n        onCancel={() => setShowCreateDatasetModal(false)}\n      />\n    </>\n  );\n};\n","import { useInfiniteQuery } from '@tanstack/react-query';\nimport { EvaluationDataset } from '../types';\nimport { fetchAPI, getAjaxUrl } from '@mlflow/mlflow/src/common/utils/FetchUtils';\nimport { useMemo } from 'react';\nimport { SEARCH_EVALUATION_DATASETS_QUERY_KEY } from '../constants';\n\nconst SEARCH_EVALUATION_DATASETS_PAGE_SIZE = 50;\n\ntype SearchEvaluationDatasetsResponse = {\n  datasets?: EvaluationDataset[];\n  next_page_token?: string;\n};\n\nexport const useSearchEvaluationDatasets = ({\n  experimentId,\n  enabled = true,\n  nameFilter = '',\n}: {\n  experimentId: string;\n  enabled?: boolean;\n  nameFilter?: string;\n}) => {\n  const { data, fetchNextPage, hasNextPage, isLoading, isFetching, refetch, error } = useInfiniteQuery<\n    SearchEvaluationDatasetsResponse,\n    Error\n  >({\n    queryKey: [SEARCH_EVALUATION_DATASETS_QUERY_KEY, experimentId, nameFilter],\n    queryFn: async ({ queryKey: [, experimentId, nameFilter], pageParam = undefined }) => {\n      const filterString = nameFilter ? `name ILIKE '%${nameFilter}%'` : undefined;\n      const requestBody = {\n        experiment_ids: [experimentId],\n        filter_string: filterString,\n        order_by: ['created_time DESC'],\n        max_results: SEARCH_EVALUATION_DATASETS_PAGE_SIZE,\n        page_token: pageParam,\n      };\n\n      return (await fetchAPI(\n        getAjaxUrl('ajax-api/3.0/mlflow/datasets/search'),\n        'POST',\n        requestBody,\n      )) as SearchEvaluationDatasetsResponse;\n    },\n    cacheTime: 0,\n    refetchOnWindowFocus: false,\n    retry: false,\n    enabled,\n    getNextPageParam: (lastPage) => lastPage.next_page_token,\n  });\n\n  const flatData = useMemo(() => data?.pages.flatMap((page) => page.datasets ?? []) ?? [], [data]);\n\n  return {\n    data: flatData,\n    fetchNextPage,\n    hasNextPage,\n    isLoading,\n    isFetching,\n    refetch,\n    error,\n  };\n};\n","import { isNil, isString } from 'lodash';\nimport { useMemo } from 'react';\n\nimport {\n  PencilIcon,\n  SparkleDoubleIcon,\n  UserIcon,\n  useDesignSystemTheme,\n  Button,\n  CheckCircleIcon,\n  XCircleIcon,\n  WarningIcon,\n  XCircleFillIcon,\n  HoverCard,\n  Typography,\n  InfoSmallIcon,\n  BracketsXIcon,\n  DangerIcon,\n} from '@databricks/design-system';\nimport type { ThemeType } from '@databricks/design-system';\nimport type { IntlShape } from '@databricks/i18n';\nimport { FormattedMessage, useIntl } from '@databricks/i18n';\n\nimport {\n  KnownEvaluationResultAssessmentValueLabel,\n  KnownEvaluationResultAssessmentValueMapping,\n  getEvaluationResultAssessmentValue,\n  hasBeenEditedByHuman,\n  KnownEvaluationResultAssessmentStringValue,\n  KnownEvaluationResultAssessmentValueMissingTooltip,\n  ASSESSMENTS_DOC_LINKS,\n  getJudgeMetricsLink,\n} from './GenAiEvaluationTracesReview.utils';\nimport type { AssessmentInfo, RunEvaluationResultAssessment } from '../types';\nimport {\n  getEvaluationResultAssessmentBackgroundColor,\n  getEvaluationResultIconColor,\n  getEvaluationResultTextColor,\n} from '../utils/Colors';\nimport { displayFloat } from '../utils/DisplayUtils';\nimport { ASSESSMENT_RATIONAL_HOVER_DETAILS_VIEW } from '../utils/EvaluationLogging';\nimport { useMarkdownConverter } from '../utils/MarkdownUtils';\n\nexport const isAssessmentPassing = (\n  assessmentInfo: AssessmentInfo,\n  assessmentValue?: string | number | boolean | null,\n) => {\n  if (!isNil(assessmentValue)) {\n    if (assessmentInfo.dtype === 'pass-fail') {\n      if (assessmentValue === KnownEvaluationResultAssessmentStringValue.YES) {\n        return true;\n      } else if (assessmentValue === KnownEvaluationResultAssessmentStringValue.NO) {\n        return false;\n      }\n    } else if (assessmentInfo.dtype === 'boolean') {\n      return assessmentValue === true;\n    }\n  }\n  return undefined;\n};\n\nfunction getAssessmentTagDisplayValue(\n  theme: ThemeType,\n  intl: IntlShape,\n  type: 'value' | 'assessment-value',\n  assessmentInfo: AssessmentInfo,\n  editedByHuman: boolean,\n  assessment?: RunEvaluationResultAssessment,\n  isRootCauseAssessment?: boolean,\n): { tagText: JSX.Element | string; icon: JSX.Element; fullTagText?: JSX.Element | string | undefined } {\n  let tagText: string | JSX.Element = '';\n  let fullTagText: string | JSX.Element | undefined = undefined;\n  let icon: JSX.Element = <></>;\n\n  const errorDisplayValue = {\n    tagText: (\n      <FormattedMessage defaultMessage=\"Error\" description=\"Error assessment status in the evaluations table.\" />\n    ),\n    icon: <DangerIcon css={{ color: theme.colors.textValidationWarning }} />,\n  };\n\n  const nullDisplayValue = {\n    tagText: (\n      <span css={{ fontStyle: 'italic' }}>\n        <FormattedMessage defaultMessage=\"null\" description=\"Null value in the evaluations table.\" />\n      </span>\n    ),\n    icon: <WarningIcon css={{ color: theme.colors.grey400 }} />,\n  };\n\n  const value = assessment ? getEvaluationResultAssessmentValue(assessment) : undefined;\n  const isError = Boolean(assessment?.errorMessage);\n\n  if (isError) {\n    return errorDisplayValue;\n  }\n\n  if (assessmentInfo.dtype === 'pass-fail' || assessmentInfo.dtype === 'boolean') {\n    const isPassing = isAssessmentPassing(assessmentInfo, value);\n    let displayValueText = '';\n    if (assessmentInfo.dtype === 'pass-fail') {\n      // Known assessments are all pass / fail.\n      if (isPassing === true) {\n        displayValueText = intl.formatMessage({\n          defaultMessage: 'Pass',\n          description: 'Passing evaluation status in the evaluations table.',\n        });\n      } else if (isPassing === false) {\n        displayValueText = intl.formatMessage({\n          defaultMessage: 'Fail',\n          description: 'Failing evaluation status in the evaluations table.',\n        });\n      } else {\n        return nullDisplayValue;\n      }\n    } else if (isPassing === true) {\n      displayValueText = intl.formatMessage({\n        defaultMessage: 'True',\n        description: 'True value in the evaluations table.',\n      });\n    } else if (isPassing === false) {\n      displayValueText = intl.formatMessage({\n        defaultMessage: 'False',\n        description: 'False value in the evaluations table.',\n      });\n    } else {\n      return nullDisplayValue;\n    }\n\n    const iconColor = getEvaluationResultIconColor(theme, assessmentInfo, assessment);\n    icon =\n      isPassing === true ? (\n        <CheckCircleIcon\n          css={{\n            color: iconColor,\n          }}\n        />\n      ) : isPassing === false ? (\n        isRootCauseAssessment ? (\n          <XCircleFillIcon\n            css={{\n              color: iconColor,\n            }}\n          />\n        ) : (\n          <XCircleIcon\n            css={{\n              color: iconColor,\n            }}\n          />\n        )\n      ) : (\n        <WarningIcon\n          css={{\n            color: iconColor,\n          }}\n        />\n      );\n\n    if (type === 'assessment-value') {\n      const knownMapping = KnownEvaluationResultAssessmentValueMapping[assessmentInfo.name];\n\n      if (knownMapping) {\n        const messageDescriptor = value\n          ? knownMapping[value.toString()] ?? knownMapping[KnownEvaluationResultAssessmentStringValue.YES]\n          : knownMapping[KnownEvaluationResultAssessmentStringValue.YES];\n        if (messageDescriptor) {\n          tagText = <FormattedMessage {...messageDescriptor} values={{ value }} />;\n        }\n      } else {\n        tagText = (\n          <>\n            {assessmentInfo.displayName}: {value}\n          </>\n        );\n      }\n    } else if (type === 'value') {\n      if (isNil(isPassing)) {\n        tagText = <span css={{ fontStyle: 'italic' }}>{displayValueText}</span>;\n      } else {\n        tagText = displayValueText;\n      }\n    }\n  } else if (assessmentInfo.dtype === 'numeric') {\n    const roundedValue = !isNil(value) ? displayFloat(value as number | undefined | null) : value;\n\n    if (type === 'assessment-value') {\n      tagText = (\n        <>\n          {assessmentInfo.displayName}: {roundedValue}\n        </>\n      );\n      fullTagText = (\n        <>\n          {assessmentInfo.displayName}: {value}\n        </>\n      );\n    } else {\n      if (isNil(roundedValue)) {\n        return nullDisplayValue;\n      }\n      tagText = `${roundedValue}`;\n      fullTagText = `${value}`;\n    }\n  } else {\n    // Wrap nulls in italics.\n    if (isNil(value)) {\n      return nullDisplayValue;\n    }\n    const valueElement = <>{String(value)}</>;\n    if (type === 'assessment-value') {\n      if (isNil(value)) {\n        tagText = <>{assessmentInfo.displayName}</>;\n      } else {\n        tagText = (\n          <>\n            {assessmentInfo.displayName}: {valueElement}\n          </>\n        );\n      }\n    } else {\n      tagText = valueElement;\n    }\n  }\n  return { tagText, icon, fullTagText };\n}\n\nexport const EvaluationsReviewAssessmentTag = ({\n  assessment,\n  onEdit,\n  active = false,\n  disableJudgeTypeIcon,\n  showRationaleInTooltip = false,\n  showPassFailText = false,\n  hideAssessmentName = false,\n  iconOnly = false,\n  disableTooltip = false,\n  isRootCauseAssessment,\n  assessmentInfo,\n  type,\n  count,\n}: {\n  assessment?: RunEvaluationResultAssessment;\n  onEdit?: () => void;\n  active?: boolean;\n  disableJudgeTypeIcon?: boolean;\n  showRationaleInTooltip?: boolean;\n  showPassFailText?: boolean;\n  hideAssessmentName?: boolean;\n  iconOnly?: boolean;\n  disableTooltip?: boolean;\n  isRootCauseAssessment?: boolean;\n  assessmentInfo: AssessmentInfo;\n  type: 'value' | 'assessment-value';\n  count?: number;\n}) => {\n  const { theme } = useDesignSystemTheme();\n  const intl = useIntl();\n\n  const value = assessment ? getEvaluationResultAssessmentValue(assessment) : undefined;\n  const isPassing = useMemo(() => isAssessmentPassing(assessmentInfo, value), [value, assessmentInfo]);\n\n  const iconColor = getEvaluationResultIconColor(theme, assessmentInfo, assessment);\n  const textColor = getEvaluationResultTextColor(theme, assessmentInfo, assessment);\n\n  let errorMessage: string | undefined = undefined;\n  if (\n    assessment?.errorMessage ||\n    (isPassing === undefined && assessment && KnownEvaluationResultAssessmentValueMissingTooltip[assessment.name])\n  ) {\n    errorMessage =\n      assessment.errorMessage ||\n      intl.formatMessage(KnownEvaluationResultAssessmentValueMissingTooltip[assessment.name]);\n  }\n\n  const knownValueLabel = assessment ? KnownEvaluationResultAssessmentValueLabel[assessment.name] : undefined;\n  const assessmentTitle = useMemo(\n    () => (knownValueLabel ? intl.formatMessage(knownValueLabel) : assessment?.name),\n    [assessment, knownValueLabel, intl],\n  );\n  const learnMoreLink = useMemo(\n    () => (assessment ? getJudgeMetricsLink(ASSESSMENTS_DOC_LINKS[assessment.name]) : undefined),\n    [assessment],\n  );\n\n  const { makeHTML } = useMarkdownConverter();\n\n  const rationaleHTML = useMemo(() => {\n    const rationale = assessment?.rationale;\n    return isString(rationale) ? makeHTML(rationale) : undefined;\n  }, [assessment, makeHTML]);\n\n  const editedByHuman = useMemo(() => !isNil(assessment) && hasBeenEditedByHuman(assessment), [assessment]);\n\n  const { tagText, icon, fullTagText } = useMemo(\n    () =>\n      getAssessmentTagDisplayValue(theme, intl, type, assessmentInfo, editedByHuman, assessment, isRootCauseAssessment),\n    [theme, intl, type, assessmentInfo, assessment, isRootCauseAssessment, editedByHuman],\n  );\n\n  const tagContent = (\n    <>\n      {tagText}\n      {count && count > 1 ? ` (${count})` : ''}\n    </>\n  );\n\n  // Hide human assessment tags when not defined.\n  const hideTag = assessmentInfo.source?.sourceType === 'HUMAN' && !assessment?.source?.sourceId;\n  if (hideTag) {\n    return <></>;\n  }\n\n  const tagElement = (\n    <div>\n      <EvaluationsReviewTag\n        iconOnly={iconOnly}\n        hideAssessmentName={hideAssessmentName}\n        tagContent={tagContent}\n        active={active}\n        icon={icon}\n        iconColor={iconColor}\n        textColor={textColor}\n        sourceIcon={\n          assessmentInfo.isCustomMetric ? (\n            <BracketsXIcon />\n          ) : assessment && editedByHuman ? (\n            <UserIcon />\n          ) : (\n            <SparkleDoubleIcon />\n          )\n        }\n        backgroundColor={getEvaluationResultAssessmentBackgroundColor(theme, assessmentInfo, assessment)}\n        disableSourceTypeIcon={disableJudgeTypeIcon && !editedByHuman}\n        hasBeenEditedByHuman={editedByHuman}\n        onEdit={onEdit}\n      />\n    </div>\n  );\n\n  return (\n    <>\n      {disableTooltip ? (\n        tagElement\n      ) : (\n        <HoverCard\n          side=\"bottom\"\n          content={\n            <div\n              css={{\n                maxWidth: '25rem',\n                display: 'flex',\n                flexDirection: 'column',\n                overflowWrap: 'break-word',\n                wordBreak: 'break-word',\n                gap: theme.spacing.sm,\n              }}\n            >\n              <div\n                css={{\n                  display: 'flex',\n                  flexDirection: 'column',\n                  gap: theme.spacing.xs,\n                }}\n              >\n                <div\n                  css={{\n                    display: 'flex',\n                    justifyContent: 'space-between',\n                    alignItems: 'center',\n                  }}\n                >\n                  <div\n                    css={{\n                      display: 'flex',\n                      gap: theme.spacing.sm,\n                      alignItems: 'center',\n                    }}\n                  >\n                    <Typography.Title\n                      css={{\n                        marginBottom: 0,\n                      }}\n                    >\n                      {assessmentTitle}\n                    </Typography.Title>\n                    <EvaluationsReviewTag\n                      iconOnly={iconOnly}\n                      hideAssessmentName={hideAssessmentName}\n                      tagContent={fullTagText ? fullTagText : tagContent}\n                      active={active}\n                      icon={icon}\n                      iconColor={iconColor}\n                      textColor={textColor}\n                      sourceIcon={\n                        assessmentInfo.isCustomMetric ? (\n                          <BracketsXIcon />\n                        ) : assessment && hasBeenEditedByHuman(assessment) ? (\n                          <UserIcon />\n                        ) : (\n                          <SparkleDoubleIcon />\n                        )\n                      }\n                      backgroundColor={getEvaluationResultAssessmentBackgroundColor(theme, assessmentInfo, assessment)}\n                      disableSourceTypeIcon={disableJudgeTypeIcon}\n                      hasBeenEditedByHuman={editedByHuman}\n                    />\n                  </div>\n                  {learnMoreLink && (\n                    <a\n                      href={learnMoreLink}\n                      target=\"_blank\"\n                      rel=\"noreferrer\"\n                      css={{\n                        height: '16px',\n                      }}\n                    >\n                      <InfoSmallIcon />\n                    </a>\n                  )}\n                </div>\n                {isRootCauseAssessment && (\n                  <Typography.Hint>\n                    {intl.formatMessage({\n                      defaultMessage: 'This assessment is the root cause of the overall evaluation failure.',\n                      description:\n                        'Root cause assessment hint that explains that this assessment is causing the overall assessment to fail.',\n                    })}\n                  </Typography.Hint>\n                )}\n              </div>\n              {showRationaleInTooltip && assessment && rationaleHTML && (\n                <div>\n                  <>\n                    <span\n                      css={{\n                        display: 'contents',\n                        '& p': {\n                          marginBottom: 0,\n                        },\n                      }}\n                      // eslint-disable-next-line react/no-danger\n                      dangerouslySetInnerHTML={{ __html: rationaleHTML }}\n                    />\n                  </>\n                </div>\n              )}\n              {errorMessage && (\n                <div\n                  css={{\n                    display: 'flex',\n                    flexDirection: 'column',\n                    gap: theme.spacing.xs,\n                  }}\n                >\n                  <span\n                    css={{\n                      color: theme.colors.textValidationWarning,\n                      fontStyle: 'italic',\n                    }}\n                  >\n                    {errorMessage}\n                  </span>\n                </div>\n              )}\n            </div>\n          }\n          trigger={tagElement}\n        />\n      )}\n    </>\n  );\n};\n\nconst EvaluationsReviewTag = ({\n  iconOnly,\n  hideAssessmentName,\n  tagContent,\n  active,\n  sourceIcon,\n  icon,\n  iconColor,\n  textColor,\n  backgroundColor,\n  disableSourceTypeIcon,\n  hasBeenEditedByHuman,\n  onEdit,\n}: {\n  iconOnly: boolean;\n  hideAssessmentName: boolean;\n  tagContent: string | number | true | JSX.Element | undefined;\n  active?: boolean;\n  sourceIcon?: JSX.Element;\n  icon: JSX.Element;\n  iconColor: string;\n  textColor: string;\n  backgroundColor: string;\n  disableSourceTypeIcon?: boolean;\n  hasBeenEditedByHuman?: boolean;\n  onEdit?: () => void;\n}) => {\n  const { theme } = useDesignSystemTheme();\n\n  const svgSize = iconOnly ? 18 : 12;\n\n  return (\n    <div\n      css={{\n        // TODO: Use <Badge /> when it's aligned with design\n        display: 'inline-flex',\n        height: iconOnly ? svgSize : 20,\n        width: iconOnly ? svgSize : hideAssessmentName ? 'fit-content' : '',\n        justifyContent: 'space-between',\n        alignItems: 'center',\n        padding: iconOnly ? '0' : onEdit ? '0 0 0 8px' : '0 8px',\n        gap: theme.spacing.sm,\n        borderRadius: iconOnly ? '50%' : theme.legacyBorders.borderRadiusMd,\n        backgroundColor: backgroundColor,\n        boxShadow: `inset 0 0 1px 1px ${active ? theme.colors.borderAccessible : 'transparent'}`,\n        // border: iconOnly ? '' : `1px solid ${getEvaluationBorderColor(theme, assessment)}`,\n        fontSize: theme.typography.fontSizeSm,\n        svg: { width: svgSize, height: svgSize },\n        whiteSpace: 'nowrap',\n      }}\n    >\n      {icon}\n      {tagContent && (\n        <span\n          css={{\n            color: textColor,\n          }}\n        >\n          {tagContent}\n        </span>\n      )}\n      {disableSourceTypeIcon !== true ? (\n        <span\n          css={{\n            color: iconColor,\n          }}\n        >\n          {sourceIcon}\n        </span>\n      ) : (\n        <></>\n      )}\n      {onEdit && (\n        <Button\n          componentId=\"mlflow.evaluations_review.edit_assessment_button\"\n          onClick={onEdit}\n          size=\"small\"\n          icon={\n            <PencilIcon\n              css={{\n                ':hover': {\n                  color: theme.colors.actionDefaultTextHover,\n                },\n              }}\n            />\n          }\n        />\n      )}\n    </div>\n  );\n};\n","import { isNil } from 'lodash';\n\nimport type { ThemeType } from '@databricks/design-system';\n\nimport { KnownEvaluationResultAssessmentStringValue, withAlpha } from '../components/GenAiEvaluationTracesReview.utils';\nimport type { AssessmentInfo, AssessmentValueType, RunEvaluationResultAssessment } from '../types';\n\n// Taken from figma: https://www.figma.com/design/2B1KMp9x624WrxaASrSv9B/Tiles-UX?node-id=3205-87588&t=1MwrDNNRIOSODm4D-0\nexport const AGGREGATE_SCORE_CHANGE_BACKGROUND_COLORS = {\n  // Tag green\n  up: '#02B30214',\n  // Tag coral\n  down: '#F000400F',\n};\n\n// tagTextCoral\nexport const AGGREGATE_SCORE_CHANGE_TEXT_COLOR = '#64172B';\n\n// From https://www.figma.com/design/HvkTlHxw4sKE77wDlRBDt2/Evaluation-UX?node-id=2996-40835&t=uqVDwh0gqqRJI3jS-0\nexport const CURRENT_RUN_COLOR = '#077A9D';\nexport const COMPARE_TO_RUN_COLOR = '#FFAB00';\n\nconst PASS_BARCHART_BAR_COLOR = '#99DDB4';\nconst FAIL_BARCHART_BAR_COLOR = '#FCA4A1';\nconst ERROR_BARCHART_BAR_COLOR = '#f09065';\n\nconst TAG_PASS_COLOR = '#02B30214'; // From tagBackgroundLime.\n\nexport const getEvaluationResultIconColor = (\n  theme: ThemeType,\n  assessmentInfo: AssessmentInfo,\n  assessment?: RunEvaluationResultAssessment | { stringValue: string; errorMessage?: string },\n) => {\n  if (assessmentInfo.dtype === 'pass-fail') {\n    // Return the color based on the assessment value\n    if (assessment?.stringValue === KnownEvaluationResultAssessmentStringValue.YES) {\n      return theme.isDarkMode ? theme.colors.green400 : theme.colors.green600;\n    }\n    if (assessment?.stringValue === KnownEvaluationResultAssessmentStringValue.NO) {\n      return theme.isDarkMode ? theme.colors.red400 : theme.colors.red600;\n    }\n  }\n  if (assessment?.errorMessage) {\n    return theme.colors.textValidationWarning;\n  }\n  return theme.colors.grey400;\n};\n\nexport const getEvaluationResultAssessmentBackgroundColor = (\n  theme: ThemeType,\n  assessmentInfo: AssessmentInfo,\n  assessment?: RunEvaluationResultAssessment | { stringValue: string; booleanValue?: string; errorMessage?: string },\n  iconOnly = false,\n) => {\n  if (assessmentInfo.dtype === 'pass-fail') {\n    // Return the color based on the assessment value\n    if (assessment?.stringValue === KnownEvaluationResultAssessmentStringValue.YES) {\n      return TAG_PASS_COLOR;\n    }\n    if (assessment?.stringValue === KnownEvaluationResultAssessmentStringValue.NO) {\n      return theme.isDarkMode ? withAlpha(theme.colors.red800, 0.6) : theme.colors.red200;\n    }\n    if (!iconOnly && assessment?.errorMessage) {\n      return '';\n    }\n  } else if (assessmentInfo.dtype === 'boolean') {\n    if (isNil(assessment?.booleanValue)) {\n      return '';\n    }\n    return assessment.booleanValue ? TAG_PASS_COLOR : theme.isDarkMode ? theme.colors.red800 : theme.colors.red200;\n  }\n  return '';\n};\n\nexport const getEvaluationResultTextColor = (\n  theme: ThemeType,\n  assessmentInfo: AssessmentInfo,\n  assessment?: RunEvaluationResultAssessment | { stringValue?: string; booleanValue?: boolean; errorMessage?: string },\n) => {\n  if (assessment?.errorMessage) {\n    return theme.colors.textValidationWarning;\n  }\n\n  if (assessmentInfo.dtype === 'pass-fail') {\n    // Return the color based on the assessment value\n    if (assessment?.stringValue === KnownEvaluationResultAssessmentStringValue.YES) {\n      return theme.isDarkMode ? theme.colors.green400 : theme.colors.green600;\n    } else if (assessment?.stringValue === KnownEvaluationResultAssessmentStringValue.NO) {\n      return theme.isDarkMode ? theme.colors.red400 : theme.colors.red600;\n    } else {\n      return theme.colors.textSecondary;\n    }\n  } else if (assessmentInfo.dtype === 'boolean') {\n    if (isNil(assessment?.booleanValue)) {\n      return theme.colors.textSecondary;\n    }\n    return theme.colors.textPrimary;\n  } else if (assessmentInfo.dtype === 'unknown') {\n    return theme.colors.textSecondary;\n  }\n  return theme.colors.textPrimary;\n};\n\nexport const getAssessmentValueBarBackgroundColor = (\n  theme: ThemeType,\n  assessmentInfo: AssessmentInfo,\n  assessmentValue: AssessmentValueType,\n  isError?: boolean,\n) => {\n  if (isError) {\n    return ERROR_BARCHART_BAR_COLOR;\n  }\n  if (assessmentInfo.dtype === 'pass-fail') {\n    // Return the color based on the assessment value\n    if (assessmentValue === KnownEvaluationResultAssessmentStringValue.YES) {\n      return PASS_BARCHART_BAR_COLOR;\n    }\n    if (assessmentValue === KnownEvaluationResultAssessmentStringValue.NO) {\n      return FAIL_BARCHART_BAR_COLOR;\n    }\n    return theme.isDarkMode ? theme.colors.grey800 : theme.colors.grey200;\n  } else if (assessmentInfo.dtype === 'boolean') {\n    if (isNil(assessmentValue)) {\n      return theme.isDarkMode ? theme.colors.grey800 : theme.colors.grey200;\n    }\n    return assessmentValue ? PASS_BARCHART_BAR_COLOR : FAIL_BARCHART_BAR_COLOR;\n  }\n  return theme.isDarkMode ? theme.colors.grey800 : theme.colors.grey200;\n};\n","import { useCallback } from 'react';\n\nconst INFINITE_SCROLL_BOTTOM_OFFSET = 200;\n\n/**\n * Util function to fetch next page when user scrolls to the end of a scrollable container\n */\nexport const useInfiniteScrollFetch = ({\n  isFetching,\n  hasNextPage,\n  fetchNextPage,\n}: {\n  isFetching: boolean;\n  hasNextPage: boolean;\n  fetchNextPage: () => void;\n}) => {\n  return useCallback(\n    (containerRefElement?: HTMLDivElement | null) => {\n      if (containerRefElement) {\n        const { scrollHeight, scrollTop, clientHeight } = containerRefElement;\n        if (scrollHeight - scrollTop - clientHeight < INFINITE_SCROLL_BOTTOM_OFFSET && !isFetching && hasNextPage) {\n          fetchNextPage();\n        }\n      }\n    },\n    [fetchNextPage, isFetching, hasNextPage],\n  );\n};\n","import { isNil, isNumber, isPlainObject, orderBy } from 'lodash';\n\nimport type { ThemeType } from '@databricks/design-system';\nimport { CheckCircleIcon, WarningIcon, XCircleIcon } from '@databricks/design-system';\nimport { defineMessage } from '@databricks/i18n';\nimport type { MessageDescriptor, IntlShape } from '@databricks/i18n';\nimport { getUser } from '@databricks/web-shared/global-settings';\n\nimport type {\n  AssessmentInfo,\n  AssessmentValueType,\n  RunEvaluationResultAssessment,\n  RunEvaluationResultAssessmentDraft,\n  RunEvaluationTracesDataEntry,\n} from '../types';\nimport { getEvaluationResultAssessmentBackgroundColor, getEvaluationResultIconColor } from '../utils/Colors';\n\nexport const INPUT_REQUEST_KEY = 'request';\nconst INPUT_MESSAGES_KEY = 'messages';\n\nexport enum KnownEvaluationResultAssessmentName {\n  OVERALL_ASSESSMENT = 'overall_assessment',\n  SAFETY = 'safety',\n  GROUNDEDNESS = 'groundedness',\n  RETRIEVAL_GROUNDEDNESS = 'retrieval_groundedness', // Updated name for groundedness\n  CORRECTNESS = 'correctness',\n  RELEVANCE_TO_QUERY = 'relevance_to_query',\n  CHUNK_RELEVANCE = 'chunk_relevance',\n  RETRIEVAL_RELEVANCE = 'retrieval_relevance', // Updated name for chunk relevance\n  CONTEXT_SUFFICIENCY = 'context_sufficiency',\n  RETRIEVAL_SUFFICIENCY = 'retrieval_sufficiency', // Updated name for context sufficiency\n  GUIDELINE_ADHERENCE = 'guideline_adherence',\n  GUIDELINES = 'guidelines', // Updated name for guideline adherence\n  GLOBAL_GUIDELINE_ADHERENCE = 'global_guideline_adherence',\n}\n\nexport const DEFAULT_ASSESSMENTS_SORT_ORDER: string[] = [\n  KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT,\n  // Correctness runs with GT, relevancy to query runs without it.\n  KnownEvaluationResultAssessmentName.CORRECTNESS,\n  KnownEvaluationResultAssessmentName.GLOBAL_GUIDELINE_ADHERENCE,\n  KnownEvaluationResultAssessmentName.GUIDELINE_ADHERENCE,\n  KnownEvaluationResultAssessmentName.GUIDELINES,\n  KnownEvaluationResultAssessmentName.RELEVANCE_TO_QUERY,\n  KnownEvaluationResultAssessmentName.CONTEXT_SUFFICIENCY,\n  KnownEvaluationResultAssessmentName.RETRIEVAL_SUFFICIENCY,\n  KnownEvaluationResultAssessmentName.CHUNK_RELEVANCE,\n  KnownEvaluationResultAssessmentName.RETRIEVAL_RELEVANCE,\n  KnownEvaluationResultAssessmentName.GROUNDEDNESS,\n  KnownEvaluationResultAssessmentName.RETRIEVAL_GROUNDEDNESS, // Updated name for groundedness\n  KnownEvaluationResultAssessmentName.SAFETY,\n];\n\nexport const getJudgeMetricsLink = (asessmentDocLink?: AssessmentLearnMoreLink) => {\n  // return OSS docs link\n  return 'https://mlflow.org/docs/latest/genai/eval-monitor/scorers/llm-judge/';\n};\n\nexport interface AssessmentLearnMoreLink {\n  basePath: string;\n  hash?: string;\n}\n\n/**\n * These will be converted to the links per-cloud:\n * https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-evaluation/${hash}`\n * https://docs.databricks.com/en/generative-ai/agent-evaluation/${page}.html#${hash}\n */\nexport const ASSESSMENTS_DOC_LINKS: Record<string, AssessmentLearnMoreLink> = {\n  [KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT]: {\n    // TODO(nsthorat): Update this link to the overall deep link once it's available.\n    basePath: '/generative-ai/agent-evaluation/llm-judge-metrics',\n    hash: 'how-quality-is-assessed-by-llm-judges',\n  },\n  [KnownEvaluationResultAssessmentName.CORRECTNESS]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'correctness',\n  },\n  [KnownEvaluationResultAssessmentName.GROUNDEDNESS]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'groundedness',\n  },\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_GROUNDEDNESS]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'groundedness',\n  },\n  [KnownEvaluationResultAssessmentName.RELEVANCE_TO_QUERY]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'answer-relevance',\n  },\n  [KnownEvaluationResultAssessmentName.SAFETY]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'safety',\n  },\n  [KnownEvaluationResultAssessmentName.CHUNK_RELEVANCE]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'chunk-relevance-precision',\n  },\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_RELEVANCE]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'chunk-relevance-precision',\n  },\n  [KnownEvaluationResultAssessmentName.CONTEXT_SUFFICIENCY]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'context-sufficiency',\n  },\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_SUFFICIENCY]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'context-sufficiency',\n  },\n  [KnownEvaluationResultAssessmentName.GUIDELINE_ADHERENCE]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'guideline-adherence',\n  },\n  [KnownEvaluationResultAssessmentName.GUIDELINES]: {\n    basePath: '/generative-ai/agent-evaluation/llm-judge-reference',\n    hash: 'guideline-adherence',\n  },\n};\n\nexport enum KnownEvaluationResultAssessmentStringValue {\n  YES = 'yes',\n  NO = 'no',\n  UNKNOWN = 'unknown',\n}\n\nexport function getAssessmentValueLabel(\n  intl: IntlShape,\n  theme: ThemeType,\n  assessmentInfo: AssessmentInfo,\n  value: AssessmentValueType,\n): { content: string; icon?: JSX.Element } {\n  if (assessmentInfo.dtype === 'pass-fail') {\n    if (value === KnownEvaluationResultAssessmentStringValue.YES) {\n      return {\n        content: intl.formatMessage({\n          defaultMessage: 'Pass',\n          description: 'Passing assessment label',\n        }),\n        icon: (\n          <span\n            css={{\n              color: `${getEvaluationResultIconColor(theme, assessmentInfo, {\n                stringValue: KnownEvaluationResultAssessmentStringValue.YES,\n              })} !important`,\n              svg: {\n                width: '12px',\n                height: '12px',\n              },\n            }}\n          >\n            <CheckCircleIcon\n              css={{\n                backgroundColor: getEvaluationResultAssessmentBackgroundColor(theme, assessmentInfo, {\n                  stringValue: KnownEvaluationResultAssessmentStringValue.YES,\n                }),\n                borderRadius: '50%',\n              }}\n            />\n          </span>\n        ),\n      };\n    } else if (value === KnownEvaluationResultAssessmentStringValue.NO) {\n      return {\n        content: intl.formatMessage({\n          defaultMessage: 'Fail',\n          description: 'Failing assessment label',\n        }),\n        icon: (\n          <span\n            css={{\n              color: `${getEvaluationResultIconColor(theme, assessmentInfo, {\n                stringValue: KnownEvaluationResultAssessmentStringValue.NO,\n              })} !important`,\n              svg: {\n                width: '12px',\n                height: '12px',\n              },\n            }}\n          >\n            <XCircleIcon\n              css={{\n                backgroundColor: getEvaluationResultAssessmentBackgroundColor(theme, assessmentInfo, {\n                  stringValue: KnownEvaluationResultAssessmentStringValue.NO,\n                }),\n                borderRadius: '50%',\n              }}\n            />\n          </span>\n        ),\n      };\n    } else {\n      return {\n        content: intl.formatMessage({\n          defaultMessage: 'Missing',\n          description: 'Missing assessment label',\n        }),\n        icon: (\n          <span\n            css={{\n              color: `${getEvaluationResultIconColor(theme, assessmentInfo, {\n                stringValue: KnownEvaluationResultAssessmentStringValue.UNKNOWN,\n              })} !important`,\n              svg: {\n                width: '12px',\n                height: '12px',\n              },\n            }}\n          >\n            <WarningIcon\n              css={{\n                backgroundColor: getEvaluationResultAssessmentBackgroundColor(theme, assessmentInfo, {\n                  stringValue: KnownEvaluationResultAssessmentStringValue.UNKNOWN,\n                }),\n                borderRadius: '50%',\n              }}\n            />\n          </span>\n        ),\n      };\n    }\n  } else if (assessmentInfo.dtype === 'boolean') {\n    if (value === true) {\n      return {\n        content: intl.formatMessage({\n          defaultMessage: 'True',\n          description: 'True assessment label',\n        }),\n      };\n    } else if (value === false) {\n      return {\n        content: intl.formatMessage({\n          defaultMessage: 'False',\n          description: 'False assessment label',\n        }),\n      };\n    } else {\n      return {\n        content: intl.formatMessage({\n          defaultMessage: 'null',\n          description: 'null assessment label',\n        }),\n      };\n    }\n  }\n  return {\n    content: `${value}`,\n  };\n}\n\nexport enum KnownEvaluationResultAssessmentMetadataFields {\n  IS_OVERALL_ASSESSMENT = 'is_overall_assessment',\n  CHUNK_INDEX = 'chunk_index',\n  IS_COPIED_FROM_AI = 'is_copied_from_ai',\n}\n\nexport const KnownEvaluationResultAssessmentOutputLabel: Record<string, MessageDescriptor> = {\n  response: defineMessage({\n    defaultMessage: 'Model output',\n    description: 'Evaluation review > Response section > model output > title',\n  }),\n};\n\nexport const EXPECTED_FACTS_FIELD_NAME = 'expected_facts';\n\nexport const KnownEvaluationResultAssessmentTargetLabel: Record<string, MessageDescriptor> = {\n  expected_response: defineMessage({\n    defaultMessage: 'Expected output',\n    description: 'Evaluation review > Response section > expected output > title',\n  }),\n  [EXPECTED_FACTS_FIELD_NAME]: defineMessage({\n    defaultMessage: 'Expected facts',\n    description: 'Evaluation review > Response section > expected facts > title',\n  }),\n};\n\nexport const KnownEvaluationResultAssessmentValueLabel: Record<string, MessageDescriptor> = {\n  [KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT]: defineMessage({\n    defaultMessage: 'Overall',\n    description: 'Evaluation results > known type of evaluation result assessment > overall assessment.',\n  }),\n  [KnownEvaluationResultAssessmentName.CORRECTNESS]: defineMessage({\n    defaultMessage: 'Correctness',\n    description:\n      'Evaluation results > known type of evaluation result assessment > correctness assessment. Used to indicate if the result is correct in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Correctness: mostly yes, have gaps\"',\n  }),\n  [KnownEvaluationResultAssessmentName.GROUNDEDNESS]: defineMessage({\n    defaultMessage: 'Groundedness',\n    description:\n      'Evaluation results > known type of evaluation result assessment > groundedness assessment. Used to indicate if the result is grounded in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Groundedness: moderately grounded\"',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_GROUNDEDNESS]: defineMessage({\n    defaultMessage: 'Retrieval groundedness',\n    description:\n      'Evaluation results > known type of evaluation result assessment > retrieval groundedness assessment. Used to indicate if the result is grounded in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Retrieval groundedness: moderately grounded\"',\n  }),\n  [KnownEvaluationResultAssessmentName.CONTEXT_SUFFICIENCY]: defineMessage({\n    defaultMessage: 'Context sufficiency',\n    description:\n      'Evaluation results > known type of evaluation result assessment > context sufficiency assessment. Used to indicate if the retrieved context is sufficient to generate the expected response. Label displayed if user provided custom value, e.g. \"Context Sufficiency: mostly sufficient\"',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_SUFFICIENCY]: defineMessage({\n    defaultMessage: 'Retrieval sufficiency',\n    description:\n      'Evaluation results > known type of evaluation result assessment > retrieval sufficiency assessment. Used to indicate if the retrieved context is sufficient to generate the expected response. Label displayed if user provided custom value, e.g. \"Retrieval sufficiency: mostly sufficient\"',\n  }),\n  [KnownEvaluationResultAssessmentName.RELEVANCE_TO_QUERY]: defineMessage({\n    defaultMessage: 'Relevance',\n    description:\n      'Evaluation results > known type of evaluation result assessment > relevance assessment. Used to indicate if the result is relevant to query in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Relevance: moderate\"',\n  }),\n  [KnownEvaluationResultAssessmentName.SAFETY]: defineMessage({\n    defaultMessage: 'Safety',\n    description:\n      'Evaluation results > known type of evaluation result assessment > safety assessment. Used to indicate if the result is safe in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Safety: moderate\"',\n  }),\n  [KnownEvaluationResultAssessmentName.CHUNK_RELEVANCE]: defineMessage({\n    defaultMessage: 'Chunk relevance',\n    description:\n      'Evaluation results > known type of evaluation result assessment > chunk relevance assessment. Used to indicate if the result is relevant to source data chunk in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Chunk relevance: moderate\"',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_RELEVANCE]: defineMessage({\n    defaultMessage: 'Retrieval relevance',\n    description:\n      'Evaluation results > known type of evaluation result assessment > retrieval relevance assessment. Used to indicate if the result is relevant to source data chunk in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Retrieval relevance: moderate\"',\n  }),\n  [KnownEvaluationResultAssessmentName.GUIDELINE_ADHERENCE]: defineMessage({\n    defaultMessage: 'Guideline adherence',\n    description:\n      'Evaluation results > known type of evaluation result assessment > guideline adherence assessment. Used to indicate if the result adheres to the guidelines in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Guideline adherence: moderate\"',\n  }),\n  [KnownEvaluationResultAssessmentName.GUIDELINES]: defineMessage({\n    defaultMessage: 'Guidelines',\n    description:\n      'Evaluation results > known type of evaluation result assessment > guidelines assessment. Used to indicate if the result adheres to the guidelines in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Guidelines: moderate\"',\n  }),\n  [KnownEvaluationResultAssessmentName.GLOBAL_GUIDELINE_ADHERENCE]: defineMessage({\n    defaultMessage: 'Global guideline adherence',\n    description:\n      'Evaluation results > known type of evaluation result assessment > global guideline adherence assessment. Used to indicate if the result adheres to the global guidelines in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Global guideline adherence: moderate\"',\n  }),\n};\n\nexport const KnownEvaluationResultAssessmentValueMissingTooltip: Record<string, MessageDescriptor> = {\n  [KnownEvaluationResultAssessmentName.CORRECTNESS]: defineMessage({\n    defaultMessage:\n      'Correctness assessment is missing. This is likely because you have not provided an expected response (ground truth) or grading notes.',\n    description:\n      'Evaluation results > known type of evaluation result assessment > correctness assessment. Used to indicate if the result is correct in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Correctness: mostly yes, have gaps\"',\n  }),\n  [KnownEvaluationResultAssessmentName.GROUNDEDNESS]: defineMessage({\n    defaultMessage:\n      'Groundedness assessment is missing. This is likely because your agent is not returning retrieved_context.',\n    description:\n      'Evaluation results > known type of evaluation result assessment > groundedness assessment. Used to indicate if the result is grounded in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Groundedness: moderately grounded\"',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_GROUNDEDNESS]: defineMessage({\n    defaultMessage:\n      'Retrieval Groundedness assessment is missing. This is likely because your agent is not returning retrieved_context.',\n    description:\n      'Evaluation results > known type of evaluation result assessment > retrieval groundedness assessment. Used to indicate if the result is grounded in context of LLMs evaluation. Label displayed if user provided custom value, e.g. \"Retrieval Groundedness: moderately grounded\"',\n  }),\n  [KnownEvaluationResultAssessmentName.CONTEXT_SUFFICIENCY]: defineMessage({\n    defaultMessage:\n      'Context sufficiency assessment is missing. This is likely because your agent is not returning retrieved_context.',\n    description:\n      'Evaluation results > known type of evaluation result assessment > context sufficiency assessment. Used to indicate if the retrieved context is sufficient to generate the expected response. Label displayed if user provided custom value, e.g. \"Context Sufficiency: mostly sufficient\"',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_SUFFICIENCY]: defineMessage({\n    defaultMessage:\n      'Retrieval sufficiency assessment is missing. This is likely because your agent is not returning retrieved_context.',\n    description:\n      'Evaluation results > known type of evaluation result assessment > retrieval sufficiency assessment. Used to indicate if the retrieved context is sufficient to generate the expected response. Label displayed if user provided custom value, e.g. \"Retrieval sufficiency: mostly sufficient\"',\n  }),\n};\n\nexport const KnownEvaluationResultAssessmentValueDescription: Record<string, MessageDescriptor> = {\n  [KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT]: defineMessage({\n    defaultMessage: 'The overall assessment passes when all of the judges pass.',\n    description:\n      'Evaluation results > known type of evaluation result assessment > overall assessment > description of overall assessment',\n  }),\n  [KnownEvaluationResultAssessmentName.CORRECTNESS]: defineMessage({\n    defaultMessage:\n      \"The correctness LLM judge gives a binary evaluation and written rationale on whether the agent's generated response is factually accurate and semantically similar to the provided ground-truth response or grading notes.\",\n    description:\n      'Evaluation results > known type of evaluation result assessment > description of correctness assessment.',\n  }),\n  [KnownEvaluationResultAssessmentName.GROUNDEDNESS]: defineMessage({\n    defaultMessage:\n      \"The groundedness LLM judge returns a binary evaluation and written rationale on whether the generated response is factually consistent with the agent's retrieved context.\",\n    description: 'Evaluation results > known type of evaluation result assessment > description of groundedness judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_GROUNDEDNESS]: defineMessage({\n    defaultMessage:\n      \"The retrieval groundedness LLM judge returns a binary evaluation and written rationale on whether the generated response is factually consistent with the agent's retrieved context.\",\n    description:\n      'Evaluation results > known type of evaluation result assessment > description of retrieval groundedness judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.RELEVANCE_TO_QUERY]: defineMessage({\n    defaultMessage:\n      'The relevance_to_query LLM judge determines whether the response is relevant to the input request.',\n    description: 'Evaluation results > known type of evaluation result assessment > description of relevance judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.SAFETY]: defineMessage({\n    defaultMessage:\n      'The safety LLM judge returns a binary rating and a written rationale on whether the generated response has harmful or toxic content.',\n    description: 'Evaluation results > known type of evaluation result assessment > description of safety judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.CHUNK_RELEVANCE]: defineMessage({\n    defaultMessage:\n      'The chunk-relevance-precision LLM judge determines whether the chunks returned by the retriever are relevant to the input request. Precision is calculated as the number of relevant chunks returned divided by the total number of chunks returned. For example, if the retriever returns four chunks, and the LLM judge determines that three of the four returned documents are relevant to the request, then llm_judged/chunk_relevance/precision is 0.75.',\n    description: 'Evaluation results > known type of evaluation result assessment > chunk relevance judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_RELEVANCE]: defineMessage({\n    defaultMessage:\n      'The retrieval-relevance LLM judge determines whether the chunks returned by the retriever are relevant to the input request. Precision is calculated as the number of relevant chunks returned divided by the total number of chunks returned. For example, if the retriever returns four chunks, and the LLM judge determines that three of the four returned documents are relevant to the request, then llm_judged/chunk_relevance/precision is 0.75.',\n    description: 'Evaluation results > known type of evaluation result assessment > retrieval relevance judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.CONTEXT_SUFFICIENCY]: defineMessage({\n    defaultMessage:\n      'The context sufficiency LLM judge determines whether the retrieved context is sufficient to generate the expected response.',\n    description: 'Evaluation results > known type of evaluation result assessment > context sufficiency judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_SUFFICIENCY]: defineMessage({\n    defaultMessage:\n      'The retrieval sufficiency LLM judge determines whether the retrieved context is sufficient to generate the expected response.',\n    description: 'Evaluation results > known type of evaluation result assessment > retrieval sufficiency judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.GUIDELINE_ADHERENCE]: defineMessage({\n    defaultMessage:\n      'The guideline adherence LLM judge determines whether the response adheres to the guidelines provided.',\n    description: 'Evaluation results > known type of evaluation result assessment > guideline adherence judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.GUIDELINES]: defineMessage({\n    defaultMessage:\n      'The guidelines LLM judge determines whether the response adheres to the guidelines provided. All responses must adhere to guidelines.',\n    description: 'Evaluation results > known type of evaluation result assessment > guidelines judge.',\n  }),\n  [KnownEvaluationResultAssessmentName.GLOBAL_GUIDELINE_ADHERENCE]: defineMessage({\n    defaultMessage:\n      'The global guideline adherence LLM judge determines whether the response adheres to the global guidelines provided. All responses must adhere to global guidelines.',\n    description: 'Evaluation results > known type of evaluation result assessment > global guideline adherence judge.',\n  }),\n};\n\nexport const KnownEvaluationResultAssessmentValueMapping: Record<string, Record<string, MessageDescriptor>> = {\n  [KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Pass',\n      description:\n        'Evaluation results > overall assessment > pass value label. Displayed if evaluation result is overall considered as approved by LLM judge or human.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Fail',\n      description:\n        'Evaluation results > overall assessment > fail value label. Displayed if evaluation result is overall considered as disapproved by LLM judge or human.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.CHUNK_RELEVANCE]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Relevant',\n      description:\n        'Evaluation results > chunk relevancy assessment > positive value label. Displayed if evaluation result is considered as relevant to the query.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Irrelevant',\n      description:\n        'Evaluation results > chunk relevancy assessment > negative value label. Displayed if evaluation result is considered as irrelevant to the query.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_RELEVANCE]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Relevant',\n      description:\n        'Evaluation results > retrieval relevancy assessment > positive value label. Displayed if evaluation result is considered as relevant to the query.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Irrelevant',\n      description:\n        'Evaluation results > retrieval relevancy assessment > negative value label. Displayed if evaluation result is considered as irrelevant to the query.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.CONTEXT_SUFFICIENCY]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Context sufficient',\n      description:\n        'Evaluation results > context sufficiency assessment > positive value label. Displayed if retrieved context is sufficient to generate the expected response.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Context insufficient',\n      description:\n        'Evaluation results > context sufficiency assessment > negative value label. Displayed if retrieved context is insufficient to generate the expected response.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_SUFFICIENCY]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Sufficient',\n      description:\n        'Evaluation results > retrieval sufficiency assessment > positive value label. Displayed if retrieved context is sufficient to generate the expected response.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Insufficient',\n      description:\n        'Evaluation results > retrieval sufficiency assessment > negative value label. Displayed if retrieved context is insufficient to generate the expected response.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.RELEVANCE_TO_QUERY]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Relevant',\n      description:\n        'Evaluation results > relevancy assessment > positive value label. Displayed if evaluation result is considered as irrelevant to the query.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Irrelevant',\n      description:\n        'Evaluation results > relevancy assessment > negative value label. Displayed if evaluation result is considered as irrelevant to the query.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.GROUNDEDNESS]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Grounded',\n      description:\n        'Evaluation results > grounded assessment > positive value label. Displayed if evaluation result is considered as grounded.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Not grounded',\n      description:\n        'Evaluation results > grounded assessment > negative value label. Displayed if evaluation result is considered as not grounded.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.RETRIEVAL_GROUNDEDNESS]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Grounded',\n      description:\n        'Evaluation results > retrieval grounded assessment > positive value label. Displayed if evaluation result is considered as grounded.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Not grounded',\n      description:\n        'Evaluation results > retrieval grounded assessment > negative value label. Displayed if evaluation result is considered as not grounded.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.CORRECTNESS]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Correct',\n      description:\n        'Evaluation results > correctness assessment > positive value label. Displayed if evaluation result is considered as correct.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Incorrect',\n      description:\n        'Evaluation results > correctness assessment > negative value label. Displayed if evaluation result is considered as incorrect.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.SAFETY]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Safe',\n      description:\n        'Evaluation results > safety assessment > positive value label. Displayed if evaluation result is considered as safe.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Unsafe',\n      description:\n        'Evaluation results > safety assessment > negative value label. Displayed if evaluation result is considered as unsafe.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.GUIDELINE_ADHERENCE]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Adheres to guidelines',\n      description:\n        'Evaluation results > guideline adherence assessment > positive value label. Displayed if evaluation result adheres to the guidelines.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Violates guidelines',\n      description:\n        'Evaluation results > guideline adherence assessment > negative value label. Displayed if evaluation result does not adhere to the guidelines.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.GUIDELINES]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Adheres to guidelines',\n      description:\n        'Evaluation results > guidelines assessment > positive value label. Displayed if evaluation result adheres to the guidelines.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Violates guidelines',\n      description:\n        'Evaluation results > guidelines assessment > negative value label. Displayed if evaluation result does not adhere to the guidelines.',\n    }),\n  },\n  [KnownEvaluationResultAssessmentName.GLOBAL_GUIDELINE_ADHERENCE]: {\n    [KnownEvaluationResultAssessmentStringValue.YES]: defineMessage({\n      defaultMessage: 'Adheres to global guidelines',\n      description:\n        'Evaluation results > global guideline adherence assessment > positive value label. Displayed if evaluation result adheres to the global guidelines.',\n    }),\n    [KnownEvaluationResultAssessmentStringValue.NO]: defineMessage({\n      defaultMessage: 'Violates global guidelines',\n      description:\n        'Evaluation results > global guideline adherence assessment > negative value label. Displayed if evaluation result does not adhere to the global guidelines.',\n    }),\n  },\n};\n\nconst isAssessmentAiGenerated = (assessment: RunEvaluationResultAssessment) => {\n  return assessment?.source?.sourceType === 'AI_JUDGE';\n};\n\n/**\n * Returns the title for the given evaluation result.\n * If the evaluation has an input request, it will be used as the title. Otherwise, the evaluation ID will be used.\n * Stringifies the value if it's an object or an array.\n */\nexport const getEvaluationResultTitle = (evaluation: RunEvaluationTracesDataEntry): string => {\n  // Use the request as the title if defined.\n  let title = getEvaluationResultInputTitle(evaluation, INPUT_REQUEST_KEY);\n\n  if (isNil(title)) {\n    title = getEvaluationResultInputTitle(evaluation, INPUT_MESSAGES_KEY);\n  }\n\n  // If the title is still undefined, JSON-serialize the inputs.\n  if (isNil(title) && !isNil(evaluation.inputs) && Object.keys(evaluation.inputs).length > 0) {\n    title = stringifyValue(evaluation.inputs);\n  }\n\n  if (isNil(title) || title === '') {\n    title = evaluation.evaluationId;\n  }\n\n  return title;\n};\n\n/**\n * Returns the title for the given evaluation result and input key.\n * This is different than getEvaluationResultTitle in that it computes a title per input key. getEvaluationResultTitle returns a title for the\n * whole row (used in the header of an evaluation modal).\n */\nexport const getEvaluationResultInputTitle = (\n  evaluation: RunEvaluationTracesDataEntry,\n  inputKey: string,\n): string | undefined => {\n  if (!isNil(evaluation.inputsTitle)) {\n    return typeof evaluation.inputsTitle === 'string' ? evaluation.inputsTitle : JSON.stringify(evaluation.inputsTitle);\n  }\n  // Use the request as the title if defined.\n  let title: string | undefined = undefined;\n  // Use the last message content as the title if defined.\n  const input = evaluation.inputs[inputKey];\n  if (\n    isPlainObject(input) &&\n    !isNil(input[INPUT_MESSAGES_KEY]) &&\n    Array.isArray(input[INPUT_MESSAGES_KEY]) &&\n    !isNil(input[INPUT_MESSAGES_KEY][0]?.content)\n  ) {\n    title = input[INPUT_MESSAGES_KEY][input[INPUT_MESSAGES_KEY].length - 1]?.content;\n  } else if (!isNil(input) && Array.isArray(input) && !isNil(input[0]?.content)) {\n    // Try to parse OpenAI messages.\n    title = input[input.length - 1]?.content;\n  } else {\n    title = input ? stringifyValue(input) : undefined;\n  }\n\n  return title;\n};\n\nexport const isEvaluationResultOverallAssessment = (assessmentEntry: RunEvaluationResultAssessment) =>\n  assessmentEntry.metadata?.[KnownEvaluationResultAssessmentMetadataFields.IS_OVERALL_ASSESSMENT] === true;\n\nexport const isEvaluationResultPerRetrievalChunkAssessment = (assessmentEntry: RunEvaluationResultAssessment) =>\n  isNumber(assessmentEntry.metadata?.[KnownEvaluationResultAssessmentMetadataFields.CHUNK_INDEX]);\n\nexport const getEvaluationResultAssessmentValue = (\n  assessment: RunEvaluationResultAssessment,\n): AssessmentValueType | undefined => {\n  const value = assessment.stringValue ?? assessment.numericValue ?? assessment.booleanValue;\n  if (isNil(value)) {\n    return undefined;\n  }\n  return value;\n};\n\n/**\n * Add alpha channel to the given hex color.\n */\nexport function withAlpha(hexColor: string, opacity: number): string {\n  let color = hexColor;\n  const startsWithHash = color.startsWith('#');\n  if (startsWithHash) {\n    color = hexColor.slice(1);\n  }\n  const alpha = Math.round(Math.min(Math.max(opacity, 0), 1) * 255);\n  const hexAlpha = alpha.toString(16).toUpperCase();\n  return `${startsWithHash ? '#' : ''}${color}${hexAlpha}`;\n}\n\n/**\n * A list of known response assessment names, used to populate suggestions\n */\nexport const KnownEvaluationResponseAssessmentNames = [\n  KnownEvaluationResultAssessmentName.GUIDELINE_ADHERENCE,\n  KnownEvaluationResultAssessmentName.GUIDELINES,\n  KnownEvaluationResultAssessmentName.GLOBAL_GUIDELINE_ADHERENCE,\n  KnownEvaluationResultAssessmentName.RELEVANCE_TO_QUERY,\n  KnownEvaluationResultAssessmentName.CONTEXT_SUFFICIENCY,\n  KnownEvaluationResultAssessmentName.RETRIEVAL_SUFFICIENCY,\n  KnownEvaluationResultAssessmentName.CORRECTNESS,\n  KnownEvaluationResultAssessmentName.GROUNDEDNESS,\n  KnownEvaluationResultAssessmentName.RETRIEVAL_GROUNDEDNESS,\n  KnownEvaluationResultAssessmentName.SAFETY,\n];\n\n/**\n * A list of known retrieval assessment names, used to populate suggestions\n */\nexport const KnownEvaluationRetrievalAssessmentNames = [KnownEvaluationResultAssessmentName.CHUNK_RELEVANCE];\n\n/**\n * Creates a draft assessment object with the given values.\n */\nexport const createDraftEvaluationResultAssessmentObject = ({\n  name,\n  isOverallAssessment,\n  value,\n  rationale,\n  metadata = {},\n}: {\n  isOverallAssessment: boolean;\n  name: string;\n  value: string | boolean;\n  rationale?: string;\n  metadata?: RunEvaluationResultAssessment['metadata'];\n}): RunEvaluationResultAssessmentDraft => {\n  // Use current user's email to set as source ID\n  const sourceId = getUser() ?? '';\n\n  const resultMetadata = isOverallAssessment\n    ? { ...metadata, [KnownEvaluationResultAssessmentMetadataFields.IS_OVERALL_ASSESSMENT]: true }\n    : metadata;\n\n  const booleanValue = typeof value === 'boolean' ? value : null;\n  const stringValue = typeof value !== 'boolean' ? value : null;\n\n  return {\n    booleanValue: booleanValue,\n    numericValue: null,\n    stringValue: stringValue,\n    name,\n    metadata: resultMetadata,\n    rationale: rationale ?? null,\n    source: {\n      sourceId,\n      sourceType: 'HUMAN',\n      metadata: {},\n    },\n    timestamp: Date.now(),\n    isDraft: true,\n  };\n};\n\nexport const shouldRepeatExistingOriginalOverallAiAssessment = (\n  sourceEvaluationResult: RunEvaluationTracesDataEntry,\n  pendingAssessmentEntries: RunEvaluationResultAssessmentDraft[],\n) =>\n  sourceEvaluationResult.overallAssessments.length > 0 &&\n  sourceEvaluationResult.overallAssessments.every(isAssessmentAiGenerated) &&\n  !pendingAssessmentEntries.some(isEvaluationResultOverallAssessment);\n\nexport const copyAiOverallAssessmentAsHumanAssessment = (\n  sourceEvaluationResult: RunEvaluationTracesDataEntry,\n): RunEvaluationResultAssessmentDraft | null => {\n  const firstAiOverallAssessment = sourceEvaluationResult.overallAssessments.find(isAssessmentAiGenerated);\n\n  if (!firstAiOverallAssessment) {\n    return null;\n  }\n\n  const sourceId = getUser() ?? '';\n\n  return {\n    ...firstAiOverallAssessment,\n    timestamp: Date.now(),\n    isDraft: true,\n    source: {\n      sourceType: 'HUMAN',\n      sourceId,\n      metadata: {},\n    },\n    metadata: {\n      ...firstAiOverallAssessment.metadata,\n      // Explicitly marking it as reviewed to indicate this assessment is copied from AI\n      [KnownEvaluationResultAssessmentMetadataFields.IS_COPIED_FROM_AI]: true,\n    },\n  };\n};\n\nexport const isDraftAssessment = (\n  assessment: RunEvaluationResultAssessment | RunEvaluationResultAssessmentDraft,\n): assessment is RunEvaluationResultAssessmentDraft => 'isDraft' in assessment && assessment.isDraft;\n\n/**\n * Returns a list of detailed assessments.\n *\n * For well-known assessments, the list is sorted based on the known stable order;\n * for other assessments, the list is sorted based on the timestamp of the first appearance\n * of the assessment (last item in the group).\n */\nexport const getOrderedAssessments = (assessmentsByName: Record<string, RunEvaluationResultAssessment[]>) =>\n  orderBy(Object.entries(assessmentsByName), ([key, assessments], index) => {\n    // If we're dealing with a known detailed assessment, we want to sort it based on its index in the known names list\n    // so its position is stable\n    const indexInKnownNames = DEFAULT_ASSESSMENTS_SORT_ORDER.indexOf(key as KnownEvaluationResultAssessmentName);\n\n    if (indexInKnownNames !== -1) {\n      // If it's a known detailed assessment, sort by its index in the known names list\n      return indexInKnownNames;\n    } else {\n      // Otherwise, sort by the timestamp of the last item in the group\n      return assessments[assessments.length - 1]?.timestamp ?? index;\n    }\n  });\n\nexport const isEvaluationResultReviewedAlready = (evaluationResult: RunEvaluationTracesDataEntry) =>\n  evaluationResult.overallAssessments\n    ?.filter((assessment) => !isDraftAssessment(assessment))\n    .some((assessment) => !isAssessmentAiGenerated(assessment)) ?? false;\n\nexport const hasBeenEditedByHuman = (assessment: RunEvaluationResultAssessment) =>\n  // It is not AI generated, and it doesn't have the `IS_FROM_AI` metadata field set to true\n  assessment.source?.sourceType === 'HUMAN' &&\n  !assessment.metadata?.[KnownEvaluationResultAssessmentMetadataFields.IS_COPIED_FROM_AI];\n\nexport const getEvaluationResultAssessmentChunkIndex = (assessment: RunEvaluationResultAssessment) =>\n  assessment.metadata?.[KnownEvaluationResultAssessmentMetadataFields.CHUNK_INDEX];\n\n// Auto select the first non-empty evaluation ID if no evaluation ID is selected\nexport const autoSelectFirstNonEmptyEvaluationId = (\n  evaluationResults: RunEvaluationTracesDataEntry[] | null,\n  selectedEvaluationId: string | undefined,\n  setSelectedEvaluationId: (evaluationId: string | undefined) => void,\n) => {\n  if (!selectedEvaluationId && evaluationResults) {\n    // Find first non-empty evaluationId in data\n    const firstNonEmpty = evaluationResults.find((evaluation) => evaluation.evaluationId);\n    if (firstNonEmpty) {\n      setSelectedEvaluationId(firstNonEmpty.evaluationId);\n    }\n  }\n};\n\n/**\n * Converts the given value to a string if it's an object or an array.\n */\nexport const stringifyValue = (value: any) => {\n  return isPlainObject(value) || Array.isArray(value) ? JSON.stringify(value, undefined, 2) : value;\n};\n\n/**\n * Utility function: generates suggestions for the assessment values based on original assessment and options.\n */\nexport const getAssessmentValueSuggestions = (\n  intl: IntlShape,\n  originalAssessment?: RunEvaluationResultAssessment,\n  assessmentHistory?: RunEvaluationResultAssessment[],\n  assessmentInfos?: AssessmentInfo[],\n) => {\n  // If we're starting with an existing assessment, we should suggest the values that are relevant to it.\n  if (originalAssessment) {\n    const mapping = KnownEvaluationResultAssessmentValueMapping[originalAssessment.name];\n    if (!mapping) {\n      return [];\n    }\n\n    return Object.entries(mapping).map(([key, value]) => {\n      return { key, label: intl.formatMessage(value), rootAssessmentName: originalAssessment.name };\n    });\n  }\n\n  // If we're starting with a new assessment, we only suggest 'boolean' values and a new value.\n  return (assessmentInfos || [])\n    .filter((assessmentInfo) => assessmentInfo.dtype === 'boolean')\n    .map((assessmentInfo) => ({\n      key: assessmentInfo.name,\n      label: assessmentInfo.name,\n      rootAssessmentName: assessmentInfo.name,\n      // Disabled when the assessment already exists.\n      disabled: assessmentHistory?.some((assessment) => assessment.name === assessmentInfo.name),\n    }));\n};\n\n/**\n * Returns true if the assessment is missing.\n * An assessment is considered missing if it doesn't have a value, rationale or error message.\n */\nexport const isAssessmentMissing = (assessment?: RunEvaluationResultAssessment) => {\n  if (!assessment) {\n    return false;\n  } else {\n    const hasRationale = Boolean(assessment.rationale);\n    const hasValue = !isNil(getEvaluationResultAssessmentValue(assessment));\n    const hasErrorMessage = Boolean(assessment.errorMessage);\n    return !(hasRationale || hasValue || hasErrorMessage);\n  }\n};\n\n/**\n * Checks if the given value is a retrieved context.\n * A retrieved context is a list of objects with a `doc_uri` and `content` field.\n */\nexport const isRetrievedContext = (value: any): boolean => {\n  return Array.isArray(value) && value.every((v) => isPlainObject(v) && 'doc_uri' in v && 'content' in v);\n};\n","import { first, isNil } from 'lodash';\n\nimport type { ThemeType } from '@databricks/design-system';\nimport type { IntlShape } from '@databricks/i18n';\n\nimport { getAssessmentValueBarBackgroundColor } from './Colors';\nimport { isAssessmentPassing } from '../components/EvaluationsReviewAssessmentTag';\nimport {\n  ASSESSMENTS_DOC_LINKS,\n  DEFAULT_ASSESSMENTS_SORT_ORDER,\n  getEvaluationResultAssessmentValue,\n  getJudgeMetricsLink,\n  KnownEvaluationResultAssessmentName,\n  KnownEvaluationResultAssessmentStringValue,\n  KnownEvaluationResultAssessmentValueDescription,\n  KnownEvaluationResultAssessmentValueLabel,\n  KnownEvaluationResultAssessmentValueMissingTooltip,\n} from '../components/GenAiEvaluationTracesReview.utils';\nimport type {\n  AssessmentAggregates,\n  AssessmentRunCounts,\n  AssessmentInfo,\n  EvalTraceComparisonEntry,\n  RunEvaluationResultAssessment,\n  RunEvaluationTracesDataEntry,\n  AssessmentDType,\n  AssessmentFilter,\n  AssessmentValueType,\n  NumericAggregateCount,\n  NumericAggregate,\n} from '../types';\n\nexport interface StackedRunBarchartItem {\n  value: number;\n  fraction: number;\n  isSelected: boolean;\n  toggleFilter?: () => void;\n  tooltip: string;\n}\nexport interface StackedBarchartItem {\n  name: string;\n  current: StackedRunBarchartItem;\n  other?: StackedRunBarchartItem;\n  backgroundColor: string;\n  scoreChange?: number;\n}\n\nexport const ERROR_KEY = 'Error';\n\nexport function doesAssessmentContainErrors(assessment?: RunEvaluationResultAssessment): boolean {\n  return Boolean(assessment?.errorCode || assessment?.errorMessage);\n}\n\nfunction getCustomMetricNameAndAssessment(assessmentPath: string): { metricName: string; assessmentName: string } {\n  // metric/all_guidelines/guideline_adherence\n  // gets parsed to {metricName: 'all_guidelines', assessmentName: 'guideline_adherence'}\n  const splits = assessmentPath.split('/');\n  if (splits.length === 1) {\n    return { metricName: assessmentPath, assessmentName: assessmentPath };\n  } else if (splits.length === 2) {\n    return { metricName: splits[0], assessmentName: splits[1] };\n  } else {\n    return { metricName: splits[1], assessmentName: splits.slice(2).join('/') };\n  }\n}\n\nconst PASS_FAIL_VALUES: string[] = [\n  KnownEvaluationResultAssessmentStringValue.YES,\n  KnownEvaluationResultAssessmentStringValue.NO,\n];\n/**\n * Computes global metadata for each of the assessments.\n */\nexport function getAssessmentInfos(\n  intl: IntlShape,\n  currentEvaluationResults: RunEvaluationTracesDataEntry[],\n  otherEvaluationResults: RunEvaluationTracesDataEntry[] | undefined,\n): AssessmentInfo[] {\n  const assessmentInfos: Record<string, AssessmentInfo> = {};\n  // Compute dtypes in the first pass.\n  const assessmentDtypes: Record<string, AssessmentDType | undefined> = {\n    [KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT]: 'pass-fail',\n  };\n  // Set of all assessment names. Will be filled after the first pass when computing dtypes.\n  const assessmentNames = new Set<string>();\n\n  [...currentEvaluationResults, ...(otherEvaluationResults || [])].forEach((result) => {\n    const responseAssessmentsByName: [string, RunEvaluationResultAssessment[]][] = Object.entries(\n      result.responseAssessmentsByName || {},\n    );\n\n    const overallAssessmentsByName: [string, RunEvaluationResultAssessment[]][] = result.overallAssessments.map(\n      (assessment) => [KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT as string, [assessment]],\n    );\n    const retrievalAssessmentsByName: [string, RunEvaluationResultAssessment[]][] = [];\n    result.retrievalChunks?.forEach((chunk) => {\n      // Iterate chunk.retrievalAssessmentsByName\n      for (const [assessmentName, assessments] of Object.entries(chunk.retrievalAssessmentsByName || {})) {\n        retrievalAssessmentsByName.push([assessmentName, assessments]);\n      }\n    });\n\n    for (const [assessmentName, assessments] of [\n      ...responseAssessmentsByName,\n      ...overallAssessmentsByName,\n      ...retrievalAssessmentsByName,\n    ]) {\n      assessmentNames.add(assessmentName);\n      const assessment = assessments[0];\n      // For string values, if we see a value that is not \"yes\" or \"no\", we treat it as a string.\n      // This is not a great approach, we should probably actually pass the pass-fail dtype information back somehow.\n      let dtype: AssessmentDType | undefined = !isNil(assessment.stringValue)\n        ? 'pass-fail'\n        : !isNil(assessment.numericValue)\n        ? 'numeric'\n        : !isNil(assessment.booleanValue)\n        ? 'boolean'\n        : undefined;\n\n      if (doesAssessmentContainErrors(assessment)) {\n        dtype = undefined;\n      }\n\n      if (!assessmentDtypes[assessmentName]) {\n        if (assessmentName in KnownEvaluationResultAssessmentValueLabel) {\n          dtype = 'pass-fail';\n        }\n        assessmentDtypes[assessmentName] = dtype;\n      }\n\n      // Treat non-\"yes\"|\"no\" as string values.\n      if (\n        dtype === 'pass-fail' &&\n        !isNil(assessment.stringValue) &&\n        !PASS_FAIL_VALUES.includes(assessment.stringValue)\n      ) {\n        assessmentDtypes[assessmentName] = 'string';\n      }\n\n      // If the dtype is not the same as the current dtype (meaning there's mixed data types),\n      // treat it as a string.\n      if (dtype !== undefined && dtype !== assessmentDtypes[assessmentName]) {\n        assessmentDtypes[assessmentName] = 'string';\n      }\n    }\n  });\n\n  // if any assessment does not have a dtype, give it 'unknown' type. this can happen if all evaluations for that assessment are errors\n  for (const assessmentName of assessmentNames) {\n    if (!assessmentDtypes[assessmentName]) {\n      assessmentDtypes[assessmentName] = 'unknown';\n    }\n  }\n\n  [...currentEvaluationResults, ...(otherEvaluationResults || [])].forEach((result) => {\n    const responseAssessmentsByName: [string, RunEvaluationResultAssessment[]][] = Object.entries(\n      result.responseAssessmentsByName || {},\n    );\n\n    const overallAssessmentsByName: [string, RunEvaluationResultAssessment[]][] = result.overallAssessments.map(\n      (assessment) => [KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT as string, [assessment]],\n    );\n    const retrievalAssessmentsByName: [string, RunEvaluationResultAssessment[]][] = [];\n    result.retrievalChunks?.forEach((chunk) => {\n      // Iterate chunk.retrievalAssessmentsByName\n      for (const [assessmentName, assessments] of Object.entries(chunk.retrievalAssessmentsByName || {})) {\n        retrievalAssessmentsByName.push([assessmentName, assessments]);\n      }\n    });\n\n    const assessmentNames = Object.keys(assessmentDtypes);\n    for (const assessmentName of assessmentNames) {\n      const assessmentsByName = [\n        ...responseAssessmentsByName.filter(([name]) => name === assessmentName),\n        ...overallAssessmentsByName.filter(([name]) => name === assessmentName),\n        ...retrievalAssessmentsByName.filter(([name]) => name === assessmentName),\n      ];\n      // NOTE: We only take the first assessment as row-level judges produce a single assessment.\n      const assessments = assessmentsByName.map(([_, assessments]) => assessments[0]);\n      const assessment: RunEvaluationResultAssessment | undefined = assessments[0];\n\n      const isError = doesAssessmentContainErrors(assessment);\n\n      if (isNil(assessmentInfos[assessmentName])) {\n        let displayName: string;\n        let metricName: string;\n        let isCustomMetric = false;\n\n        const isKnown = KnownEvaluationResultAssessmentValueLabel[assessmentName] !== undefined;\n        if (isKnown) {\n          displayName = intl.formatMessage(KnownEvaluationResultAssessmentValueLabel[assessmentName]);\n          metricName = assessmentName;\n          isCustomMetric = false;\n        } else {\n          const { metricName: customMetricName, assessmentName: customAssessmentName } =\n            getCustomMetricNameAndAssessment(assessmentName);\n          displayName = customAssessmentName || '-';\n          metricName = customMetricName;\n          if (assessment?.source?.sourceType === 'CODE') {\n            isCustomMetric = true;\n          }\n        }\n        const dtype = assessmentDtypes[assessmentName] || 'string';\n\n        const docsLink = getJudgeMetricsLink(ASSESSMENTS_DOC_LINKS[assessmentName]);\n        const missingTooltip =\n          assessmentName in KnownEvaluationResultAssessmentValueMissingTooltip\n            ? intl.formatMessage(KnownEvaluationResultAssessmentValueMissingTooltip[assessmentName])\n            : '';\n        const description =\n          assessmentName in KnownEvaluationResultAssessmentValueDescription\n            ? intl.formatMessage(KnownEvaluationResultAssessmentValueDescription[assessmentName])\n            : assessment?.source?.sourceType === 'HUMAN'\n            ? intl.formatMessage({\n                defaultMessage: 'This assessment is produced by a human judge.',\n                description: 'Human judge assessment description',\n              })\n            : intl.formatMessage({\n                defaultMessage: 'This assessment is produced by a custom metric.',\n                description: 'Custom judge assessment description',\n              });\n\n        let assessmentValue = assessment ? getEvaluationResultAssessmentValue(assessment) : undefined;\n        if (assessmentValue === null) assessmentValue = undefined;\n\n        const uniqueValues = new Set<AssessmentValueType>();\n        if (!isError) {\n          uniqueValues.add(assessmentValue);\n        }\n\n        assessmentInfos[assessmentName] = {\n          name: assessmentName,\n          displayName: displayName,\n          isKnown,\n          metricName,\n          isCustomMetric,\n          source: assessment?.source,\n          dtype,\n          uniqueValues,\n          isOverall: assessmentName === KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT,\n          docsLink,\n          missingTooltip,\n          description,\n          isEditable: assessment?.source?.sourceType === 'AI_JUDGE' || assessment?.source?.sourceType === 'HUMAN',\n          isRetrievalAssessment: retrievalAssessmentsByName.some(([name]) => name === assessmentName),\n          containsErrors: isError,\n        };\n      } else {\n        const assessmentInfo = assessmentInfos[assessmentName];\n        let value = assessment ? getEvaluationResultAssessmentValue(assessment) : undefined;\n        if (isNil(value)) value = undefined;\n        if (!isError) {\n          assessmentInfo.uniqueValues.add(value);\n        }\n\n        // Update isEditable.\n        if (!assessmentInfo.isEditable) {\n          assessmentInfo.isEditable =\n            assessment?.source?.sourceType === 'AI_JUDGE' || assessment?.source?.sourceType === 'HUMAN';\n        }\n\n        // isRetrievalAssessment should be true if any evaluation result has this assessment.\n        assessmentInfo.isRetrievalAssessment =\n          assessmentInfo.isRetrievalAssessment || retrievalAssessmentsByName.some(([name]) => name === assessmentName);\n\n        assessmentInfo.containsErrors = assessmentInfo.containsErrors || isError;\n      }\n    }\n  });\n\n  // Remove the overall assessment if it does not have any non-null values.\n  const seenOverallAssessmentValues =\n    assessmentInfos[KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT]?.uniqueValues || new Set();\n  const hasOverallValue =\n    seenOverallAssessmentValues.has(KnownEvaluationResultAssessmentStringValue.YES) ||\n    seenOverallAssessmentValues.has(KnownEvaluationResultAssessmentStringValue.NO);\n  if (!hasOverallValue) {\n    delete assessmentInfos[KnownEvaluationResultAssessmentName.OVERALL_ASSESSMENT];\n  }\n\n  return sortAssessmentInfos(Object.values(assessmentInfos));\n}\n\nexport function sortAssessmentInfos(assessmentInfos: AssessmentInfo[]): AssessmentInfo[] {\n  // Sort by DEFAULT_ASSESSMENTS_SORT_ORDER, fall back to alphabetical order of (metricName, name) which come after.\n  return assessmentInfos.sort((a, b) => {\n    const orderA = DEFAULT_ASSESSMENTS_SORT_ORDER.indexOf(a.name);\n    const orderB = DEFAULT_ASSESSMENTS_SORT_ORDER.indexOf(b.name);\n\n    // If both are in the sort order, compare their indices\n    if (orderA !== -1 && orderB !== -1) {\n      return orderA - orderB;\n    }\n\n    // If only one is in the sort order, prioritize it\n    if (orderA !== -1) return -1;\n    if (orderB !== -1) return 1;\n\n    // Otherwise, sort by name alphabetically\n    return a.name.localeCompare(b.name);\n  });\n}\n\nexport function getNumericAggregate(numericValues: number[]): NumericAggregate | undefined {\n  if (numericValues.length === 0) {\n    return undefined;\n  }\n\n  const numericAggregateCounts: NumericAggregateCount[] = [];\n  const min = Math.min(...numericValues);\n  const max = Math.max(...numericValues);\n\n  // Set a minimum bucket size of 0.01, since the data is displayed in 2 decimal places.\n  // Show at most 10 buckets.\n  const bucketSize = Math.max(0.01, (max - min) / 10);\n  let maxCount = 0;\n\n  if (min === max) {\n    numericAggregateCounts.push({ lower: min, upper: max, count: numericValues.length });\n  } else {\n    for (let i = min; i < max; i += bucketSize) {\n      numericAggregateCounts.push({ lower: i, upper: Math.min(i + bucketSize, max), count: 0 });\n    }\n  }\n\n  numericAggregateCounts.sort((a, b) => a.lower - b.lower);\n  for (const numericValue of numericValues) {\n    const bucket = numericAggregateCounts.find(\n      (bucket) =>\n        numericValue >= bucket.lower &&\n        (numericValue < bucket.upper || (numericValue === bucket.upper && numericValue === max)),\n    );\n    if (bucket) {\n      bucket.count++;\n      maxCount = Math.max(maxCount, bucket.count);\n    }\n  }\n  return { min, max, maxCount, counts: numericAggregateCounts };\n}\n\nexport function getAssessmentNumericAggregates(\n  assessmentInfo: AssessmentInfo,\n  evalResults: RunEvaluationTracesDataEntry[],\n): NumericAggregate | undefined {\n  if (assessmentInfo.dtype !== 'numeric') {\n    return undefined;\n  }\n  const numericValues = evalResults\n    .flatMap((evalResult) => {\n      const assessments = assessmentInfo.isOverall\n        ? evalResult.overallAssessments\n        : evalResult.responseAssessmentsByName[assessmentInfo.name];\n      const result = assessments\n        ?.map((assessment) => getEvaluationResultAssessmentValue(assessment))\n        .filter((value) => value !== undefined && typeof value === 'number');\n      return result;\n    })\n    .filter((value) => !isNil(value));\n  return getNumericAggregate(numericValues);\n}\n\nfunction getAssessmentRunValueCounts(\n  assessmentInfo: AssessmentInfo,\n  evalResults: RunEvaluationTracesDataEntry[],\n): AssessmentRunCounts | undefined {\n  if (assessmentInfo.dtype === 'numeric') {\n    return undefined;\n  }\n  const valueCounts: AssessmentRunCounts = new Map();\n  evalResults.forEach((evalResult) => {\n    const assessments = assessmentInfo.isOverall\n      ? evalResult.overallAssessments\n      : evalResult.responseAssessmentsByName[assessmentInfo.name];\n    const valueCountsBySourceId =\n      assessments && assessments.length > 0\n        ? getUniqueValueCountsBySourceId(assessmentInfo, assessments)\n        : [{ value: undefined, count: 1 }];\n    const keysToCount = assessmentInfo.containsErrors\n      ? [ERROR_KEY, ...assessmentInfo.uniqueValues]\n      : assessmentInfo.uniqueValues;\n    for (const uniqueValue of keysToCount) {\n      const valueCountBySourceId = valueCountsBySourceId.find((valueCount) => valueCount.value === uniqueValue);\n      const count = valueCountBySourceId ? valueCountBySourceId.count : 0;\n      valueCounts.set(uniqueValue, (valueCounts.get(uniqueValue) || 0) + count);\n    }\n  });\n  return valueCounts;\n}\n\nfunction getAssessmentRunNumericValues(\n  assessmentInfo: AssessmentInfo,\n  evalResults: RunEvaluationTracesDataEntry[],\n): number[] | undefined {\n  if (assessmentInfo.dtype !== 'numeric') {\n    return undefined;\n  }\n  const values: number[] = [];\n  evalResults.forEach((evalResult) => {\n    const assessment = assessmentInfo.isOverall\n      ? first(evalResult.overallAssessments)\n      : first(evalResult.responseAssessmentsByName[assessmentInfo.name]);\n    if (assessment) {\n      const value = getEvaluationResultAssessmentValue(assessment);\n\n      if (!isNil(value)) {\n        values.push(Number(value));\n      }\n    }\n  });\n  return values;\n}\n\nfunction getRootCauseAssessmentCount(\n  assessmentInfo: AssessmentInfo,\n  evalResults: RunEvaluationTracesDataEntry[],\n): number {\n  let numRootCause = 0;\n  evalResults.forEach((evalResult) => {\n    if (isNil(evalResult)) return;\n    const overallAssessment = first(evalResult.overallAssessments);\n    if (overallAssessment?.rootCauseAssessment?.assessmentName === assessmentInfo.name) {\n      numRootCause++;\n    }\n  });\n  return numRootCause;\n}\n\nexport function getAssessmentAggregates(\n  assessmentInfo: AssessmentInfo,\n  evalResults: EvalTraceComparisonEntry[],\n  allAssessmentFilters: AssessmentFilter[],\n): AssessmentAggregates {\n  const currentEvalResults = evalResults.map((entry) => entry.currentRunValue).filter((entry) => !isNil(entry));\n  const otherEvalResults = evalResults.map((entry) => entry.otherRunValue).filter((entry) => !isNil(entry));\n\n  const currentAssessmentAggregates = getAssessmentRunValueCounts(assessmentInfo, currentEvalResults);\n  const otherAssessmentAggregates = getAssessmentRunValueCounts(assessmentInfo, otherEvalResults);\n\n  const currentNumericAggregates = getAssessmentNumericAggregates(assessmentInfo, currentEvalResults);\n\n  const assessmentFilters = allAssessmentFilters.filter((filter) => filter.assessmentName === assessmentInfo.name);\n\n  return {\n    assessmentInfo,\n    currentCounts: currentAssessmentAggregates,\n    otherCounts: otherAssessmentAggregates,\n    currentNumericValues: getAssessmentRunNumericValues(assessmentInfo, currentEvalResults),\n    otherNumericValues: getAssessmentRunNumericValues(assessmentInfo, otherEvalResults),\n    currentNumericAggregate: currentNumericAggregates,\n    currentNumRootCause: getRootCauseAssessmentCount(assessmentInfo, currentEvalResults),\n    otherNumRootCause: getRootCauseAssessmentCount(assessmentInfo, otherEvalResults),\n    assessmentFilters,\n  };\n}\n\n/**\n * Computes the total aggregate score for an assessment and evaluation results.\n *\n * For pass-fail dtypes, it computes what percentage of the runs have the assessment value as 'yes'.\n * for boolean dtypes, it computes what percentage of the runs have the assessment value as 'true'.\n */\nexport function getAssessmentAggregateOverallFraction(\n  assessmentInfo: AssessmentInfo,\n  assessmentRunCounts: AssessmentRunCounts = new Map(),\n): number {\n  if (assessmentInfo.dtype === 'pass-fail' || assessmentInfo.dtype === 'boolean') {\n    let total = 0;\n    let passCount = 0;\n    for (const [value, count] of assessmentRunCounts) {\n      if (isAssessmentPassing(assessmentInfo, value)) {\n        passCount += count;\n      }\n      // We only consider non-null values for the total score.\n      if (!isNil(value) && value !== ERROR_KEY) {\n        total += count;\n      }\n    }\n    return total > 0 ? passCount / total : 0;\n  }\n  return 0;\n}\n\nfunction getAssessmentBarChartValueBarItem(\n  intl: IntlShape,\n  assessmentInfo: AssessmentInfo,\n  assessmentFilters: AssessmentFilter[],\n  value: string | boolean | number | undefined,\n  valueCounts: AssessmentRunCounts,\n  runName: string,\n  toggleAssessmentFilter: (\n    assessmentName: string,\n    filterValue: AssessmentValueType,\n    run: string,\n    filterType: AssessmentFilter['filterType'],\n  ) => void,\n): StackedRunBarchartItem {\n  let numEvals = 0;\n  const isErrorOrNull = value === ERROR_KEY || value === undefined;\n  for (const [key, count] of valueCounts) {\n    if (key !== undefined && key !== ERROR_KEY) {\n      numEvals += count;\n    }\n  }\n  const numValue = valueCounts.get(value) || 0;\n  const fraction = !isErrorOrNull && numEvals > 0 ? numValue / numEvals : 0;\n\n  const filterType: AssessmentFilter['filterType'] = undefined;\n\n  return {\n    value: valueCounts.get(value) || 0,\n    fraction,\n    isSelected: assessmentFilters.some(\n      (filter) =>\n        filter.filterValue === value && filter.assessmentName === assessmentInfo.name && filter.run === runName,\n    ),\n    toggleFilter: () => toggleAssessmentFilter(assessmentInfo.name, value, runName, filterType),\n    tooltip: !isErrorOrNull\n      ? intl.formatMessage(\n          {\n            defaultMessage: '{numValue}/{numEvals} for run \"{runName}\"',\n            description: 'Passing assessment tooltip',\n          },\n          {\n            numValue: numValue,\n            numEvals,\n            runName,\n          },\n        )\n      : intl.formatMessage(\n          {\n            defaultMessage: '{numValue} for run \"{runName}\"',\n            description: 'Error/null assessment tooltip',\n          },\n          {\n            numValue,\n            runName,\n          },\n        ),\n  };\n}\n\nfunction getBarChartKeys(assessmentInfo: AssessmentInfo) {\n  const keys = getSortedUniqueValues(assessmentInfo);\n  if (assessmentInfo.containsErrors) {\n    keys.push(ERROR_KEY);\n  }\n\n  return keys;\n}\n\nexport function getBarChartData(\n  intl: IntlShape,\n  theme: ThemeType,\n  assessmentInfo: AssessmentInfo,\n  assessmentFilters: AssessmentFilter[],\n  toggleAssessmentFilter: (\n    assessmentName: string,\n    filterValue: AssessmentValueType,\n    run: string,\n    filterType: AssessmentFilter['filterType'],\n  ) => void,\n  displayInfoCounts: AssessmentAggregates,\n  currentRunDisplayName?: string,\n  compareToRunDisplayName?: string,\n): StackedBarchartItem[] {\n  const showCompareData = displayInfoCounts.otherCounts !== undefined;\n\n  const barItems: StackedBarchartItem[] = [];\n\n  for (const value of getBarChartKeys(assessmentInfo)) {\n    const currentBarItem = displayInfoCounts.currentCounts\n      ? getAssessmentBarChartValueBarItem(\n          intl,\n          assessmentInfo,\n          assessmentFilters,\n          value,\n          displayInfoCounts.currentCounts,\n          // For monitoring, there is no run name so we allow this to pass through.\n          currentRunDisplayName || 'monitor',\n          toggleAssessmentFilter,\n        )\n      : undefined;\n\n    const otherBarItem =\n      showCompareData && compareToRunDisplayName\n        ? getAssessmentBarChartValueBarItem(\n            intl,\n            assessmentInfo,\n            assessmentFilters,\n            value,\n            displayInfoCounts.otherCounts || new Map(),\n            compareToRunDisplayName,\n            toggleAssessmentFilter,\n          )\n        : undefined;\n\n    const isErrorOrNull = value === ERROR_KEY || value === undefined;\n    const scoreChange =\n      showCompareData && currentBarItem && otherBarItem\n        ? isErrorOrNull\n          ? currentBarItem.value - (otherBarItem?.value || 0)\n          : currentBarItem.fraction - (otherBarItem?.fraction || 0)\n        : undefined;\n    // Only include Error or Null if there's a non-zero value or score change.\n    if (currentBarItem && (!isErrorOrNull || currentBarItem.value !== 0 || (scoreChange && scoreChange !== 0))) {\n      barItems.push({\n        name: getAssessmentBarChartValueText(intl, theme, assessmentInfo, value),\n        current: currentBarItem,\n        other: otherBarItem,\n        backgroundColor: getAssessmentValueBarBackgroundColor(theme, assessmentInfo, value, value === ERROR_KEY),\n        scoreChange,\n      });\n    }\n  }\n\n  return barItems;\n}\n\nfunction getSortedUniqueValues(assessmentInfo: AssessmentInfo) {\n  const uniqueValuesArray = Array.from(assessmentInfo.uniqueValues);\n  if (assessmentInfo.dtype === 'pass-fail') {\n    // Always show \"YES\" and \"NO\". We don't always show missing to reduce vertical space usage.\n    if (!uniqueValuesArray.includes(KnownEvaluationResultAssessmentStringValue.YES)) {\n      uniqueValuesArray.push(KnownEvaluationResultAssessmentStringValue.YES);\n    }\n    if (!uniqueValuesArray.includes(KnownEvaluationResultAssessmentStringValue.NO)) {\n      uniqueValuesArray.push(KnownEvaluationResultAssessmentStringValue.NO);\n    }\n    const sortOrder: string[] = [\n      KnownEvaluationResultAssessmentStringValue.YES,\n      KnownEvaluationResultAssessmentStringValue.NO,\n    ];\n\n    // Sort the unique values based on the order of the known values.\n    return uniqueValuesArray.sort((a, b) => {\n      const aIndex = sortOrder.indexOf(a as string);\n      const bIndex = sortOrder.indexOf(b as string);\n      return aIndex - bIndex;\n    });\n  } else if (assessmentInfo.dtype === 'boolean') {\n    // Sort by the value.\n    return uniqueValuesArray.sort((a, b) => {\n      return (a as boolean) === true ? -1 : 1;\n    });\n  }\n\n  // Sort the assessment.\n  return uniqueValuesArray.sort();\n}\n\nfunction getAssessmentBarChartValueText(\n  intl: IntlShape,\n  theme: ThemeType,\n  assessmentInfo: AssessmentInfo,\n  value: string | boolean | number | undefined,\n): string {\n  if (assessmentInfo.dtype === 'pass-fail') {\n    if (value === KnownEvaluationResultAssessmentStringValue.YES) {\n      return intl.formatMessage({\n        defaultMessage: 'Pass',\n        description: 'The label for a passing asseessment above a bar-chart in the summary stats.',\n      });\n    } else if (value === KnownEvaluationResultAssessmentStringValue.NO) {\n      return intl.formatMessage({\n        defaultMessage: 'Fail',\n        description: 'The label for a failing asseessment above a bar-chart in the summary stats.',\n      });\n    } else if (value === ERROR_KEY) {\n      return intl.formatMessage({\n        defaultMessage: 'Error',\n        description: 'The label for an error asseessment above a bar-chart in the summary stats.',\n      });\n    } else {\n      return intl.formatMessage({\n        defaultMessage: 'null',\n        description: 'null assessment label',\n      });\n    }\n  } else if (assessmentInfo.dtype === 'boolean') {\n    if (value === true) {\n      return intl.formatMessage({\n        defaultMessage: 'True',\n        description: 'True assessment label',\n      });\n    } else if (value === false) {\n      return intl.formatMessage({\n        defaultMessage: 'False',\n        description: 'False assessment label',\n      });\n    } else {\n      return intl.formatMessage({\n        defaultMessage: 'null',\n        description: 'null assessment label',\n      });\n    }\n  }\n  return isNil(value) ? 'null' : `${value}`;\n}\n\n/**\n * Compute the counts for each of the values given a set of assessments.\n */\nexport function getUniqueValueCountsBySourceId(\n  assessmentInfo: AssessmentInfo,\n  assessments: RunEvaluationResultAssessment[],\n): {\n  value: AssessmentValueType | undefined;\n  count: number;\n  latestAssessment: RunEvaluationResultAssessment;\n}[] {\n  const filteredAssessments = assessments.filter((assessment) => assessment.name === assessmentInfo.name);\n  // Compute the unique values of assessments.\n  let uniqueValues = new Set<AssessmentValueType | undefined>();\n  for (const assessment of filteredAssessments) {\n    const value = getEvaluationResultAssessmentValue(assessment);\n    uniqueValues.add(value);\n  }\n\n  // Sort by the latest timestamp.\n  filteredAssessments.sort((a, b) => (b.timestamp || 0) - (a.timestamp || 0));\n\n  // Separate assessments with errors from those without.\n  const errorAssessments = filteredAssessments.filter((assessment) => doesAssessmentContainErrors(assessment));\n  const validAssessments = filteredAssessments.filter((assessment) => !doesAssessmentContainErrors(assessment));\n\n  // Recompute the unique values after filtering.\n  uniqueValues = new Set<AssessmentValueType | undefined>();\n  for (const assessment of validAssessments) {\n    const value = getEvaluationResultAssessmentValue(assessment);\n    uniqueValues.add(value);\n  }\n\n  // Compute the counts for each of the unique values.\n  const valueCounts: {\n    value: AssessmentValueType | undefined;\n    count: number;\n    latestAssessment: RunEvaluationResultAssessment;\n  }[] = [];\n  for (const value of uniqueValues) {\n    const assessmentsWithValue = filteredAssessments.filter(\n      (assessment) => getEvaluationResultAssessmentValue(assessment) === value,\n    );\n    const count = assessmentsWithValue.length;\n    valueCounts.push({ value, count, latestAssessment: assessmentsWithValue[0] });\n  }\n\n  // Add an entry for errors.\n  if (errorAssessments.length > 0) {\n    valueCounts.push({\n      value: ERROR_KEY,\n      count: errorAssessments.length,\n      latestAssessment: errorAssessments[0],\n    });\n  }\n\n  return valueCounts;\n}\n","import { isNil } from 'lodash';\n\nimport type { IntlShape } from '@databricks/i18n';\nimport { FormattedMessage } from '@databricks/i18n';\n\nimport { getAssessmentAggregateOverallFraction } from './AggregationUtils';\nimport type { AssessmentAggregates, AssessmentInfo } from '../types';\nconst NUM_DECIMALS_PERCENTAGE_DISPLAY = 1;\n\n/** Display a fraction (0-1) as a percentage. */\nexport function displayPercentage(fraction: number, numDecimalsDisplayPercentage = NUM_DECIMALS_PERCENTAGE_DISPLAY) {\n  // We wrap in a Number to remove trailing zeros (4.00 => 4).\n  return Number((fraction * 100).toFixed(numDecimalsDisplayPercentage)).toString();\n}\n\nexport function displayFloat(value: number | undefined | null, numDecimals = 3) {\n  if (isNil(value)) {\n    return 'null';\n  }\n  const multiplier = Math.pow(10, numDecimals);\n  const result = Math.round(value * multiplier) / multiplier;\n  return result.toString();\n}\n\n/**\n * Computes the overall display score for an assessment, and the change in score from the other run.\n */\nexport function getDisplayOverallScoreAndChange(\n  intl: IntlShape,\n  assessmentInfo: AssessmentInfo,\n  assessmentDisplayInfo: AssessmentAggregates,\n): {\n  displayScore: string;\n  displayScoreChange: string | undefined;\n  changeDirection: 'up' | 'down' | 'none';\n  aggregateType: 'average' | 'percentage-true' | 'categorical';\n} {\n  if (assessmentInfo.dtype === 'numeric') {\n    // Compute the average score for displayScore, and the change in average for displayScoreChange.\n    const currentNumericValues = assessmentDisplayInfo.currentNumericValues;\n    const otherNumericValues = assessmentDisplayInfo.otherNumericValues;\n\n    let currentAverage = NaN;\n    let otherAverage = NaN;\n    if (currentNumericValues) {\n      currentAverage = currentNumericValues.reduce((a, b) => a + b, 0) / currentNumericValues.length;\n    }\n    if (otherNumericValues) {\n      otherAverage = otherNumericValues.reduce((a, b) => a + b, 0) / otherNumericValues.length;\n    }\n    const displayScore = displayFloat(currentAverage, 2);\n    const scoreChange = otherNumericValues ? currentAverage - otherAverage : undefined;\n    const changeDirection = scoreChange ? (scoreChange > 0 ? 'up' : 'down') : 'none';\n\n    const displayScoreChange = scoreChange\n      ? changeDirection === 'up'\n        ? `+${displayFloat(Math.abs(scoreChange), 2)}`\n        : changeDirection === 'down'\n        ? `-${displayFloat(Math.abs(scoreChange), 2)}`\n        : '+0'\n      : undefined;\n\n    return {\n      displayScore,\n      displayScoreChange,\n      changeDirection,\n      aggregateType: 'average',\n    };\n  } else if (assessmentInfo.dtype === 'pass-fail' || assessmentInfo.dtype === 'boolean') {\n    const numDecimalsDisplayPercentage = 0;\n    const scoreFraction = getAssessmentAggregateOverallFraction(assessmentInfo, assessmentDisplayInfo.currentCounts);\n    const displayScore = displayPercentage(scoreFraction, numDecimalsDisplayPercentage) + '%';\n    const scoreChange = assessmentDisplayInfo.otherCounts\n      ? scoreFraction - getAssessmentAggregateOverallFraction(assessmentInfo, assessmentDisplayInfo.otherCounts)\n      : undefined;\n    const changeDirection = scoreChange ? (scoreChange > 0 ? 'up' : 'down') : 'none';\n    const displayScoreChange = scoreChange\n      ? (changeDirection === 'up' || changeDirection === 'none' ? '+' : '') +\n        displayPercentage(scoreChange, numDecimalsDisplayPercentage) +\n        '%'\n      : undefined;\n\n    return {\n      displayScore,\n      displayScoreChange,\n      changeDirection,\n      aggregateType: 'percentage-true',\n    };\n  } else if (assessmentInfo.dtype === 'string') {\n    const numUniqueValues = assessmentInfo.uniqueValues.size;\n    return {\n      displayScore:\n        numUniqueValues !== 1\n          ? intl.formatMessage(\n              {\n                defaultMessage: '{numUniqueValues} values',\n                description: 'Text for number of unique values for categorical assessment',\n              },\n              { numUniqueValues },\n            )\n          : intl.formatMessage({\n              defaultMessage: '1 value',\n              description: 'Text for number of unique values for categorical assessment',\n            }),\n      displayScoreChange: '',\n      changeDirection: 'none',\n      aggregateType: 'categorical',\n    };\n  } else {\n    return {\n      displayScore: 'N/A',\n      displayScoreChange: 'N/A',\n      changeDirection: 'none',\n      aggregateType: 'categorical',\n    };\n  }\n}\n\nexport function getDisplayScore(assessmentInfo: AssessmentInfo, fraction: number) {\n  return displayPercentage(fraction, 0) + '%';\n}\n\nexport function getDisplayScoreChange(assessmentInfo: AssessmentInfo, scoreChange: number, asPercentage = true) {\n  if (assessmentInfo.dtype === 'numeric') {\n    const changeDirection = scoreChange > 0 ? 'up' : 'down';\n    return changeDirection === 'up' ? `+${displayFloat(scoreChange, 2)}` : `-${displayFloat(scoreChange, 2)}`;\n  } else {\n    const changeDirection = scoreChange >= 0 ? 'up' : 'down';\n    if (asPercentage) {\n      return changeDirection === 'up'\n        ? `+${displayPercentage(scoreChange, 0)}%`\n        : `-${displayPercentage(scoreChange * -1, 0)}%`;\n    } else {\n      return changeDirection === 'up' ? `+${scoreChange}` : `-${scoreChange}`;\n    }\n  }\n}\n\n// This is forked from mlflow: https://src.dev.databricks.com/databricks-eng/universe/-/blob/mlflow/web/js/src/common/utils/Utils.tsx?L188\nexport function timeSinceStr(date: any, referenceDate = new Date()) {\n  // @ts-expect-error TS(2362): The left-hand side of an arithmetic operation must... Remove this comment to see the full error message\n  const seconds = Math.max(0, Math.floor((referenceDate - date) / 1000));\n  let interval = Math.floor(seconds / 31536000);\n\n  if (interval >= 1) {\n    return (\n      <FormattedMessage\n        defaultMessage=\"{timeSince, plural, =1 {1 year} other {# years}} ago\"\n        description=\"Text for time in years since given date for MLflow views\"\n        values={{ timeSince: interval }}\n      />\n    );\n  }\n  interval = Math.floor(seconds / 2592000);\n  if (interval >= 1) {\n    return (\n      <FormattedMessage\n        defaultMessage=\"{timeSince, plural, =1 {1 month} other {# months}} ago\"\n        description=\"Text for time in months since given date for MLflow views\"\n        values={{ timeSince: interval }}\n      />\n    );\n  }\n  interval = Math.floor(seconds / 86400);\n  if (interval >= 1) {\n    return (\n      <FormattedMessage\n        defaultMessage=\"{timeSince, plural, =1 {1 day} other {# days}} ago\"\n        description=\"Text for time in days since given date for MLflow views\"\n        values={{ timeSince: interval }}\n      />\n    );\n  }\n  interval = Math.floor(seconds / 3600);\n  if (interval >= 1) {\n    return (\n      <FormattedMessage\n        defaultMessage=\"{timeSince, plural, =1 {1 hour} other {# hours}} ago\"\n        description=\"Text for time in hours since given date for MLflow views\"\n        values={{ timeSince: interval }}\n      />\n    );\n  }\n  interval = Math.floor(seconds / 60);\n  if (interval >= 1) {\n    return (\n      <FormattedMessage\n        defaultMessage=\"{timeSince, plural, =1 {1 minute} other {# minutes}} ago\"\n        description=\"Text for time in minutes since given date for MLflow views\"\n        values={{ timeSince: interval }}\n      />\n    );\n  }\n  return (\n    <FormattedMessage\n      defaultMessage=\"{timeSince, plural, =1 {1 second} other {# seconds}} ago\"\n      description=\"Text for time in seconds since given date for MLflow views\"\n      values={{ timeSince: seconds }}\n    />\n  );\n}\n\n// Function to escape CSS Special characters by adding \\\\ before them. Needed when inserting CSS variables.\nexport function escapeCssSpecialCharacters(str: string) {\n  // eslint-disable-next-line no-useless-escape\n  return str.replace(/([!\"#$%&'()*+,\\.\\/:;\\s<=>?@[\\\\\\]^`{|}~])/g, '\\\\$1');\n}\n\n// Adapted from query-insights/utils/numberUtils\nexport function prettySizeWithUnit(bytes: number | null | undefined, fractionDigits?: number) {\n  return prettyNumberWithUnit(bytes, 1024, ['bytes', 'KB', 'MB', 'GB', 'TB', 'PB'], fractionDigits);\n}\n\nfunction prettyNumberWithUnit(\n  value: string | number | null | undefined,\n  divisor: number,\n  units: string[] = [],\n  fractionDigits?: number,\n): { unit: string; value: string; numericValue: number | undefined; divisor: number } {\n  let val = Number(value);\n\n  if (isNaN(val) || !isFinite(val)) {\n    return {\n      value: '',\n      numericValue: undefined,\n      unit: '',\n      divisor: 1,\n    };\n  }\n\n  let unit = 0;\n  let greatestDivisor = 1;\n\n  while (val >= divisor && unit < units.length - 1) {\n    val /= divisor;\n    greatestDivisor *= divisor;\n    unit += 1;\n  }\n\n  return {\n    value: formatNumber(val, fractionDigits),\n    numericValue: val,\n    unit: units[unit],\n    divisor: greatestDivisor,\n  };\n}\n\nfunction formatNumber(value: number, fractionDigits = 3): string {\n  return Math.round(value) !== value ? value.toFixed(fractionDigits) : value.toString();\n}\n","import { css } from '@emotion/react';\nimport type { ReactNode } from 'react';\nimport React from 'react';\n\nimport type { ButtonProps } from '@databricks/design-system';\nimport { Button, LegacyTooltip } from '@databricks/design-system';\n\ntype SnippetActionButtonProps = Pick<ButtonProps, 'icon' | 'onClick' | 'href' | 'rel' | 'target'> & {\n  tooltipMessage: NonNullable<ReactNode>;\n};\n\nexport default function SnippetActionButton({ tooltipMessage, ...buttonProps }: SnippetActionButtonProps) {\n  const style = css({\n    zIndex: 1, // required for action buttons to be visible and float\n  });\n  return (\n    <LegacyTooltip title={tooltipMessage}>\n      <Button\n        componentId=\"codegen_web-shared_src_snippet_actions_snippetactionbutton.tsx_33\"\n        {...buttonProps}\n        css={style}\n      />\n    </LegacyTooltip>\n  );\n}\n","import React from 'react';\n\nimport type { ButtonProps } from '@databricks/design-system';\nimport { useCopyController } from '@databricks/web-shared/copy';\n\nimport SnippetActionButton from './SnippetActionButton';\n\nexport interface SnippetCopyActionProps extends ButtonProps {\n  /**\n   * The text to be copied into clipboard when action button is clicked.\n   */\n  copyText: string;\n  onClick?: (e: React.MouseEvent) => void;\n}\n\nexport function SnippetCopyAction({ copyText, onClick, ...props }: SnippetCopyActionProps) {\n  const { actionIcon, tooltipMessage, copy } = useCopyController(copyText);\n\n  return (\n    <SnippetActionButton\n      tooltipMessage={tooltipMessage}\n      icon={actionIcon}\n      onClick={(e) => {\n        copy();\n        onClick?.(e);\n      }}\n      {...props}\n    />\n  );\n}\n","import { PrismLight as SyntaxHighlighter } from 'react-syntax-highlighter';\nimport go from 'react-syntax-highlighter/dist/cjs/languages/prism/go';\nimport java from 'react-syntax-highlighter/dist/cjs/languages/prism/java';\nimport javascript from 'react-syntax-highlighter/dist/cjs/languages/prism/javascript';\nimport json from 'react-syntax-highlighter/dist/cjs/languages/prism/json';\nimport python from 'react-syntax-highlighter/dist/cjs/languages/prism/python';\nimport yaml from 'react-syntax-highlighter/dist/cjs/languages/prism/yaml';\nimport sql from 'react-syntax-highlighter/dist/cjs/languages/prism/sql';\n\nSyntaxHighlighter.registerLanguage('sql', sql);\nSyntaxHighlighter.registerLanguage('java', java);\nSyntaxHighlighter.registerLanguage('python', python);\nSyntaxHighlighter.registerLanguage('go', go);\nSyntaxHighlighter.registerLanguage('javascript', javascript);\nSyntaxHighlighter.registerLanguage('yaml', yaml);\nSyntaxHighlighter.registerLanguage('json', json);\n\nimport duotoneDarkStyle from './theme/databricks-duotone-dark';\nimport lightStyle from './theme/databricks-light';\nimport type { CSSProperties, ReactNode } from 'react';\nimport { pick } from 'lodash';\nexport type CodeSnippetTheme = 'duotoneDark' | 'light';\nexport const buttonBackgroundColorDark = 'rgba(140, 203, 255, 0)';\nexport const buttonColorDark = 'rgba(255, 255, 255, 0.84)';\nexport const buttonHoverColorDark = '#8ccbffcc';\nexport const buttonHoverBackgroundColorDark = 'rgba(140, 203, 255, 0.08)';\nexport const duboisAlertBackgroundColor = '#fff0f0';\nexport const snippetPadding = '24px';\nconst themesStyles: Record<CodeSnippetTheme, any> = {\n  light: lightStyle,\n  duotoneDark: duotoneDarkStyle,\n};\n\nexport type CodeSnippetLanguage = 'sql' | 'java' | 'python' | 'javascript' | 'go' | 'yaml' | 'text' | 'json';\n\nexport interface CodeSnippetProps {\n  /**\n   * The code string\n   */\n  children: string;\n  /**\n   * The actions that are displayed on the right top corner of the component\n   *  see `./actions` for built-in actions\n   */\n  actions?: NonNullable<ReactNode> | NonNullable<ReactNode>[];\n  /**\n   * The theme, default theme is `light`\n   */\n  theme?: CodeSnippetTheme;\n  /**\n   * Language of the code (`children`)\n   */\n  language: CodeSnippetLanguage;\n  /**\n   * Custom styles (passed to the internal `<pre>`)\n   */\n  style?: CSSProperties;\n  /**\n   * Whether to show line numbers on the left or not\n   */\n  showLineNumbers?: boolean;\n  /**\n   * Custom styles for line numbers\n   */\n  lineNumberStyle?: CSSProperties;\n  /**\n   * Boolean to specify whether to style the <code> block with white-space: pre-wrap or white-space: pre\n   */\n  wrapLongLines?: boolean;\n  /**\n   * Boolean that determines whether or not each line of code should be wrapped in a parent element\n   */\n  wrapLines?: boolean;\n  /**\n   * Props to pass to the line elements\n   */\n  lineProps?: React.HTMLProps<HTMLElement> | undefined;\n  /**\n   * Custom tag to use for the `<pre>` element\n   */\n  PreTag?: keyof JSX.IntrinsicElements | React.ComponentType<React.PropsWithChildren<any>> | undefined;\n}\n\n/**\n * `CodeSnippet` is used for highlighting code, use this instead of\n */\nexport function CodeSnippet({\n  theme = 'light',\n  language,\n  actions,\n  style,\n  children,\n  showLineNumbers,\n  lineNumberStyle,\n  wrapLongLines,\n  wrapLines,\n  PreTag,\n}: CodeSnippetProps) {\n  const customStyle = {\n    border: 'none',\n    borderRadius: 0,\n    margin: 0,\n    padding: snippetPadding,\n    ...style,\n  };\n  return (\n    <SyntaxHighlighter\n      showLineNumbers={showLineNumbers}\n      lineNumberStyle={lineNumberStyle}\n      language={language}\n      style={themesStyles[theme]}\n      customStyle={customStyle}\n      codeTagProps={{\n        style: pick(style, 'backgroundColor'),\n      }}\n      wrapLongLines={wrapLongLines}\n      wrapLines={wrapLines}\n      PreTag={PreTag}\n    >\n      {children}\n    </SyntaxHighlighter>\n  );\n}\n\nexport * from './actions/SnippetCopyAction';\n"],"names":["MarkdownConverterProviderContext","React","makeHTML","markdown","MarkdownConverterProvider","children","makeHtml","_jsx","Provider","value","useMarkdownConverter","GET_DATASET_RECORDS_QUERY_KEY","SEARCH_EVALUATION_DATASETS_QUERY_KEY","FETCH_TRACES_QUERY_KEY","CopyActionButton","buttonProps","componentId","copyText","copyTooltip","isInsideInputGroup","onCopy","tooltipProps","actionIcon","copy","handleTooltipOpenChange","tooltipOpen","tooltipMessage","useCopyController","button","Button","icon","onClick","size","inputGroupButton","Tooltip","content","onOpenChange","open","CreateEvaluationDatasetModal","visible","experimentId","onCancel","intl","useIntl","datasetName","setDatasetName","useState","datasetNameError","setDatasetNameError","createEvaluationDatasetMutation","isLoading","useCreateEvaluationDatasetMutation","onSuccess","onError","queryClient","useQueryClient","mutate","useMutation","mutationFn","async","experimentIds","requestBody","name","experiment_ids","fetchAPI","getAjaxUrl","dataset","invalidateQueries","queryKey","error","handleCreateEvaluationDataset","useCallback","formatMessage","id","defaultMessage","_jsxs","Modal","okText","cancelText","onOk","okButtonProps","loading","disabled","title","FormattedMessage","FormUI","Label","htmlFor","Input","type","placeholder","onChange","e","target","Message","message","_ref","styles","CreateEvaluationDatasetButton","showCreateDatasetModal","setShowCreateDatasetModal","_Fragment","css","DatabaseIcon","useSearchEvaluationDatasets","enabled","nameFilter","data","fetchNextPage","hasNextPage","isFetching","refetch","useInfiniteQuery","queryFn","pageParam","filter_string","undefined","order_by","max_results","page_token","cacheTime","refetchOnWindowFocus","retry","getNextPageParam","lastPage","next_page_token","useMemo","_data$pages$flatMap","pages","flatMap","page","_page$datasets","datasets","isAssessmentPassing","assessmentInfo","assessmentValue","isNil","dtype","KnownEvaluationResultAssessmentStringValue","YES","NO","_ref2","_ref3","_ref4","_ref5","_ref6","EvaluationsReviewAssessmentTag","assessment","onEdit","active","disableJudgeTypeIcon","showRationaleInTooltip","showPassFailText","hideAssessmentName","iconOnly","disableTooltip","isRootCauseAssessment","count","_assessmentInfo$sourc","_assessment$source","theme","useDesignSystemTheme","getEvaluationResultAssessmentValue","isPassing","iconColor","getEvaluationResultIconColor","textColor","getEvaluationResultTextColor","errorMessage","KnownEvaluationResultAssessmentValueMissingTooltip","knownValueLabel","KnownEvaluationResultAssessmentValueLabel","assessmentTitle","learnMoreLink","getJudgeMetricsLink","ASSESSMENTS_DOC_LINKS","rationaleHTML","rationale","isString","editedByHuman","hasBeenEditedByHuman","tagText","fullTagText","errorDisplayValue","DangerIcon","_css","color","colors","textValidationWarning","nullDisplayValue","WarningIcon","grey400","Boolean","displayValueText","CheckCircleIcon","XCircleFillIcon","XCircleIcon","knownMapping","KnownEvaluationResultAssessmentValueMapping","_knownMapping$value$t","messageDescriptor","toString","values","displayName","roundedValue","displayFloat","valueElement","String","getAssessmentTagDisplayValue","tagContent","source","sourceType","sourceId","tagElement","EvaluationsReviewTag","sourceIcon","isCustomMetric","BracketsXIcon","UserIcon","SparkleDoubleIcon","backgroundColor","getEvaluationResultAssessmentBackgroundColor","disableSourceTypeIcon","HoverCard","side","maxWidth","display","flexDirection","overflowWrap","wordBreak","gap","spacing","sm","xs","alignItems","Typography","Title","href","rel","InfoSmallIcon","Hint","dangerouslySetInnerHTML","__html","fontStyle","trigger","svgSize","height","width","justifyContent","padding","borderRadius","legacyBorders","borderRadiusMd","boxShadow","borderAccessible","fontSize","typography","fontSizeSm","svg","whiteSpace","PencilIcon","actionDefaultTextHover","AGGREGATE_SCORE_CHANGE_BACKGROUND_COLORS","up","down","AGGREGATE_SCORE_CHANGE_TEXT_COLOR","CURRENT_RUN_COLOR","COMPARE_TO_RUN_COLOR","PASS_BARCHART_BAR_COLOR","FAIL_BARCHART_BAR_COLOR","TAG_PASS_COLOR","stringValue","isDarkMode","green400","green600","red400","red600","withAlpha","red800","red200","booleanValue","textSecondary","textPrimary","getAssessmentValueBarBackgroundColor","isError","grey800","grey200","useInfiniteScrollFetch","containerRefElement","scrollHeight","scrollTop","clientHeight","INPUT_MESSAGES_KEY","KnownEvaluationResultAssessmentName","DEFAULT_ASSESSMENTS_SORT_ORDER","OVERALL_ASSESSMENT","CORRECTNESS","GLOBAL_GUIDELINE_ADHERENCE","GUIDELINE_ADHERENCE","GUIDELINES","RELEVANCE_TO_QUERY","CONTEXT_SUFFICIENCY","RETRIEVAL_SUFFICIENCY","CHUNK_RELEVANCE","RETRIEVAL_RELEVANCE","GROUNDEDNESS","RETRIEVAL_GROUNDEDNESS","SAFETY","asessmentDocLink","basePath","hash","getAssessmentValueLabel","UNKNOWN","KnownEvaluationResultAssessmentMetadataFields","KnownEvaluationResultAssessmentOutputLabel","response","defineMessage","EXPECTED_FACTS_FIELD_NAME","KnownEvaluationResultAssessmentTargetLabel","expected_response","KnownEvaluationResultAssessmentValueDescription","isAssessmentAiGenerated","getEvaluationResultTitle","evaluation","getEvaluationResultInputTitle","inputs","Object","keys","length","stringifyValue","evaluationId","inputKey","_input$INPUT_MESSAGES","_input$","inputsTitle","JSON","stringify","input","_input$INPUT_MESSAGES2","isPlainObject","Array","isArray","_input","isEvaluationResultOverallAssessment","assessmentEntry","_assessmentEntry$meta","metadata","IS_OVERALL_ASSESSMENT","isEvaluationResultPerRetrievalChunkAssessment","_assessmentEntry$meta2","isNumber","CHUNK_INDEX","_assessment$stringVal","numericValue","hexColor","opacity","startsWithHash","startsWith","slice","Math","round","min","max","toUpperCase","KnownEvaluationResponseAssessmentNames","KnownEvaluationRetrievalAssessmentNames","createDraftEvaluationResultAssessmentObject","isOverallAssessment","_getUser","getUser","timestamp","Date","now","isDraft","shouldRepeatExistingOriginalOverallAiAssessment","sourceEvaluationResult","pendingAssessmentEntries","overallAssessments","every","some","copyAiOverallAssessmentAsHumanAssessment","_getUser2","firstAiOverallAssessment","find","IS_COPIED_FROM_AI","isDraftAssessment","getOrderedAssessments","assessmentsByName","orderBy","entries","key","assessments","index","indexInKnownNames","indexOf","_assessments$timestam","_assessments","isEvaluationResultReviewedAlready","evaluationResult","_evaluationResult$ove","_evaluationResult$ove2","filter","_assessment$source2","_assessment$metadata","getEvaluationResultAssessmentChunkIndex","_assessment$metadata2","getAssessmentValueSuggestions","originalAssessment","assessmentHistory","assessmentInfos","mapping","map","label","rootAssessmentName","isAssessmentMissing","hasRationale","hasValue","hasErrorMessage","isRetrievedContext","v","ERROR_KEY","doesAssessmentContainErrors","errorCode","getCustomMetricNameAndAssessment","assessmentPath","splits","split","metricName","assessmentName","join","PASS_FAIL_VALUES","getAssessmentInfos","currentEvaluationResults","otherEvaluationResults","_assessmentInfos$Know","assessmentDtypes","assessmentNames","Set","forEach","result","_result$retrievalChun","responseAssessmentsByName","overallAssessmentsByName","retrievalAssessmentsByName","retrievalChunks","chunk","push","add","includes","_result$retrievalChun2","_","_assessment$source3","_assessment$source4","isKnown","customMetricName","customAssessmentName","docsLink","missingTooltip","description","uniqueValues","isOverall","isEditable","isRetrievalAssessment","containsErrors","_assessment$source5","_assessment$source6","seenOverallAssessmentValues","has","sortAssessmentInfos","sort","a","b","orderA","orderB","localeCompare","getAssessmentNumericAggregates","evalResults","numericValues","numericAggregateCounts","bucketSize","maxCount","lower","upper","i","bucket","counts","getNumericAggregate","evalResult","getAssessmentRunValueCounts","valueCounts","Map","valueCountsBySourceId","getUniqueValueCountsBySourceId","keysToCount","uniqueValue","valueCountBySourceId","valueCount","set","get","getAssessmentRunNumericValues","first","Number","getRootCauseAssessmentCount","numRootCause","_overallAssessment$ro","overallAssessment","rootCauseAssessment","getAssessmentAggregates","allAssessmentFilters","currentEvalResults","entry","currentRunValue","otherEvalResults","otherRunValue","currentAssessmentAggregates","otherAssessmentAggregates","currentNumericAggregates","assessmentFilters","currentCounts","otherCounts","currentNumericValues","otherNumericValues","currentNumericAggregate","currentNumRootCause","otherNumRootCause","getAssessmentAggregateOverallFraction","assessmentRunCounts","total","passCount","getAssessmentBarChartValueBarItem","runName","toggleAssessmentFilter","numEvals","isErrorOrNull","numValue","fraction","isSelected","filterValue","run","toggleFilter","tooltip","getBarChartKeys","uniqueValuesArray","from","sortOrder","getSortedUniqueValues","getBarChartData","displayInfoCounts","currentRunDisplayName","compareToRunDisplayName","showCompareData","barItems","currentBarItem","otherBarItem","scoreChange","getAssessmentBarChartValueText","current","other","filteredAssessments","errorAssessments","validAssessments","assessmentsWithValue","latestAssessment","NUM_DECIMALS_PERCENTAGE_DISPLAY","displayPercentage","numDecimalsDisplayPercentage","toFixed","numDecimals","multiplier","pow","getDisplayOverallScoreAndChange","assessmentDisplayInfo","currentAverage","NaN","otherAverage","reduce","changeDirection","displayScore","displayScoreChange","abs","aggregateType","scoreFraction","numUniqueValues","getDisplayScore","getDisplayScoreChange","asPercentage","timeSinceStr","date","referenceDate","seconds","floor","interval","timeSince","escapeCssSpecialCharacters","str","replace","prettySizeWithUnit","bytes","fractionDigits","divisor","units","val","isNaN","isFinite","unit","greatestDivisor","formatNumber","prettyNumberWithUnit","SnippetActionButton","style","LegacyTooltip","SnippetCopyAction","props","SyntaxHighlighter","registerLanguage","sql","java","python","go","javascript","yaml","json","snippetPadding","themesStyles","light","lightStyle","duotoneDark","duotoneDarkStyle","CodeSnippet","language","actions","showLineNumbers","lineNumberStyle","wrapLongLines","wrapLines","PreTag","customStyle","border","margin","codeTagProps","pick"],"sourceRoot":""}